{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb62997e-7212-47c7-8e5a-de72b0cb8903",
   "metadata": {},
   "source": [
    "# Korean Embedding ëª¨ë¸ì„ SageMaker ë°°í¬ ë° ì¶”ë¡ \n",
    "- ì´ ë…¸íŠ¸ë¶ì€ SageMaker Notebook Instance ì˜ conday_pytorch_p39 ì—ì„œ í…ŒìŠ¤íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f589c-04d8-4d46-894d-9b12e84f4f8d",
   "metadata": {},
   "source": [
    "Model Ref:\n",
    "- BM-K/KoSimCSE-roberta\n",
    "    - https://huggingface.co/BM-K/KoSimCSE-roberta\n",
    "Inference Code Ref:    \n",
    "- Huggingface Sagemaker-sdk - Deploy ğŸ¤— Transformers for inference\n",
    "    - https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb\n",
    "- Sentence Embeddings with Hugging Face Transformers, Sentence Transformers and Amazon SageMaker - Custom Inference for creating document embeddings with Hugging Face's Transformers\n",
    "    - https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c215704-222f-40a3-b018-d4b2b5fa16e1",
   "metadata": {},
   "source": [
    "# 1. HF Hubë¡œ ë¶€í„° ëª¨ë¸ ë° í† í° ë‚˜ì´ì € ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcd49e4-d2be-4cd0-9a00-95bcfcdbb002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "def cal_score(a, b):\n",
    "    '''\n",
    "    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ êµ¬í•˜ëŠ” í•¨ìˆ˜\n",
    "    '''\n",
    "    if len(a.shape) == 1: a = a.unsqueeze(0)\n",
    "    if len(b.shape) == 1: b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100\n",
    "\n",
    "model = AutoModel.from_pretrained('BM-K/KoSimCSE-roberta')\n",
    "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-roberta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4492fea2-d159-4967-a417-bef6a628f333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.config.max_length:  20\n",
      "tokenizer.max_len_single_sentence:  510\n",
      "tokenizer.max_model_input_sizes: \n",
      " {'bert-base-uncased': 512, 'bert-large-uncased': 512, 'bert-base-cased': 512, 'bert-large-cased': 512, 'bert-base-multilingual-uncased': 512, 'bert-base-multilingual-cased': 512, 'bert-base-chinese': 512, 'bert-base-german-cased': 512, 'bert-large-uncased-whole-word-masking': 512, 'bert-large-cased-whole-word-masking': 512, 'bert-large-uncased-whole-word-masking-finetuned-squad': 512, 'bert-large-cased-whole-word-masking-finetuned-squad': 512, 'bert-base-cased-finetuned-mrpc': 512, 'bert-base-german-dbmdz-cased': 512, 'bert-base-german-dbmdz-uncased': 512, 'TurkuNLP/bert-base-finnish-cased-v1': 512, 'TurkuNLP/bert-base-finnish-uncased-v1': 512, 'wietsedv/bert-base-dutch-cased': 512}\n",
      "tokenizer.model_max_length:  512\n"
     ]
    }
   ],
   "source": [
    "print(\"model.config.max_length: \", model.config.max_length)\n",
    "print(\"tokenizer.max_len_single_sentence: \", tokenizer.max_len_single_sentence)\n",
    "print(\"tokenizer.max_model_input_sizes: \\n\", tokenizer.max_model_input_sizes)\n",
    "print(\"tokenizer.model_max_length: \", tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852c991-7aab-44b6-b210-ec10ff03c28c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Max Length í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f73f6fd2-c668-486d-8145-c43d46b9cf62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences0 :  1217\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_embedding(tokenizer, model, sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    embeddings, _ = model(**inputs, return_dict=False)\n",
    "    \n",
    "    print(\"embeddings: \", embeddings.shape)\n",
    "    return None\n",
    "\n",
    "# sentences0 = [\n",
    "#                 \"ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤.\\\n",
    "#                 ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤\\\n",
    "#                 ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤\\\n",
    "#                 ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤\\\n",
    "#                 ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤\\\n",
    "#                 \"\n",
    "# ]\n",
    "\n",
    "sentences0 = [\n",
    "                \"ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤.\\\n",
    "                ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤\\\n",
    "                ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤. íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤í•  ìˆ˜ ì—†ëŠ” ì œí’ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì–´ë–¤ ì œí’ˆë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆê¹Œ? ê°€ì¥ ìˆ˜ìµì„±ì´ ì¢‹ì€ í‹ˆìƒˆ ì‹œì¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ë©´ ì´ 38ê°€ì§€ ì˜¨ë¼ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ ëª©ë¡ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì•„ë§ˆì¡´ì—ì„œ ì‹œì‘í•œ íŒë§¤ìì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì „ ì„¸ê³„ ê³ ê°ì—ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤\\\n",
    "                ì•„ë§ˆì¡´ ë§¤ì¥ì—ëŠ” ìƒˆë¡œìš´ íŒë§¤ìë¥¼ ìœ„í•œ ë§ì€ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤.íŒë§¤í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ì œí’ˆ, ë²”ì£¼ ë° ë¸Œëœë“œì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.ì¼ë¶€ ë²”ì£¼ëŠ” ëª¨ë“  íŒë§¤ìì—ê²Œ ì—´ë ¤ ìˆëŠ” ë°˜ë©´ ë‹¤ë¥¸ ë²”ì£¼ëŠ” í”„ë¡œí˜ì…”ë„ ì…€ëŸ¬ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.íŠ¹ì • ì œí’ˆì€ íŒë§¤ ìŠ¹ì¸ì´ í•„ìš”í•˜ê³  ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ëŠ” íƒ€ì‚¬ íŒë§¤ìê°€ íŒë§¤ë¥¼ ë”ìš±ë” í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì„ ì¶”ê°€ í† í° ì…ë‹ˆë‹¤\\\n",
    "                \"\n",
    "]\n",
    "\n",
    "\n",
    "print(\"sentences0 : \", len(sentences0[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "79ef486a-6873-4ce2-b4c1-bda7c5e827fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings:  torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "show_embedding(tokenizer, model, sentences0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525156e-b71e-4cc4-bdee-bf4ac4cacfc0",
   "metadata": {},
   "source": [
    "# 2. ì„¸ì´ì§€ ë©”ì´ì»¤ë¡œ ëª¨ë¸ ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56cf132c-def0-46d0-9581-4822c6067f14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::057716757052:role/gen_ai_gsmoon\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe6665-0e66-4089-9900-bf7787c2d74f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HF Model ID, HF_TASK ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6fbd1714-0d82-496e-b267-9afb2b05f923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "  'HF_MODEL_ID':'BM-K/KoSimCSE-roberta', # model_id from hf.co/models\n",
    "  'HF_TASK':'feature-extraction',\n",
    "  'SAGEMAKER_MODEL_SERVER_TIMEOUT':'3600', \n",
    "  'TS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "  'TS_MAX_REQUEST_SIZE':'2000000000',\n",
    "  'MMS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "  'MMS_MAX_REQUEST_SIZE':'2000000000'\n",
    "}        \n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub,\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.26\", # transformers version used\n",
    "   pytorch_version=\"1.13\", # pytorch version used\n",
    "   py_version=\"py39\", # python version of the DLC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8c52d-081c-46db-849f-b1f199078ba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ëª¨ë¸ ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "006baf1e-f3d4-4f14-b396-358cf051e1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!CPU times: user 210 ms, sys: 7.7 ms, total: 218 ms\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   # instance_type=\"ml.m5.xlarge\"\n",
    "   instance_type=\"ml.g5.2xlarge\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "316cf862-48a3-4727-8534-9345d1d1a6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-inference-2023-06-04-10-59-43-906'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372071e1-7e2e-45d3-9404-7c2064917af5",
   "metadata": {},
   "source": [
    "# 3. ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d82b36b6-6d12-424c-9b42-4fce8852bfcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res:  (1, 1, 517, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "payload_0 = {\n",
    "    \"inputs\" : sentences0\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def predict_payload(data):\n",
    "    res = predictor.predict(data=data)\n",
    "    res = np.array(res) # .squeeze().squeeze()\n",
    "    print(\"res: \", res.shape)\n",
    "    # print(\"embedding dimension: \", len(res[0][0][0]))\n",
    "    return None\n",
    "\n",
    "predict_payload(payload_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66e40a-f1ab-4eeb-bebc-35f279f8e55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "727b5bee-47d7-4c91-8fc3-05fd13fb077b",
   "metadata": {},
   "source": [
    "# 4. ì—”ë“œí¬ì¸íŠ¸ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fa92abce-3249-477d-b982-fc11f48c7883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec91af7-a2e8-4697-9dd8-d93c57db8b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
