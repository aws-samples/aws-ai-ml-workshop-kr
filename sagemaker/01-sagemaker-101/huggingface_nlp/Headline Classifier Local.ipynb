{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c08a9-6046-41da-baf5-9c9ea48f5fdd",
   "metadata": {},
   "source": [
    "# 뉴스 헤드라인 분류하기 (로컬 버전)\n",
    "\n",
    "> 이 노트북은 SageMaker Notebook Instance 및 conda_pytorch_p310 및 SageMaker Studio의 `Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` 커널에서 잘 작동합니다.\n",
    "\n",
    "이 예제에서는 커스텀 스크립트와 [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) 프레임워크를 사용하여 뉴스 헤드라인 분류기 모델을 훈련할 것입니다.\n",
    "\n",
    "이 \"로컬\" 노트북은 노트북 자체에서 모델을 훈련하고 테스트하는 방법을 보여줄 것이며, 동반 [\"SageMaker\" 노트북](Headline%20Classifier%20SageMaker.ipynb)은 컨테이너화된 SageMaker 훈련 작업과 엔드포인트 배포를 사용하여 동일한 프로세스를 반복할 것입니다.\n",
    "\n",
    "Hugging Face를 처음 접하는 경우 [Transformers 빠른 투어](https://huggingface.co/docs/transformers/quicktour)를 읽거나 다음 (1시간) 소개 동영상을 시청하는 것이 좋습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7373d72c-7f09-4a87-851d-dc603412912b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pYqjCzoyWyo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pYqjCzoyWyo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57514090-30b2-46c3-bee6-cb013b2038cb",
   "metadata": {},
   "source": [
    "## 설치 및 설정\n",
    "\n",
    "위에서 지정한 PyTorch SageMaker 커널은 필요한 대부분의 라이브러리를 가지고 있지만 모든 것을 가지고 있지는 않습니다. 먼저, HF transformers/datasets의 적절한 버전과 나중에 대화형 분류기 위젯을 구동하기 위한 IPyWidgets를 설치해야 합니다:\n",
    "\n",
    "> ⚠️ **참고:** 이 셀을 먼저 실행하면 노트북 커널을 다시 시작할 필요가 없습니다. 하지만 이미 `import`한 것이 있다면 이러한 설치가 적용되도록 위의 툴바에서 원형 '커널 다시 시작' 버튼을 클릭해야 합니다.\n",
    "\n",
    "아래 출력에서 pip의 *경고*는 무시할 수 있지만 *오류*는 보이지 않아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ce072d-ea68-41ef-bc9b-6fcc869d963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets                                2.2.1\n",
      "numpy                                   1.26.4\n",
      "pandas                                  2.2.3\n",
      "pytorch-lightning                       2.3.3\n",
      "pytorch-metric-learning                 2.3.0\n",
      "torch                                   2.3.1.post300\n",
      "torchmetrics                            1.2.1\n",
      "torchvision                             0.18.1a0+405940f\n",
      "transformers                            4.38.2\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep -E \"pandas|numpy|datasets|transformers|torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2cc7de2-59b4-49a7-8823-6953e2531cea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==3.2.0\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting transformers==4.26.0\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl.metadata (100 kB)\n",
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting pandas==1.5.3\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (0.26.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.26.0) (2024.11.6)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.0)\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.2) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.2)\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.11/site-packages (from pandas==1.5.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas==1.5.3) (2023.3)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.2.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets==3.2.0) (0.2.1)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m154.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m193.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m216.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m157.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m144.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m127.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m180.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m185.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, transformers, nvidia-cusolver-cu12, torch, datasets\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.17\n",
      "    Uninstalling multiprocess-0.70.17:\n",
      "      Successfully uninstalled multiprocess-0.70.17\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.38.2\n",
      "    Uninstalling transformers-4.38.2:\n",
      "      Successfully uninstalled transformers-4.38.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1.post300\n",
      "    Uninstalling torch-2.3.1.post300:\n",
      "      Successfully uninstalled torch-2.3.1.post300\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.2.1\n",
      "    Uninstalling datasets-2.2.1:\n",
      "      Successfully uninstalled datasets-2.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-common 1.1.1 requires pandas<2.3.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-core 1.1.1 requires pandas<2.3.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-features 1.1.1 requires pandas<2.3.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires pandas<2.3.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.26.0 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires pandas<2.3.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires pandas<2.3.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires transformers[sentencepiece]<4.41.0,>=4.38.0, but you have transformers 4.26.0 which is incompatible.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 tokenizers-0.13.3 torch-2.2.2 transformers-4.26.0 triton-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets==3.2.0 transformers==4.26.0 torch==2.2.2 pandas==1.5.3 numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5053cb-35f1-40cc-a3f2-4d0a73a246be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.11/site-packages (4.2.6)\n",
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-4.3.4-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.11/site-packages (from jupyter) (7.2.2)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.11/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.11/site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.11/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from jupyter) (8.1.5)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (24.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (75.6.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (6.4.2)\n",
      "Requirement already satisfied: traitlets in /opt/conda/lib/python3.11/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (1.8.10)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (0.10.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (2.18.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->jupyter) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from jupyter-console->jupyter) (3.0.48)\n",
      "  Downloading jupyterlab-4.2.7-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/conda/lib/python3.11/site-packages (from anyio->httpx>=0.25.0->jupyterlab) (4.12.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (1.26.19)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.11/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
      "Downloading jupyterlab-4.2.7-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m166.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jupyterlab\n",
      "  Attempting uninstall: jupyterlab\n",
      "    Found existing installation: jupyterlab 4.2.6\n",
      "    Uninstalling jupyterlab-4.2.6:\n",
      "      Successfully uninstalled jupyterlab-4.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-ai 2.28.3 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed jupyterlab-4.2.7\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install --upgrade jupyter jupyterlab\n",
    "pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5d2d-d062-468f-96dc-d51018cc2450",
   "metadata": {},
   "source": [
    "설치가 완료되면 나머지 노트북에서 사용할 라이브러리와 Python 내장 기능을 로드합니다.\n",
    "\n",
    "[%autoreload magic](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html)은 로컬 .py 파일로 작업할 때 유용합니다. 각 셀 실행 시 라이브러리를 다시 로드하면 노트북 커널을 다시 시작하지 않고도 로컬로 편집/업데이트된 스크립트를 사용할 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efbe751a-dce5-4dd1-b96c-35738d28fe1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 05:49:41.143811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-09 05:49:41.159958: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-09 05:49:41.164975: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 05:49:41.177975: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import os  # Operating system utils e.g. file paths\n",
    "\n",
    "# External Dependencies:\n",
    "import datasets  # Hugging Face data loading utilities\n",
    "import ipywidgets as widgets  # Interactive prediction widget\n",
    "import pandas as pd  # Utilities for working with data tables (dataframes)\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import transformers  # Hugging Face Transformers framework\n",
    "\n",
    "local_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b6e3e-1f50-4337-8339-fc05d71af52f",
   "metadata": {},
   "source": [
    "## 데이터셋 준비하기\n",
    "\n",
    "이 예제는 [Registry of Open Data on AWS](https://registry.opendata.aws/fast-ai-nlp/) 공개 리포지토리에서 **FastAi AG News** 데이터셋을 다운로드합니다. 이 데이터셋에는 뉴스 헤드라인과 해당 주제 클래스가 포함된 테이블이 들어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131a0145-9033-4112-a67f-5e229679229e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-nlp/ag_news_csv.tgz to data/ag_news_csv.tgz\n",
      "Done!\n",
      "CPU times: user 24.2 ms, sys: 46.5 ms, total: 70.7 ms\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download the AG News data from the Registry of Open Data on AWS.\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-nlp/ag_news_csv.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the AG News data.\n",
    "!tar zxf {local_dir}/ag_news_csv.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "\n",
    "# Push data partitions to separate subfolders, which is useful for local script debugging later\n",
    "os.renames(f\"{local_dir}/test.csv\", f\"{local_dir}/test/test.csv\")\n",
    "os.renames(f\"{local_dir}/train.csv\", f\"{local_dir}/train/train.csv\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba225c-14bd-4941-8fa0-a68fe7f5fe6f",
   "metadata": {},
   "source": [
    "데이터를 다운로드하고 추출한 후 아래와 같이 일부 예제를 탐색할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5369b9a2-c6f8-46ce-9b98-9451817be488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86110</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Oracle to drop PeopleSoft suit if tender fails</td>\n",
       "      <td>Oracle Corp. notified Delaware's Court of Chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74390</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>NTT DoCoMo, IBM, Intel team to secure mobile d...</td>\n",
       "      <td>With an eye towards making mobile devices and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77491</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Election Is Crunch Time for U.S. Secret Service</td>\n",
       "      <td>With just days to go before the U.S. president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27497</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Former Celtic striker Larsson on Barcelona bench</td>\n",
       "      <td>Henrik Larsson was left on the bench by Barcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47492</th>\n",
       "      <td>World</td>\n",
       "      <td>Four Suicides Linked to Child Porn Probe (AP)</td>\n",
       "      <td>AP - The government will press on with a child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CATEGORY                                              TITLE  \\\n",
       "86110  Sci/Tech     Oracle to drop PeopleSoft suit if tender fails   \n",
       "74390  Sci/Tech  NTT DoCoMo, IBM, Intel team to secure mobile d...   \n",
       "77491  Sci/Tech    Election Is Crunch Time for U.S. Secret Service   \n",
       "27497    Sports   Former Celtic striker Larsson on Barcelona bench   \n",
       "47492     World      Four Suicides Linked to Child Porn Probe (AP)   \n",
       "\n",
       "                                                 CONTENT  \n",
       "86110  Oracle Corp. notified Delaware's Court of Chan...  \n",
       "74390  With an eye towards making mobile devices and ...  \n",
       "77491  With just days to go before the U.S. president...  \n",
       "27497  Henrik Larsson was left on the bench by Barcel...  \n",
       "47492  AP - The government will press on with a child...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"CATEGORY\", \"TITLE\", \"CONTENT\"]\n",
    "# we use the train.csv only\n",
    "df = pd.read_csv(f\"{local_dir}/train/train.csv\", names=column_names, header=None, delimiter=\",\")\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1, random_state=1337)\n",
    "\n",
    "# Make the (1-indexed) category classes more readable:\n",
    "class_names = [\"Other\", \"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "idx2label = {ix: name for ix, name in enumerate(class_names)}\n",
    "label2idx = {name: ix for ix, name in enumerate(class_names)}\n",
    "\n",
    "df = df.replace({\"CATEGORY\": idx2label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f56818-09f1-48fc-bd5b-21530e7ef9c5",
   "metadata": {},
   "source": [
    "이 연습에서 우리는 **다음만 사용할 것입니다**:\n",
    "\n",
    "- 뉴스 기사의 **제목**(헤드라인)을 입력으로 사용합니다.\n",
    "- **카테고리**를 예측할 대상 변수로 사용합니다.\n",
    "\n",
    "이 데이터셋에는 아래와 같이 4개의 고르게 분포된 주제 클래스가 포함되어 있습니다.\n",
    "\n",
    "> ℹ️ **'기타'에 대해:** 원시 데이터셋은 1-4의 숫자로 카테고리를 나타내고, 모델은 0부터 시작하는 숫자를 기대하므로, 데이터 준비를 단순하게 유지하고 클래스의 추가적이고 혼란스러운 숫자 표현을 도입하지 않기 위해 사용되지 않은 '기타' 클래스를 삽입했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a70b377-ee49-4780-8b32-57db4ee149ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sci/Tech    30000\n",
       "Sports      30000\n",
       "World       30000\n",
       "Business    30000\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628acab-0b0b-4b77-9800-8dc154c55249",
   "metadata": {},
   "source": [
    "## 훈련 매개변수 정의하기\n",
    "\n",
    "우리는 [Hugging Face Hub](https://huggingface.co/models)에서 (비교적 작은) 사전 훈련된 모델을 미세 조정할 것이며, 낮은 수준의 훈련 루프를 처음부터 작성하는 대신 높은 수준의 [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)를 사용할 것입니다.\n",
    "\n",
    "아래에서 훈련을 위한 기본 매개변수를 설정할 것입니다.\n",
    "\n",
    "> 🏎️ 이 노트북 내 예제의 경우 기본적으로 **저비용, CPU 전용 컴퓨팅**을 사용할 것입니다. 우리가 훈련하는 모델은 현대 LLM 표준에 비해 \"작은\" 모델이지만, 합리적인 시간 내에 완료될 수 있도록 훈련을 매우 일찍 중단해야 할 것입니다.\n",
    ">\n",
    "> 결과적으로 생성된 모델은 매우 부족하게 훈련되며, 동일한 아키텍처가 궁극적으로 얻을 수 있는 것보다 훨씬 덜 정확할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c772a2-b9f1-4908-b7e0-07e162933fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"amazon/bort\"  # ID of the pre-trained model to start from\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"{local_dir}/model\",  # Where to save trained model snapshots\n",
    "    #logging_dir=f\"{local_dir}/local-logs\",  # Optionally, save logs too\n",
    "    max_steps=500,  # Maximum number of training steps to run\n",
    "    num_train_epochs=3,  # Maximum number of times to loop through the training data\n",
    "    per_device_train_batch_size=16,  # Examples per mini-batch for training\n",
    "    per_device_eval_batch_size=32,  # Examples per mini-batch for validation\n",
    "    evaluation_strategy=\"steps\",  # Run validation every N 'steps' instead of every 'epoch'\n",
    "    eval_steps=100,  # Number of training steps between validation runs\n",
    "    save_strategy=\"steps\",  # Must be same as evaluation_strategy when load_best_model_at_end=True\n",
    "    load_best_model_at_end=True,  # If current model at end is not the best, load the best\n",
    "    metric_for_best_model=\"f1\",  # Use F1 score for judging which model is 'best'\n",
    "    learning_rate=5e-5,  # Initial learning rate (decays over time by default)\n",
    "    warmup_steps=100,  # Number of steps to gradually increase the learning rate from the start\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37d97-07f7-4985-8b6a-19aa751d1ab4",
   "metadata": {},
   "source": [
    "## 지표 정의하기\n",
    "\n",
    "여기서는 모델이 검증될 때마다 실행될 [콜백 함수](https://huggingface.co/docs/transformers/main_classes/callback)를 설정하여 훈련된 모델의 품질을 측정하고자 하는 방법을 정의할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca817667-2bb8-4098-9840-466d42a13d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2df25-93e0-4f15-89de-844b291d6862",
   "metadata": {},
   "source": [
    "## 모델 훈련 및 검증하기\n",
    "\n",
    "이 섹션에서는 기본 모델과 데이터셋을 로드하고 실제 훈련 및 검증 프로세스를 실행할 것입니다.\n",
    "\n",
    "먼저, 주어진 `model_id`에 대한 사전 훈련된 모델과 함께 제공되는 [토크나이저](https://huggingface.co/docs/transformers/main_classes/tokenizer)를 로드해야 합니다. 이는 Hugging Face Hub에서 자동으로 다운로드됩니다.\n",
    "\n",
    "모델을 설정하는 과정에서 미세 조정할 주제 클래스의 수를 지정하고 사람이 읽을 수 있는 이름을 설정해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f351c2e7-70ee-4d02-8b28-b1792073b8df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabf08db8a60474892eabc3feee6212c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2036b15daa484a088e3bf4bec46d6d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a1c2187870433498b7c406155f79e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494a261e956143b383deb0443a386800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6715ecae73b2405dba02f67a9fad2147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec650ecdd2014ac49071ca9a55c42db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(class_names))\n",
    "model.config.label2id = label2idx\n",
    "model.config.id2label = idx2label\n",
    "\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabbc33-4f7a-4591-82d2-ec0b07bcb1d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "데이터셋에 이미 제공된 원시 `train.csv` 및 `test.csv` 파일을 훈련의 입력으로 사용할 것이지만, 먼저 일부 사전 처리를 설정해야 합니다:\n",
    "\n",
    "- CSV에 열 헤더가 없기 때문에 `column_names`를 수동으로 지정해야 합니다.\n",
    "- `tokenizer`는 모델이 기대하는 (숫자) 입력으로 원시 텍스트를 변환합니다. 여기에는 모델에서 지원하는 최대 길이로 긴 헤드라인을 자르는 작업도 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9610050f-63d8-43d1-9037-39e75d8bcf65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8361ef1163b4ec8b8be006d6ac3b669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8933ad0ec92a4fb284dab80caa7ff1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5348c978b2ee4f8199ad9aecae2317c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bebfc5163d45c19579d4da99993dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(batch):\n",
    "    \"\"\"Tokenize and pre-process raw examples for training/validation\"\"\"\n",
    "    result = tokenizer(batch[\"title\"], truncation=True)\n",
    "    result[\"label\"] = batch[\"category\"]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Load the raw datasets:\n",
    "raw_train_dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=os.path.join(local_dir, \"train\", \"train.csv\"),\n",
    "    column_names=[\"category\", \"title\", \"content\"],\n",
    "    split=datasets.Split.ALL,\n",
    ")\n",
    "raw_test_dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=os.path.join(local_dir, \"test\", \"test.csv\"),\n",
    "    column_names=[\"category\", \"title\", \"content\"],\n",
    "    split=datasets.Split.ALL,\n",
    ")\n",
    "\n",
    "# Run the tokenization/pre-processing, keeping only the output fields from preprocess()\n",
    "train_dataset = raw_train_dataset.map(\n",
    "    preprocess, batched=True, batch_size=1000, remove_columns=raw_train_dataset.column_names\n",
    ")\n",
    "test_dataset = raw_test_dataset.map(\n",
    "    preprocess, batched=True, batch_size=1000, remove_columns=raw_test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427526e0-6fb6-45a0-94a0-9bb755a9f9e4",
   "metadata": {},
   "source": [
    "매개변수와 사전 처리된 데이터가 로드되었으므로 이제 모델을 훈련하고 평가할 준비가 되었습니다.\n",
    "\n",
    "> ⏰ **참고:** 기본 `ml.t3.medium` (2 vCPU + 4 GiB RAM) Studio 인스턴스 유형에서 이 프로세스는 완료되기까지 약 20분이 소요됩니다.\n",
    ">\n",
    "> 기다리는 동안 [SageMaker 노트북](Headline%20Classifier%20SageMaker.ipynb)으로 이동하여 이 프로세스가 SageMaker 훈련 작업으로 마이그레이션될 때 어떻게 다를지 탐색할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b077dc-5cb7-4945-885b-cfccd49c25d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 120000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n",
      "  Number of trainable parameters = 76162053\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:19, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.526869</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.451436</td>\n",
       "      <td>0.285921</td>\n",
       "      <td>0.285921</td>\n",
       "      <td>0.285921</td>\n",
       "      <td>0.285921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.378278</td>\n",
       "      <td>0.256842</td>\n",
       "      <td>0.256842</td>\n",
       "      <td>0.256842</td>\n",
       "      <td>0.256842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.283660</td>\n",
       "      <td>0.407237</td>\n",
       "      <td>0.407237</td>\n",
       "      <td>0.407237</td>\n",
       "      <td>0.407237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>1.218112</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.455000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to data/model/checkpoint-500\n",
      "Configuration saved in data/model/checkpoint-500/config.json\n",
      "Model weights saved in data/model/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in data/model/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in data/model/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from data/model/checkpoint-500 (score: 0.455).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 1.31 s, total: 21.9 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create Trainer instance\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()\n",
    "\n",
    "# evaluate model\n",
    "eval_result = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fd733-4aa9-457c-b369-a5cbcde46768",
   "metadata": {},
   "source": [
    "지표에서 볼 수 있듯이 여기서 훈련된 모델은 아마도 매우 정확하지 않을 것이며, 훈련이 종료된 시점에서도 정확도는 여전히 빠르게 증가할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e58b2-f792-46e1-b7a3-7613bb9f3184",
   "metadata": {},
   "source": [
    "## 모델을 추론에 사용하기\n",
    "\n",
    "모델이 훈련되면 새 데이터에 대한 추론에 사용할 준비가 되었습니다.\n",
    "\n",
    "여기서 모델은 이미 훈련 프로세스에서 메모리에 로드되어 있으므로 쉽게 사용할 수 있도록 [Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)으로 감쌀 수 있습니다.\n",
    "\n",
    "아래 셀은 사용자가 자신의 뉴스 헤드라인을 입력하고 모델이 실시간으로 분류할 수 있는 대화형 위젯을 생성합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d658acce-6ba1-401c-bf2a-027c227c4db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea936eab1884e83b96fee6b201182d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='The markets were bullish after news of the merger', continuous_update=False,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부에 따라 device 인덱스 지정\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# 파이프라인 생성 시 device 지정\n",
    "pipe = transformers.pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# pipe = transformers.pipeline(\n",
    "#     task=\"text-classification\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "\n",
    "def classify(text: str) -> dict:\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    print(pipe(text)[0])\n",
    "\n",
    "\n",
    "# Either try out the interactive widget:\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    ),\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1d76f-4a2e-41ab-b498-e3b8c1611e9d",
   "metadata": {},
   "source": [
    "Alternatively, you can call the pipeline direct from code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d11b0acb-f5b9-48b5-b7b3-404ad8158175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'Sports', 'score': 0.3571805953979492}\n"
     ]
    }
   ],
   "source": [
    "classify(\"Retailers are expanding after the recent economic growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba7286-50b7-45e7-9a4c-db5d1ba96bcc",
   "metadata": {},
   "source": [
    "## 검토\n",
    "\n",
    "이 노트북에서는 일반 Jupyter 환경에서 Hugging Face transformers를 사용하여 텍스트 분류 모델을 훈련하는 방법을 보여주었습니다.\n",
    "\n",
    "기본 노트북 컴퓨팅 인프라(`ml.t3.medium`)가 상당히 작았기 때문에 훈련에 오랜 시간이 걸렸고 결과를 탐색할 기회를 얻기 위해 일찍 중단해야 했습니다.\n",
    "\n",
    "- 더 나은 모델을 훈련하기 위해 훈련 에포크/스텝 컷오프를 확장할 수 있지만, 그러면 프로세스가 더 오래 걸릴 것입니다.\n",
    "- Studio 노트북을 더 높은 리소스 인스턴스(아마도 GPU를 사용하여)로 전환할 수 있지만, 그러면 모델을 실제로 훈련하지 않는 시간(예: 데이터 탐색 또는 평가 중)에 추가 리소스가 유휴 상태일 수 있습니다.\n",
    "- 또한 훈련 프로세스에서 시도한 다른 매개변수를 추적하기 위해 실험을 수동으로 기록해야 합니다.\n",
    "\n",
    "다음으로, [SageMaker 노트북](Headline%20Classifier%20SageMaker.ipynb)으로 이동하여 SageMaker 훈련 작업과 엔드포인트 배포가 더 빠른 훈련과 자동 메타데이터 추적을 위해 온디맨드 컴퓨팅을 활용하는 데 어떻게 도움이 되는지 보여줄 것입니다. 이 경우 필요한 것에 대해서만 비용을 지불하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd8642-83b4-4f4a-802c-493470218d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
