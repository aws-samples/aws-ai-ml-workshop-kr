{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 1] Train a Keras Sequential Model\n",
    "\n",
    "본 노트북(notebook)은 SageMaker 상에서 Keras Sequential model을 학습하는 방법을 단계별로 설명합니다. 본 노트북에서 사용한 모델은 간단한 deep CNN(Convolutional Neural Network) 모델로 [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)에 소개된 모델과 동일합니다.\n",
    "- 참고로, 본 모델은 25 epoch 학습 후에 검증셋의 정확도(accuracy)가 약 75%이고 50 epoch 학습 후에 검증셋의 정확도가 약 79% 입니다.\n",
    "- 본 워크샵 과정에서는 시간 관계상 5 epoch까지만 학습합니다. (단, Horovod 기반 분산 학습은 10 epoch까지 학습합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "[CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)은 머신 러닝에서 가장 유명한 데이터셋 중 하나입니다.\n",
    "이 데이터셋은 10개의 다른 클래스로 구성된(클래스당 6,000장) 60,000장의 32x32 픽셀 이미지들로 구성되어 있습니다.\n",
    "아래 그림은 클래스당 10장의 이미지들을 랜덤으로 추출한 결과입니다. \n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)\n",
    "\n",
    "본 실습에서 여러분들은 deep CNN을 학습하여 영상 분류(image classification) 작업을 수행합니다. 다음 노트북들에서\n",
    "여러분들은 File Mode, Pipe Mode와 Horovod 기반 분산 학습(distributed training) 결과를 비교할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "아래 AWS CLI(Command Line Interface) 커맨드를 사용하여 S3(Amazon Simple Storage Service)에 저장된 TFRecord 데이터셋을 여러분의 로컬 노트북 인스턴스로 복사합니다.\n",
    "S3 경로는 `s3://floor28/data/cifar10` 입니다. \n",
    "\n",
    "### TFRecord는 무엇인가요?\n",
    "- Google에서 Tensorflow backend로 모델링 시에 공식적으로 권장하는 binary 포맷입니다.\n",
    "- Tensorflow의 protocol buffer 파일로 직렬화된 입력 데이터가 담겨 있습니다.\n",
    "- 대용량 데이터를 멀티스레딩으로 빠르게 스트리밍할 때 유용합니다. (모든 데이터는 메모리의 하나의 블록에 저장되므로, 입력 파일이 개별로 저장된 경우보다 데이터 로딩에 필요한 시간이 대폭 단축됩니다.)\n",
    "- Example 객체로 구성된 배열의 집합체입니다. (an array of Examples)\n",
    "- 아래 그림은 $m$차원 feautre가 $n$개의 샘플로 구성된 TFRecord 예시입니다.\n",
    "![TFRecord](./images/TFRecord.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://floor28/data/cifar10 ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 스크립트는 모델 학습에 필요한 인자값(arguments)들을 사용합니다. 모델 학습에 필요한 인자값들은 아래와 같습니다.\n",
    "\n",
    "1. `model_dir` - 로그와 체크 포인트를 저장하는 경로\n",
    "2. `train, validation, eval` - TFRecord 데이터셋을 저장하는 경로\n",
    "3. `epochs` - epoch 횟수\n",
    "\n",
    "아래 명령어로 **<font color='red'>SageMaker 관련 API 호출 없이</font>** 로컬 노트북 인스턴스 환경에서 1 epoch만 학습해 봅니다. 참고로, MacBook Pro(15-inch, 2018) 2.6GHz Core i7 16GB 사양에서 2분 20초~2분 40초 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!mkdir -p logs\n",
    "!python training_script/cifar10_keras.py --model_dir ./logs \\\n",
    "                                         --train data/train \\\n",
    "                                         --validation data/validation \\\n",
    "                                         --eval data/eval \\\n",
    "                                         --epochs 1\n",
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue'>본 스크립트는 SageMaker상의 notebook에서 구동하고 있지만, 여러분의 로컬 컴퓨터에서도 python과 jupyter notebook이 정상적으로 인스톨되어 있다면 동일하게 수행 가능합니다.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use TensorFlow Script Mode\n",
    "\n",
    "TensorFlow 버전 1.11 이상에서 Amazon SageMaker Python SDK는 **스크립트 모드(Script mode)**를 지원합니다. 스크립트 모드는 종래 레거시 모드(Legacy mode) 대비 아래 장점들이 있습니다.\n",
    "\n",
    "* 스크립트 모드의 학습 스크립트는 일반적으로 TensorFlow 용으로 작성하는 학습 스크립트와 더 유사하므로 TensorFlow 학습 스크립트를 최소한의 변경으로 실행할 수 있습니다. 따라서, 기존 레거시 모드보다 TensorFlow 학습 스크립트를 수정하는 것이 더 쉽습니다. \n",
    "    - 레거시 모드는 Tensorflow Estimator API를 기반으로 한 아래의 함수들을 반드시 포함해야 합니다.\n",
    "        - 아래 함수들에서 하나의 함수를 만드시 포함해야 합니다.\n",
    "            - `model_fn`: 학습할 모델을 정의합니다,\n",
    "            - `keras_model_fn`: 학습할 tf.keras 모델을 정의합니다.\n",
    "            - `estimator_fn`: 학습할 tf.estimator.Estimator를 정의합니다.\n",
    "        - `train_input_fn`: 학습 데이터 로딩과 전처리를 수행합니다. \n",
    "        - `eval_input_fn`: 검증 데이터의 로딩과 전처리를 수행합니다.\n",
    "        - (Optional) `serving_input_fn`: 예측(prediction) 중에 모델에 전달할 feautre를 정의합니다. 이 함수는 학습시에만 사용되지만, SageMaker 엔드포인트에서 모델을 배포할 때 필요합니다.\n",
    "    - `if __name__ == “__main__”:` 블록을 정의할 수 없어 디버깅이 쉽지 않습니다.\n",
    "    \n",
    "* 스크립트 모드는 Python 2.7-와 Python 3.6-을 지원합니다.\n",
    "\n",
    "* 스크립트 모드는 **Hovorod 기반 분산 학습(distributed training)도 지원**합니다.\n",
    "\n",
    "TensorFlow 스크립트 모드에서 학습 스크립트를 작성하는 방법 및 Tensorflow 스크립트 모드의 estimator와 model 사용법에 대한 자세한 내용은\n",
    "https://sagemaker.readthedocs.io/en/stable/using_tf.html 을 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing your script for training in SageMaker\n",
    "\n",
    "SageMaker 스크립트 모드의 학습 스크립트는 SageMaker 외부에서 실행할 수 있는 학습 스크립트와 매우 유사합니다.\n",
    "SageMaker는 하나의 인자값(argument), model_dir와 로그 및 모델 아티팩트(model artifacts)에 사용되는 S3 경로로 학습 스크립트를 실행합니다.\n",
    "\n",
    "SageMaker 학습 인스턴스에서는 학습의 컨테이너에 S3에 저장된 데이터를 다운로드하여 학습에 활용합니다. 그 때, S3 버킷의 데이터 경로와 컨테이너의 데이터 경로를 컨테이너 환경 변수를 통해 연결합니다.\n",
    "\n",
    "여러분은 다양한 환경 변수를 통해 학습 환경에 대한 유용한 속성들(properties)에 액세스할 수 있습니다.\n",
    "이 스크립트의 경우 `Train, Validation, Eval`이라는 3 개의 데이터 채널을 스크립트로 보냅니다.\n",
    "\n",
    "**`training_script/cifar10_keras.py`에서 스크립트 사본을 생성 후, `training_script/cifar10_keras_sm.py`로 저장하세요.**\n",
    "\n",
    "스크립트 사본을 생성하였다면 단계별로 아래의 작업들을 직접 시도합니다.\n",
    "\n",
    "----\n",
    "### TODO 1.\n",
    "`cifar10_keras_sm.py`파일에서 SageMaker API 환경 변수 SM_CHANNEL_TRAIN, SM_CHANNEL_VALIDATION, SM_CHANNEL_EVAL에서 디폴트 값을 가져오기 위해 train, validation, eval 인수를 수정해 주세요. 환경 변수에 따른 S3 경로와 컨테이너 경로는 아래 표와 같습니다.\n",
    "\n",
    "|  S3 경로  |  환경 변수  |  컨테이너 경로  |\n",
    "| :---- | :---- | :----| \n",
    "|  s3://bucket_name/prefix/train  |  `SM_CHANNEL_TRAIN`  | `/opt/ml/input/data/train`  |\n",
    "|  s3://bucket_name/prefix/validation  |  `SM_CHANNEL_VALIDATION`  | `/opt/ml/input/data/validation`  |\n",
    "|  s3://bucket_name/prefix/eval  |  `SM_CHANNEL_EVAL`  | `/opt/ml/input/data/eval`  |\n",
    "|  s3://bucket_name/prefix/model.tar.gz  |  `SM_MODEL_DIR`  |  `/opt/ml/model`  |\n",
    "|  s3://bucket_name/prefix/output.tar.gz  |  `SM_OUTPUT_DATA_DIR`  |  `/opt/ml/output/data`  |\n",
    "\n",
    "얘를 들어, `/opt/ml/input/data/train`은 학습 데이터가 다운로드되는 컨테이너 내부의 디렉토리입니다.\n",
    "\n",
    "자세한 내용은 아래의 SageMaker Python SDK 문서를 확인하시기 바랍니다.<br>\n",
    "(https://sagemaker.readthedocs.io/en/stable/using_tf.html#preparing-a-script-mode-training-script)\n",
    "\n",
    "\n",
    "SageMaker는 train, validation, eval 경로들을 직접 인자로 보내지 않고, 대신 스크립트에서 환경 변수를 사용하여 해당 인자를 필요하지 않은 것으로 표시합니다.\n",
    "\n",
    "SageMaker는 유용한 환경 변수를 여러분이 작성한 학습 스크립트로 보냅니다. 예시들은 아래와 같습니다.\n",
    "* `SM_MODEL_DIR`: 학습 작업이 모델 아티팩트(model artifacts)를 저장할 수 있는 로컬 경로를 나타내는 문자열입니다. 학습 완료 후, 해당 경로 내 모델 아티팩트는 모델 호스팅을 위해 S3에 업로드됩니다. 이는 S3 위치인 학습 스크립트에 전달 된 model_dir 인수와 다르다는 점을 주의해 주세요. SM_MODEL_DIR은 항상 `/opt/ml/model`로 설정됩니다.\n",
    "* `SM_NUM_GPUS`: 호스트(Host)에서 사용 가능한 GPU 수를 나타내는 정수(integer)입니다.\n",
    "* `SM_OUTPUT_DATA_DIR`: 출력 아티팩트를 저장할 디렉토리의 경로를 나타내는 문자열입니다. 출력 아티팩트에는 체크포인트, 그래프 및 다른 저장용 파일들이 포함될 수 있지만 모델 아티팩트는 포함되지 않습니다. 이 출력 아티팩트들은 압축되어 모델 아티팩트와 동일한 접두사가 있는 S3 버킷으로 S3에 업로드됩니다.\n",
    "\n",
    "이 샘플 코드는 네트워크 지연을 줄이기 위해 모델의 체크포인트(checkpoints)를 로컬 환경에 저장합니다. 이들은 학습 종료 후 S3에 업로드할 수 있습니다.\n",
    "\n",
    "----\n",
    "### TODO 2.\n",
    "\n",
    "`cifar10_keras_sm.py`의 `if __name__ == '__main__':` 블록 내에 아래 인자값을 추가해 주세요.\n",
    "\n",
    "```python\n",
    "parser.add_argument(\n",
    "        '--model_output_dir',\n",
    "        type=str,\n",
    "        default=os.environ.get('SM_MODEL_DIR'))\n",
    "```\n",
    "\n",
    "----\n",
    "### TODO 3.\n",
    "`ModelCheckpoint` 함수의 저장 경로를 새 경로로 아래와 같이 수정해 주세요.\n",
    "\n",
    "From:\n",
    "```python\n",
    "callbacks.append(ModelCheckpoint(args.model_dir + '/checkpoint-{epoch}.h5'))\n",
    "```\n",
    "To:\n",
    "```python\n",
    "callbacks.append(ModelCheckpoint(args.model_output_dir + '/checkpoint-{epoch}.h5'))\n",
    "```\n",
    "\n",
    "----\n",
    "### TODO 4.\n",
    "`save_model` 함수의 인자값을 아래와 같이 수정해 주세요.\n",
    "\n",
    "From:  \n",
    "```python\n",
    "return save_model(model, args.model_dir)\n",
    "```\n",
    "To:  \n",
    "```python\n",
    "return save_model(model, args.model_output_dir)\n",
    "```\n",
    "\n",
    "<font color='blue'>**본 노트북 실습에 어려움이 있다면 솔루션 파일 `training_script/cifar10_keras_sm_solution.py`을 참조하시면 됩니다.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your script locally (just like on your laptop)\n",
    "\n",
    "테스트를 위해 위와 동일한 명령(command)으로 새 스크립트를 실행하고, 예상대로 실행되는지 확인합니다. <br>\n",
    "SageMaker TensorFlow API 호출 시에 환경 변수들은 자동으로 넘겨기지만, 로컬 주피터 노트북에서 테스트 시에는 수동으로 환경 변수들을 지정해야 합니다. (아래 예제 코드를 참조해 주세요.)\n",
    "\n",
    "```python\n",
    "%env SM_MODEL_DIR=./logs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!mkdir -p logs   \n",
    "\n",
    "# Number of GPUs on this machine\n",
    "%env SM_NUM_GPUS=1\n",
    "# Where to save the model\n",
    "%env SM_MODEL_DIR=./logs\n",
    "# Where the training data is\n",
    "%env SM_CHANNEL_TRAIN=data/train\n",
    "# Where the validation data is\n",
    "%env SM_CHANNEL_VALIDATION=data/validation\n",
    "# Where the evaluation data is\n",
    "%env SM_CHANNEL_EVAL=data/eval\n",
    "\n",
    "!python training_script/cifar10_keras_sm.py --model_dir ./logs --epochs 1\n",
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SageMaker local for local testing\n",
    "\n",
    "본격적으로 학습을 시작하기 전에 로컬 모드를 사용하여 디버깅을 먼저 수행합니다. 로컬 모드는 학습 인스턴스를 생성하는 과정이 없이 로컬 인스턴스로 컨테이너를 가져온 후 곧바로 학습을 수행하기 때문에 코드를 보다 신속히 검증할 수 있습니다.\n",
    "\n",
    "Amazon SageMaker Python SDK의 로컬 모드는 TensorFlow 또는 MXNet estimator서 단일 인자값을 변경하여 CPU (단일 및 다중 인스턴스) 및 GPU (단일 인스턴스) SageMaker 학습 작업을 에뮬레이션(enumlate)할 수 있습니다. 이를 위해 Docker compose와 NVIDIA Docker를 사용합니다.\n",
    "학습 작업을 시작하기 위해 `estimator.fit() ` 호출 시, Amazon ECS에서 Amazon SageMaker TensorFlow 컨테이너를 로컬 노트북 인스턴스로 다운로드합니다.\n",
    "\n",
    "로컬 모드의 학습을 통해 여러분의 코드가 현재 사용 중인 하드웨어를 적절히 활용하고 있는지 확인하기 위한 GPU 점유와 같은 지표(metric)를 쉽게 모니터링할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sagemaker.tensorflow` 클래스를 사용하여 SageMaker Python SDK의 Tensorflow Estimator 인스턴스를 생성합니다.\n",
    "인자값으로 하이퍼파라메터와 다양한 설정들을 변경할 수 있습니다.\n",
    "\n",
    "자세한 내용은 [documentation](https://sagemaker.readthedocs.io/en/stable/using_tf.html#training-with-tensorflow-estimator)을 확인하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.14.0',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       hyperparameters={'epochs' : 1},\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 수행할 3개의 채널과 데이터의 경로를 지정합니다. **로컬 모드로 수행하기 때문에 S3 경로 대신 노트북 인스턴스의 경로를 지정하시면 됩니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit({'train': 'file://data/train',\n",
    "               'validation': 'file://data/validation',\n",
    "               'eval': 'file://data/eval'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator가 처음 실행될 때 Amazon ECR 리포지토리(repository)에서 컨테이너 이미지를 다운로드해야 하지만 학습을 즉시 시작할 수 있습니다. 즉, 별도의 학습 클러스터가 프로비저닝 될 때까지 기다릴 필요가 없습니다. 또한 반복 및 테스트시 필요할 수 있는 후속 실행에서 MXNet 또는 TensorFlow 스크립트에 대한 수정 사항이 즉시 실행되기 시작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SageMaker for faster training time\n",
    "\n",
    "이번에는 로컬 모드를 사용하지 않고 SageMaker 학습에 GPU 학습 인스턴스를 생성하여 학습 시간을 단축해 봅니다.<br>\n",
    "로컬 모드와 다른 점들은 (1) `train_instance_type`이 로컬 모드의 ‘local’ 대신 여러분이 원하는 특정 인스턴스 유형으로 설정해야 하고, (2) 학습 데이터를 Amazon S3에 업로드 후 학습 경로를 S3 경로로 설정해야 합니다. \n",
    "\n",
    "SageMaker SDK는 S3 업로드를 위한 간단한 함수(`Session.upload_data()`)를 제공합니다. 이 함수를 통해 리턴되는 값은 데이터가 저장된 S3 경로입니다.\n",
    "좀 더 자세한 설정이 필요하다면 SageMaker SDK 대신 boto3를 사용하시면 됩니다.\n",
    "\n",
    "*[Note]: 고성능 워크로드를 위해 Amazon EFS와 Amazon FSx for Lustre도 지원하고 있습니다. 자세한 정보는 아래의 AWS 블로그를 참조해 주세요.<br>\n",
    "https://aws.amazon.com/blogs/machine-learning/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-cifar10')\n",
    "display(dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3에 데이터 업로드를 완료했다면, Estimator를 새로 생성합니다. <br>\n",
    "아래 코드를 그대로 복사 후에 `train_instance_type='local'`을 `train_instance_type='ml.p2.xlarge'`로 수정하고\n",
    "`hyperparameters={'epochs': 1}`를 `hyperparameters={'epochs': 5}`로 수정합니다.\n",
    "\n",
    "```python\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.14.0',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,                       \n",
    "                       hyperparameters={'epochs': 1},\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type='local')\n",
    "```\n",
    "\n",
    "*[Note] \n",
    "2019년 8월부터 SageMaker에서도 학습 인스턴스에 EC2 spot instance를 사용하여 비용을 크게 절감할 수 있습니다. 자세한 정보는 아래의 AWS 블로그를 참조해 주세요.<br>\n",
    "https://aws.amazon.com/ko/blogs/korea/managed-spot-training-save-up-to-90-on-your-amazon-sagemaker-training-jobs/*\n",
    "\n",
    "만약 Managed Spot Instance로 학습하려면 다음 코드를 Estimator의 train_instance_type의 다음 행에 추가해 주세요.\n",
    "```python\n",
    "train_max_run = 3600,\n",
    "train_use_spot_instances = 'True',\n",
    "train_max_wait = 3600,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.14.0',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,                       \n",
    "                       hyperparameters={'epochs': 5},\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 수행합니다. 이번에는 각각의 채널(`train, validation, eval`)에 S3의 데이터 저장 위치를 지정합니다.<br>\n",
    "학습 완료 후 Billable seconds도 확인해 보세요. Billable seconds는 실제로 학습 수행 시 과금되는 시간입니다.\n",
    "```\n",
    "Billable seconds: <time>\n",
    "```\n",
    "\n",
    "참고로, `ml.p2.xlarge` 인스턴스로 5 epoch 학습 시 전체 6분~7분이 소요되고, 실제 학습에 소요되는 시간은 3분~4분이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "              'eval':'{}/eval'.format(dataset_location)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**잘 하셨습니다.** \n",
    "\n",
    "SageMaker에서 GPU 인스턴스를 사용해 5 epoch를 정상적으로 학습할 수 있었습니다.<br>\n",
    "다음 노트북으로 계속 진행하기 전에 SageMaker 콘솔의 Training jobs 섹션을 살펴보고 여러분이 수행한 job을 찾아 configuration을 확인하세요.\n",
    "\n",
    "스크립트 모드 학습에 대한 자세한 내용은 아래의 AWS 블로그를 참조해 주세요.<br>\n",
    "[Using TensorFlow eager execution with Amazon SageMaker script mode](https://aws.amazon.com/ko/blogs/machine-learning/using-tensorflow-eager-execution-with-amazon-sagemaker-script-mode/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
