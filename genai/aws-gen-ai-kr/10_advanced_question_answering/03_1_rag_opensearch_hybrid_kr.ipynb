{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d8ea21-3477-4e3d-ad9e-0944aa956a13",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OpenSearch Hybrid 검색을 통한 RAG\n",
    "> 이 노트북은  SageMaker Studio* **`Data Science 3.0`** kernel 및 ml.t3.medium 인스턴스에서 테스트 되었습니다.\n",
    "---\n",
    "### 중요\n",
    "- 이 노트북은 Anthropic 의 Claude-v2 모델 접근 가능한 분만 실행 가능합니다. \n",
    "- 접근이 안되시는 분은 노트북의 코드와 결과 만을 확인 하시면 좋겠습니다.\n",
    "- 만일 실행시에는 **\"과금\"** 이 발생이 되는 부분 유념 해주시기 바랍니다.\n",
    "\n",
    "### 선수조건\n",
    "- 이 노트북은 이전 노트북인 \"02_1_KR_RAG_OpenSearch_Keyword.ipynb\" 이 완료 되었다고 가정 합니다.\n",
    "    - 오픈서치 인텍스 관련 정보를 참조 합니다.\n",
    "\n",
    "### Methods and Resources for Hybrid search with Re-ranking \n",
    "- Score Normalization\n",
    "    - [MinMax based](https://towardsdatascience.com/text-search-vs-vector-search-better-together-3bd48eb6132a)\n",
    "    - [z-socre based](https://towardsdatascience.com/hybrid-search-2-0-the-pursuit-of-better-search-ce44d6f20c08)\n",
    "- Reciprocal Rank Fusion (RRF)\n",
    "    - [Paper](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)\n",
    "    - [Description](https://medium.com/@sowmiyajaganathan/hybrid-search-with-re-ranking-ff120c8a426d)\n",
    "- [LangChain API for Ensemble Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44d5e2-9a9b-442d-837b-9f11a04abc83",
   "metadata": {},
   "source": [
    "### 설정\n",
    "\n",
    "이 노트북의 나머지 부분을 실행하기 전에 아래 셀을 실행하여 (필요한 라이브러리가 설치되어 있는지 확인하고) Bedrock에 연결해야 합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "opensearch = boto3.client('opensearch', region)\n",
    "\n",
    "%store -r opensearch_user_id opensearch_user_password domain_name opensearch_domain_endpoint\n",
    "\n",
    "try:\n",
    "    opensearch_user_id\n",
    "    opensearch_user_password\n",
    "    domain_name\n",
    "    opensearch_domain_endpoint\n",
    "   \n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Run 00_setup notebook first or Create Your Own OpenSearch Domain\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f02e5a4-7de5-4eb2-abb2-37e2c4036295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffeb0e6-b8ce-4fc0-8371-cad833146d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8e72e-d6bc-4a0a-b7f5-99abfd674a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9f671-0306-4960-b532-25647ce64d97",
   "metadata": {},
   "source": [
    "# 2. Titan Embedding 및 LLM 인 Claude-v2 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171f58d-fc04-408b-9ca5-e25e0f916929",
   "metadata": {},
   "source": [
    "## LLM 로딩 (Claude-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b497a63-128c-4c7c-96ac-6f266c3bbd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6afc9a-0502-40cd-be9e-7b3151f3ad71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - create the Anthropic Model\n",
    "llm_text = Bedrock(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V2\"),\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 512\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0867f-4a42-49b3-9801-d169bb176918",
   "metadata": {},
   "source": [
    "## Embedding 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19277289-b417-467a-bfdf-9c710cc7f0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import KoSimCSERobertaContentHandler, SagemakerEndpointEmbeddingsJumpStart\n",
    "\n",
    "def get_embedding_model(is_bedrock_embeddings, is_KoSimCSERobert, aws_region, endpont_name=None):\n",
    "    if is_bedrock_embeddings:\n",
    "\n",
    "        # We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "        from langchain.embeddings import BedrockEmbeddings\n",
    "        llm_emb = BedrockEmbeddings(\n",
    "            client=boto3_bedrock,\n",
    "            model_id=bedrock_info.get_model_id(\n",
    "                model_name=\"Titan-Embeddings-G1\"\n",
    "            )\n",
    "        )\n",
    "        print(\"Bedrock Embeddings Model Loaded\")\n",
    "\n",
    "    elif is_KoSimCSERobert:\n",
    "        LLMEmbHandler = KoSimCSERobertaContentHandler()\n",
    "        endpoint_name_emb = endpont_name\n",
    "        llm_emb = SagemakerEndpointEmbeddingsJumpStart(\n",
    "            endpoint_name=endpoint_name_emb,\n",
    "            region_name=aws_region,\n",
    "            content_handler=LLMEmbHandler,\n",
    "        )        \n",
    "        print(\"KoSimCSERobert Embeddings Model Loaded\")\n",
    "    else:\n",
    "        llm_emb = None\n",
    "        print(\"No Embedding Model Selected\")\n",
    "    \n",
    "    return llm_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456492cc-edee-4ad9-ac14-bee9f24109f6",
   "metadata": {},
   "source": [
    "#### [중요] is_KoSimCSERobert == True 일시에 endpoint_name 을 꼭 넣어 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548af020-92ad-48d2-bf2d-773e3fb98398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_bedrock_embeddings = True\n",
    "is_KoSimCSERobert = False\n",
    "\n",
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "\n",
    "##############################\n",
    "# Parameters for is_KoSimCSERobert\n",
    "##############################\n",
    "if is_KoSimCSERobert: endpont_name = \"<endpoint-name>\"\n",
    "else: endpont_name = None\n",
    "##############################\n",
    "\n",
    "llm_emb = get_embedding_model(is_bedrock_embeddings, is_KoSimCSERobert, aws_region, endpont_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32bac51-d495-44a6-8c8e-10b62c4780e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. LangChain OpenSearch VectorStore 생성 \n",
    "## 선수 조건\n",
    "- 이전 노트북 02_1_KR_RAG_OpenSearch_Keyword.ipynb 또는 02_1_KR_RAG_OpenSearch_Semantic.ipynb를 통해서 OpenSearch Index 가 생성이 되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33dd908-116d-4726-bd40-b473216f169c",
   "metadata": {},
   "source": [
    "## 오픈 서치 도메인 및 인증 정보 세팅\n",
    "\n",
    "- [langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1be0a-aefc-46f6-827f-2f711a262f0e",
   "metadata": {},
   "source": [
    "#### [중요] 02_1_rag_opensearch_lexical_kr.ipynb를 통해 opensearch의 \"genai-demo-index-v1-with-tokenizer\" 인덱스가 생성되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600464b-0e54-4e4b-be13-12fdcecee02c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "http_auth = (opensearch_user_id, opensearch_user_password) # Master username, Master password\n",
    "index_name = \"genai-demo-index-v1-with-tokenizer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c0cbc-547a-4f1c-80a2-de30149641a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LangChain OpenSearch VectorStore 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a97a8d-0949-4a72-a0b9-c83003cfbd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "vector_db = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    "    is_aoss =False,\n",
    "    engine=\"faiss\",\n",
    "    space_type=\"l2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb9b0f-b62b-412a-a6dd-351e23d93cea",
   "metadata": {},
   "source": [
    "## OpenSearch Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad59ce-768d-49f3-b032-97d2364c66fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.opensearch import opensearch_utils\n",
    "os_client = opensearch_utils.create_aws_opensearch_client(\n",
    "    aws_region,\n",
    "    opensearch_domain_endpoint,\n",
    "    http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c17e66-f19f-4260-adbe-42ef3751cd18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 형태소 분석기 (nori_tokenizer) 사용하기 in Opensearch\n",
    "- 형태소 분석기에 대한 자세한 사항은 02_1_KR_RAG_OpenSearch_Keyword.ipynb 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bf7b7-d003-46d5-b3b7-bdde9ad5191e",
   "metadata": {},
   "source": [
    "### 인덱스 확인 (tokenization 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4620e-0720-4d04-96f9-828888ffa9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_info = os_client.indices.get(index=index_name)\n",
    "pprint(index_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8087c-8285-469d-af4b-e0f0afb7e95a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. 오픈 서치에 \"유사 서치\" 검색\n",
    "- query 를 제공해서 실제로 유사한 내용이 검색이 되는지를 확인 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507daa4-7642-4288-9c87-df37d54958b0",
   "metadata": {},
   "source": [
    "- similarity_search_with_score API 정보\n",
    "    - [API: similarity_search_with_score](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch.html#langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch.similarity_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab42354-7478-4d4b-9f07-782ba701617f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from langchain.schema import Document\n",
    "from langchain import PromptTemplate\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d67b3b-0e7f-427e-b7e6-9bcbce12fe4e",
   "metadata": {},
   "source": [
    "## (1) OpenSearch Vector 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54c091-f018-47ed-b1eb-d7c31a1f9343",
   "metadata": {},
   "source": [
    "### 프로프트 템플릿 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c11cb-b9a2-4601-b7b3-3b1c119dc6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import run_RetrievalQA, show_context_used\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435c89b-e096-468d-baa2-6d2035458bd6",
   "metadata": {},
   "source": [
    "### [TIP] Prompt의 instruction의 경우 한글보다 **영어**로 했을 때 더 좋은 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6fd51a-ae36-46f3-82be-2a6787d00e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt_template = \"\"\"\n",
    "# \\n\\nHuman: 다음 문맥의 Information을 사용하여 고객 서비스 센터 직원처럼, 마지막 질문에 대한 목차 형식으로 답변을 제공하세요. 응답을 모르면 모른다고 말하고 응답을 만들려고 하지 마세요.\n",
    "\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \\n\\nAssistant:\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "\n",
    "Human: Here is the context, inside <context></context> XML tags.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Only using the contex as above, answer the following question with the rules as below:\n",
    "    - Don't insert XML tag such as <context> and </context> when answering.\n",
    "    - Write as much as you can\n",
    "    - Be courteous and polite\n",
    "    - Only answer the question if you can find the answer in the context with certainty.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "If the answer is not in the context, just say \"주어진 내용에서 관련 답변을 찾을 수 없습니다.\"\n",
    "\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f86f7-9177-4f3b-9931-2056250210e2",
   "metadata": {},
   "source": [
    "### 필터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e47cb1-c213-47a3-bb39-c682db5af4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter01 = \"홈페이지\"\n",
    "# filter01 = \"인증서\"\n",
    "filter02 = \"신한은행\"\n",
    "# filter02 = \"아마존은행\"\n",
    "\n",
    "query = \"어린아이 등록 조건\"\n",
    "# query = \"타기관OTP 등록 방법 알려주세요\"\n",
    "\n",
    "boolean_filter = [\n",
    "    {\"term\": {\"metadata.type\": filter01}},\n",
    "    {\"term\": {\"metadata.source\": filter02}},\n",
    "]\n",
    "\n",
    "pprint(boolean_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf26f0-2a8c-4e2f-9fbb-fb8a5c3bf227",
   "metadata": {},
   "source": [
    "### LangChain RetrievalQA 를 통해 실행\n",
    "- 아래와 같이 top_k = 5 를 실행하면 해당 관련 Context 를 가져오지 못하고 , \"주어진 내용에서 찾을 수 없습니다\" 라고 답변 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef0a3e-ab46-4a6e-b7ad-520781484038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = run_RetrievalQA(\n",
    "    query=query,\n",
    "    boolean_filter=boolean_filter,\n",
    "    llm=llm_text,\n",
    "    prompt=PROMPT,\n",
    "    vector_db=vector_db,\n",
    "    verbose=True,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(\"##################################\")\n",
    "print(\"query: \", query)\n",
    "print(\"boolean_filter: \", boolean_filter)\n",
    "print(\"##################################\")\n",
    "\n",
    "print (colored(\"\\n\\n### Answer ###\", \"blue\"))\n",
    "print_ww(result['result'])\n",
    "\n",
    "print (colored(\"\\n\\n### Contexts ###\", \"green\"))\n",
    "show_context_used(result['source_documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b652850-90b9-4fb3-8fa8-e7f590844ed9",
   "metadata": {},
   "source": [
    "## (2) OpenSearch Keyword 검색\n",
    "- \"minimum_should_match=50\" 세팅을 하고, 관련 컨텍스트를 찾아 오지 못합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1bcb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rag import retriever_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233684b4-70fa-4342-bd58-8ba3d41502a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.opensearch import opensearch_utils\n",
    "#from utils.rag import get_lexical_similar_docs \n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff3cd0-99c9-4e48-9250-3ec1e45f1bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter01 = \"홈페이지\"\n",
    "# filter01 = \"인증서\"\n",
    "filter02 = \"신한은행\"\n",
    "# filter02 = \"아마존은행\"\n",
    "\n",
    "query = \"홈페이지 이용자아이디 여러 개 사용할 수 있나요?\"\n",
    "#query = \"어린아이 등록 조건\"\n",
    "\n",
    "\n",
    "search_keyword_result = retriever_utils.get_lexical_similar_docs(\n",
    "    query=query,\n",
    "    minimum_should_match=25,\n",
    "    filter=[\n",
    "        {\"term\": {\"metadata.type\": filter01}},\n",
    "        {\"term\": {\"metadata.source\": filter02}},\n",
    "    ],\n",
    "    index_name=index_name,\n",
    "    os_client=os_client,\n",
    "    k=5,\n",
    "    hybrid=False\n",
    ")\n",
    "print(search_keyword_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d39ae-0ecf-485c-a1de-bae28674e4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = load_qa_chain(\n",
    "    llm=llm_text,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=PROMPT,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "answer = chain.run(\n",
    "    input_documents=search_keyword_result,\n",
    "    question=query\n",
    ")\n",
    "\n",
    "print(\"##############################\")\n",
    "print(\"query: \\n\", query)\n",
    "print(\"answer: \\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c2835-355a-4ce5-bbdf-64e3b69f3fd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 키워드 검색 결과 (search_keyword_result)\n",
    "bm25 score는 max_value로 normalization 되어 있음 (score range 0 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d287f-2dee-4a01-a7a1-cf39922c5ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_keyword_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67677f4-2e37-44a2-b11f-2ba338651c85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (3) OpenSearch Hybrid 검색\n",
    "- 아래는 결론적으로 query = \"홈페이지 이용자아이디 여러 개 사용할 수 있나요?\" 에 답변을 제공 합니다.\n",
    "    - 시멘티 서치에서 LangChain 의 RetrievalQA 사용 대신에 , LangChain OpenSearch Vector Store의 similarity_search_with_score 를 사용 하여 제일 첫번재에 해당 답변이 검색이 됩니다.\n",
    "    - 키워드 검색에서는 해당 qeury 가 검색이 되지 않습니다.\n",
    "    - 이후에 시멘틱 검색, 키워드 검색에 가중치를 [0.3 , 0.5] 를 주어서 Ensembe 을 하여 랭킹을 하면, top_k = 5 에서 5번재로 Context 로 포함이 되어서 , 최종 검색이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1978e-de8d-41a6-84e1-36c8efdaf7ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenSearch Hybrid 는 아래와 같은 방식으로 작동합니다.\n",
    "- (1) \"Vector 서치\" 하여 스코어를 얻은 후에 표준화를 하여 스코어를 구함. \n",
    "    - 전체 결과에서 가장 높은 스코어는 표준화 과정을 통하여 스코어가 1.0 이 됨.\n",
    "- (2) Keyword 서치도 동일하게 함.\n",
    "- (3) 위의 두 개의 결과에 랭킹 알고리즘 (\"RRF\" 혹은 \"simple_weighted\"] 을 통해, 스코어를 계산하여 정렬하여 제공 함.\n",
    "    - 여기서는 simple_weighted 사용 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08264189-2886-4923-a3da-d0cd94f58d0a",
   "metadata": {},
   "source": [
    "스코어 표준화 예시\n",
    "\n",
    "<pre>\n",
    "Docs    Score\t    Normalized-Score\n",
    "\n",
    "Doc1: \t0.0083\t\t1.0\n",
    "\n",
    "Doc2: \t0.0074\t\t0.8900\n",
    "\n",
    "Doc3: \t0.0071\t\t0.8585\n",
    "\n",
    "Example: 0.0074 / 0.0083 = 0.8900\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf59e1-efb2-4fca-a3dc-47322d31387a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing.pool import ThreadPool\n",
    "#from utils.rag import get_semantic_similar_docs, get_lexical_similar_docs, get_ensemble_results, get_rerank_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e5d94-567f-4a2c-9674-06613e09656e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filter01 = \"홈페이지\"\n",
    "# filter01 = \"인증서\"\n",
    "filter02 = \"신한은행\"\n",
    "# filter02 = \"아마존은행\"\n",
    "\n",
    "query = \"홈페이지 이용자아이디 여러 개 사용할 수 있나요?\"\n",
    "\n",
    "search_hybrid_result = retriever_utils.search_hybrid(\n",
    "    query=query,\n",
    "    llm_emb=llm_emb,\n",
    "    vector_db=vector_db,\n",
    "    k=5,\n",
    "    index_name=index_name,\n",
    "    os_client=os_client,\n",
    "    filter=[\n",
    "        {\"term\": {\"metadata.type\": filter01}},\n",
    "        {\"term\": {\"metadata.source\": filter02}},\n",
    "    ],\n",
    "    fusion_algorithm=\"RRF\", # [\"RRF\", \"simple_weighted\"]\n",
    "    ensemble_weights=[.5, .5], # 시멘트 서치에 가중치 0.5 , 키워드 서치 가중치 0.5 부여.\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "answer = chain.run(\n",
    "    input_documents=search_hybrid_result,\n",
    "    question=query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92313609-5682-45ca-8eeb-8cf87bfb4270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'question: {query}')\n",
    "print(f'response: {answer}')"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
