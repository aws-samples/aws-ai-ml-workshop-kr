{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data preprocessing\n",
    "\n",
    "- 이 단계에서는 데이터 셋을 다운받고, Amazon Translate을 사용해 한국어로 번역한 후 Amazon S3에 저장하는 과정을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\")\n",
    "\n",
    "# 'train' split에서 첫 번째 샘플 출력\n",
    "print(\"전문: \", dataset['train'][0])\n",
    "print(\"#######구분해서 보기######\")\n",
    "sample = dataset['train'][0]\n",
    "print(\"Answer:\", sample['answer'])\n",
    "print(\"Question:\", sample['question'])\n",
    "print(\"Context:\", sample['context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Translate으로 데이터 한국어로 번역하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import boto3\n",
    "\n",
    "# AWS 클라이언트 생성\n",
    "translate = boto3.client(service_name='translate', region_name='us-east-1')\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\")\n",
    "\n",
    "# 'question' 열 추출 및 번역\n",
    "translated_dataset = dataset.map(\n",
    "    lambda sample: {\n",
    "        'answer': sample['answer'],\n",
    "        'question': [\n",
    "            translate.translate_text(Text=question, SourceLanguageCode=\"en\", TargetLanguageCode=\"ko\").get('TranslatedText')\n",
    "            for question in sample['question']\n",
    "        ],\n",
    "        'context': sample['context']\n",
    "    },\n",
    "    batched=True,\n",
    "    desc=\"Translating questions to Korean\"\n",
    ")\n",
    "\n",
    "# 번역된 데이터셋 저장\n",
    "translated_dataset.save_to_disk('data/translated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 번역 완료 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from IPython.display import display\n",
    "\n",
    "# 번역된 데이터셋 불러오기\n",
    "translated_dataset = translated_dataset.load_from_disk('data/translated')\n",
    "\n",
    "# 데이터셋 정보 출력\n",
    "print(translated_dataset)\n",
    "\n",
    "# 샘플 5개 출력\n",
    "for sample in translated_dataset['train']['question'][:5]:\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대화형으로 데이터셋 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "system_message = \"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database.\"\"\"\n",
    "\n",
    "def create_conversation(record):\n",
    "    sample = {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": system_message + f\"\"\"You can use the following table schema for context: {record[\"context\"]}\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Return the SQL query that answers the following question: {record[\"question\"]}\"\"\"},\n",
    "        {\"role\" : \"assistant\", \"content\": f\"\"\"{record[\"answer\"]}\"\"\"}\n",
    "    ]}\n",
    "    return sample\n",
    "\n",
    "dataset = translated_dataset\n",
    "dataset = dataset.map(create_conversation, batched=False).remove_columns(['answer', 'question', 'context'])\n",
    "\n",
    "# 먼저 전체 데이터셋에서 test set을 분리\n",
    "train_val_test_split = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# 남은 데이터에서 train과 validation을 분리\n",
    "train_val_split = train_val_test_split[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# 최종 데이터셋 구성\n",
    "training_data = train_val_split[\"train\"]\n",
    "validation_data = train_val_split[\"test\"]\n",
    "test_data = train_val_test_split[\"test\"]\n",
    "\n",
    "# 각 데이터셋을 JSON 파일로 저장\n",
    "training_data.to_json(\"../datasets/ko_train_dataset.json\", orient=\"records\", force_ascii=False)\n",
    "validation_data.to_json(\"../datasets/ko_validation_dataset.json\", orient=\"records\", force_ascii=False)\n",
    "test_data.to_json(\"../datasets/ko_test_dataset.json\", orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- json으로 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "train_data = []\n",
    "\n",
    "# Load the JSON data line by line\n",
    "with open('../datasets/ko_train_dataset.json', 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            train_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line}\")\n",
    "\n",
    "# Display the first 5 examples\n",
    "for example in train_data[:5]:\n",
    "    display(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "train_data = []\n",
    "\n",
    "# Load the JSON data line by line\n",
    "with open('../datasets/ko_test_dataset.json', 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            train_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line}\")\n",
    "\n",
    "# Display the first 5 examples\n",
    "for example in train_data[:5]:\n",
    "    display(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "train_data = []\n",
    "\n",
    "# Load the JSON data line by line\n",
    "with open('../datasets/ko_validation_dataset.json', 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            train_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping invalid JSON line: {line}\")\n",
    "\n",
    "# Display the first 5 examples\n",
    "for example in train_data[:5]:\n",
    "    display(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3에 데이터 업로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "    \n",
    "# S3 클라이언트 생성\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# 파일 경로와 S3 업로드 경로 설정\n",
    "train_local_file_path = '../datasets/ko_train_dataset.json'\n",
    "train_s3_upload_path = 'data/train/ko_train_dataset.json'\n",
    "\n",
    "validation_local_file_path = '../datasets/ko_validation_dataset.json'\n",
    "validation_s3_upload_path = 'data/validation/ko_validation_dataset.json'\n",
    "\n",
    "test_local_file_path = '../datasets/ko_test_dataset.json'\n",
    "test_s3_upload_path = 'data/test/ko_test_dataset.json'\n",
    "\n",
    "# 파일 업로드 함수\n",
    "def upload_file(local_path, s3_path):\n",
    "    try:\n",
    "        s3_client.upload_file(local_path, sagemaker_session_bucket, s3_path)\n",
    "        print(f\"파일 {local_path}가 {sagemaker_session_bucket}/{s3_path}에 업로드되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"파일 {local_path} 업로드 실패: {e}\")\n",
    "\n",
    "# 파일 업로드\n",
    "upload_file(train_local_file_path, train_s3_upload_path)\n",
    "upload_file(validation_local_file_path, validation_s3_upload_path)\n",
    "upload_file(test_local_file_path, test_s3_upload_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
