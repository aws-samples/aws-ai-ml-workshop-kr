<h1 align="center">Korean Reranker on AWS</h1>
<p align="center">
    <a href="https://github.com/aws-samples">
            <img alt="Build" src="https://img.shields.io/badge/Contribution-Welcome-blue">
    </a>
    <a href="https://github.com/aws-samples/aws-ai-ml-workshop-kr/blob/master/LICENSE">
        <img alt="License" src="https://img.shields.io/badge/LICENSE-MIT-green">
    </a>
    <a href="https://huggingface.co/Dongjin-kr/ko-reranker">
        <img alt="Build" src="https://img.shields.io/badge/KoReranker-ğŸ¤—-yellow">
    </a>
    <a href="https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/30_fine_tune/reranker-kr">
        <img alt="Build" src="https://img.shields.io/badge/KoReranker-1.0-red">
    </a>
</p>

### **í•œêµ­ì–´ Reranker** ê°œë°œì„ ìœ„í•œ **[PyTorch distributed training on SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html)** ê¸°ë°˜ íŒŒì¸íŠœë‹ ê°€ì´ë“œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
ko-rerankerëŠ” [BAAI/bge-reranker-larger](https://huggingface.co/BAAI/bge-reranker-large) ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ë°ì´í„°ì— ëŒ€í•´ fine-tunedëœ model ì…ë‹ˆë‹¤.

- - -

## 0. Features
- #### <span style="#FF69B4;"> RerankerëŠ” ì„ë² ë”© ëª¨ë¸ê³¼ ë‹¬ë¦¬ ì§ˆë¬¸ê³¼ ë¬¸ì„œë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ë©° ì„ë² ë”© ëŒ€ì‹  ìœ ì‚¬ë„ë¥¼ ì§ì ‘ ì¶œë ¥í•©ë‹ˆë‹¤.</span>
- #### <span style="#FF69B4;"> Rerankerì— ì§ˆë¬¸ê³¼ êµ¬ì ˆì„ ì…ë ¥í•˜ë©´ ì—°ê´€ì„± ì ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</span>
- #### <span style="#FF69B4;"> RerankerëŠ” CrossEntropy lossë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”ë˜ë¯€ë¡œ ê´€ë ¨ì„± ì ìˆ˜ê°€ íŠ¹ì • ë²”ìœ„ì— êµ­í•œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</span>

## 1. Usage

- using Transformers
```
    def exp_normalize(x):
      b = x.max()
      y = np.exp(x - b)
      return y / y.sum()
    
    from transformers import AutoModelForSequenceClassification, AutoTokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()
    pairs = [["ë‚˜ëŠ” ë„ˆë¥¼ ì‹«ì–´í•´", "ë‚˜ëŠ” ë„ˆë¥¼ ì‚¬ë‘í•´"], \
             ["ë‚˜ëŠ” ë„ˆë¥¼ ì¢‹ì•„í•´", "ë„ˆì— ëŒ€í•œ ë‚˜ì˜ ê°ì •ì€ ì‚¬ë‘ ì¼ ìˆ˜ë„ ìˆì–´"]]
    with torch.no_grad():
        inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)
        scores = model(**inputs, return_dict=True).logits.view(-1, ).float()
        scores = exp_normalize(scores.numpy())
        print (f'first: {scores[0]}, second: {scores[1]}')
```

- using SageMaker
```
import sagemaker
import boto3
from sagemaker.huggingface import HuggingFaceModel
try:
	role = sagemaker.get_execution_role()
except ValueError:
	iam = boto3.client('iam')
	role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']
# Hub Model configuration. https://huggingface.co/models
hub = {
	'HF_MODEL_ID':'Dongjin-kr/ko-reranker',
	'HF_TASK':'text-classification'
}
# create Hugging Face Model Class
huggingface_model = HuggingFaceModel(
	transformers_version='4.28.1',
	pytorch_version='2.0.0',
	py_version='py310',
	env=hub,
	role=role, 
)
# deploy model to SageMaker Inference
predictor = huggingface_model.deploy(
	initial_instance_count=1, # number of instances
	instance_type='ml.g5.large' # ec2 instance type
)
runtime_client = boto3.Session().client('sagemaker-runtime')
payload = json.dumps(
    {
        "inputs": [
            {"text": "ë‚˜ëŠ” ë„ˆë¥¼ ì‹«ì–´í•´", "text_pair": "ë‚˜ëŠ” ë„ˆë¥¼ ì‚¬ë‘í•´"},
            {"text": "ë‚˜ëŠ” ë„ˆë¥¼ ì¢‹ì•„í•´", "text_pair": "ë„ˆì— ëŒ€í•œ ë‚˜ì˜ ê°ì •ì€ ì‚¬ë‘ ì¼ ìˆ˜ë„ ìˆì–´"}
        ]
    }
)
response = runtime_client.invoke_endpoint(
    EndpointName="<endpoint-name>",
    ContentType="application/json",
    Accept="application/json",
    Body=payload
)
## deserialization
out = json.loads(response['Body'].read().decode()) ## for json
print (f'Response: {out}')
```
- - -

## 2. Backgound
- #### <span style="#FF69B4;"> **ì»¨íƒìŠ¤íŠ¸ ìˆœì„œê°€ ì •í™•ë„ì— ì˜í–¥ ì¤€ë‹¤**([Lost in Middel, *Liu et al., 2023*](https://arxiv.org/pdf/2307.03172.pdf)) </span>

- #### <span style="#FF69B4;"> [Reranker ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì´ìœ ](https://www.pinecone.io/learn/series/rag/rerankers/)</span>
    - í˜„ì¬ LLMì€ context ë§ì´ ë„£ëŠ”ë‹¤ê³  ì¢‹ì€ê±° ì•„ë‹˜, relevantí•œê²Œ ìƒìœ„ì— ìˆì–´ì•¼ ì •ë‹µì„ ì˜ ë§í•´ì¤€ë‹¤
    - Semantic searchì—ì„œ ì‚¬ìš©í•˜ëŠ” similarity(relevant) scoreê°€ ì •êµí•˜ì§€ ì•Šë‹¤. (ì¦‰, ìƒìœ„ ë­ì»¤ë©´ í•˜ìœ„ ë­ì»¤ë³´ë‹¤ í•­ìƒ ë” ì§ˆë¬¸ì— ìœ ì‚¬í•œ ì •ë³´ê°€ ë§ì•„?) 
        * Embeddingì€ meaning behind documentë¥¼ ê°€ì§€ëŠ” ê²ƒì— íŠ¹í™”ë˜ì–´ ìˆë‹¤. 
        * ì§ˆë¬¸ê³¼ ì •ë‹µì´ ì˜ë¯¸ìƒ ê°™ì€ê±´ ì•„ë‹ˆë‹¤. ([Hypothetical Document Embeddings](https://medium.com/prompt-engineering/hyde-revolutionising-search-with-hypothetical-document-embeddings-3474df795af8))
        * ANNs([Approximate Nearest Neighbors](https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6)) ì‚¬ìš©ì— ë”°ë¥¸ íŒ¨ë„í‹°

- - -

## 3. Reranker models

- #### <span style="#FF69B4;"> [Cohere] [Reranker](https://txt.cohere.com/rerank/)</span>
- #### <span style="#FF69B4;"> [BAAI] [bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large)</span>
- #### <span style="#FF69B4;"> [BAAI] [bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)</span>

- - -

## 4. Dataset

- #### <span style="#FF69B4;"> [msmarco-triplets](https://github.com/microsoft/MSMARCO-Passage-Ranking) </span>
    - (Question, Answer, Negative)-Triplets from MS MARCO Passages dataset, 499,184 samples
    - í•´ë‹¹ ë°ì´í„° ì…‹ì€ ì˜ë¬¸ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    - Amazon Translate ê¸°ë°˜ìœ¼ë¡œ ë²ˆì—­í•˜ì—¬ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
    
#### <span style="#FF69B4;"> Format </span>
```
{"query": str, "pos": List[str], "neg": List[str]}
```
- QueryëŠ” ì§ˆë¬¸ì´ê³ , posëŠ” ê¸ì • í…ìŠ¤íŠ¸ ëª©ë¡, negëŠ” ë¶€ì • í…ìŠ¤íŠ¸ ëª©ë¡ì…ë‹ˆë‹¤. ì¿¼ë¦¬ì— ëŒ€í•œ ë¶€ì • í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ ë§ë­‰ì¹˜ì—ì„œ ì¼ë¶€ë¥¼ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí•˜ì—¬ ë¶€ì • í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### <span style="#FF69B4;"> Example </span>
```
{"query": "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?", "pos": ["ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì›Œì‹±í„´ì´ê³ , ì¼ë³¸ì€ ë„êµì´ë©° í•œêµ­ì€ ì„œìš¸ì´ë‹¤."], "neg": ["ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ì›Œì‹±í„´ì´ê³ , ì¼ë³¸ì€ ë„êµì´ë©° ë¶í•œì€ í‰ì–‘ì´ë‹¤."]}
```
    
- - -

## 5. Performance
| Model                     | has-right-in-contexts | mrr (mean reciprocal rank) |
|:---------------------------|:-----------------:|:--------------------------:|
| without-reranker (default)| 0.93 | 0.80 |
| with-reranker (bge-reranker-large)| 0.95 | 0.84 |
| **with-reranker (fine-tuned using korean)** | **0.96** | **0.87** |

- **evaluation set**:
```code
./dataset/evaluation/eval_dataset.csv
```
- **training parameters**: 

```json
{
    "learning_rate": 5e-6,
    "fp16": True,
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 32,
    "train_group_size": 3,
    "max_len": 512,
    "weight_decay": 0.01,
}
```

- - -

## 6. Acknowledgement
- <span style="#FF69B4;"> Part of the code is developed based on [FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding/tree/master?tab=readme-ov-file) and [KoSimCSE-SageMaker](https://github.com/daekeun-ml/KoSimCSE-SageMaker/tree/7de6eefef8f1a646c664d0888319d17480a3ebe5).</span>

- - -

## 7. Citation
- <span style="#FF69B4;"> If you find this repository useful, please consider giving a star â­ and citation</span>

- - -

## 8. Contributors:
- <span style="#FF69B4;"> **Dongjin Jang, Ph.D.** (AWS AI/ML Specislist Solutions Architect) | [Mail](mailto:dongjinj@amazon.com) | [Linkedin](https://www.linkedin.com/in/dongjin-jang-kr/) | [Git](https://github.com/dongjin-ml) | </span>

- - -

## 9. License
- <span style="#FF69B4;"> KoReranker is licensed under the [MIT License](https://github.com/aws-samples/aws-ai-ml-workshop-kr/blob/master/LICENSE). </span>
