# llama3-text2sql-korean

## ğŸ”­ Overview

- ì´ repoì—ëŠ” Amazon Sagemakerë¥¼ ì´ìš©í•´ **llama3-8b ëª¨ë¸**ì„ **í•œêµ­ì–´ í˜¸í™˜ text to sql** ìš©ë„ë¡œ íŒŒì¸ íŠœë‹í•˜ëŠ” ì˜ˆì œë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

- Amazon Bedrock Imported Modelsì— íŒŒì¸ íŠœë‹ì„ ì™„ë£Œí•œ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë°©ì‹ë„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê°œë°œ í™˜ê²½

- Amazon Sagemaker Notebook instance (ml.t3.medium)
- `conda_pytorch_p310` ì´ìš©
- Amazon Bedrock Imported Models ì´ìš© ì¶”ë¡ 

### ì‚¬ìš© ëª¨ë¸ ë° ë°ì´í„° ì…‹

- ì‚¬ìš© ëª¨ë¸: [Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)
- ì‚¬ìš© ë°ì´í„° ì…‹: [b-mc2/sql-create-context](https://huggingface.co/datasets/b-mc2/sql-create-context)

#### ë°ì´í„° ì…‹ ì˜ˆì‹œ

```
Answer: SELECT COUNT(*) FROM head WHERE age > 56
Question: How many heads of the departments are older than 56 ?
Context: CREATE TABLE head (age INTEGER)
```

- Amazon Translate ì´ìš©í•˜ì—¬ user questionì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ í›„ ì‚¬ìš©

#### ë²ˆì—­ ë° ì „ì²˜ë¦¬ ì˜ˆì‹œ

```
{"messages":[{"content":"You are a powerful text-to-SQL model. Your job is to answer questions about a database.You can use the following table schema for context: CREATE TABLE table_name_52 (bronze VARCHAR, rank VARCHAR, total VARCHAR, nation VARCHAR)","role":"system"},{"content":"Return the SQL query that answers the following question: ì´ í•©ê³„ê°€ 3ë³´ë‹¤ ì‘ê³  í´ë€ë“œ êµ­ê°€ì´ê³  ìˆœìœ„ê°€ 4ë³´ë‹¤ í° ë¸Œë¡ ì¦ˆì˜ ì´ê³„ëŠ” ì–¼ë§ˆì…ë‹ˆê¹Œ?","role":"user"},{"content":"SELECT COUNT(bronze) FROM table_name_52 WHERE total < 3 AND nation = \"poland\" AND rank > 4","role":"assistant"}]}

```

## ğŸ’» ì‹¤í–‰ ì•ˆë‚´

> ì´ ë ˆí¬ì§€í† ë¦¬ëŠ” ì‹¤ìŠµìš©, í”„ë¡œë•ì…˜ìš© ì—ì…‹ì„ ì „ë¶€ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. use caseì— ë§ì¶° ì•„ë˜ ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.

### Option 1 - ì‹¤ìŠµìš© 3200ê°œ ìƒ˜í”Œ ë°ì´í„°ì…‹ ì´ìš©

- ì‹¤í–‰ ì†Œìš” ì‹œê°„: ì•½ 1ì‹œê°„ 30ë¶„ (ë°ì´í„° ì „ì²˜ë¦¬ 5ë¶„, íŒŒì¸ íŠœë‹ 35ë¶„, Amazon Bedrock Imported Model ì…‹ì—… 15ë¶„, evaluation ì‹¤í–‰)
- ì‹¤í–‰ ìˆœì„œ:
  1. [0_setup.ipynb](./notebook/0_setup.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤.
  2. [1_data_preprocessing.ipynb](./notebook/1_data_preprocessing.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ 3200ê°œì˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
  3. [2_fine_tuning.ipynb](./notebook/2_fine_tuning.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ íŒŒì¸ íŠœë‹í•©ë‹ˆë‹¤.
  4. [3_deploy.ipynb](./notebook/3_deploy.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ Amazon Bedrockì— ë°°í¬í•©ë‹ˆë‹¤.
  5. [4_evaluation.ipynb](./notebook/4_evaluation.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

### Option 2 - í”„ë¡œë•ì…˜ìš© 78577ê°œ ì „ì²´ ë°ì´í„°ì…‹ ì´ìš©

- ì‹¤í–‰ ì†Œìš” ì‹œê°„: ì•½ 12ì‹œê°„ (ë°ì´í„° ì „ì²˜ë¦¬ 3ì‹œê°„, íŒŒì¸ íŠœë‹ 8ì‹œê°„, Amazon Bedrock Imported Model ì…‹ì—… 15ë¶„, evaluation ì‹¤í–‰)
- ì‹¤í–‰ ìˆœì„œ:
  1. [0_setup.ipynb](./notebook/0_setup.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤.
  2. [1-1_full_data_preprocessing.ipynb](./notebook/1-1_full_data_preprocessing.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ 78577ê°œì˜ ì „ì²´ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
  3. [2_fine_tuning.ipynb](./notebook/2_fine_tuning.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ íŒŒì¸ íŠœë‹í•©ë‹ˆë‹¤.
  4. [3_deploy.ipynb](./notebook/3_deploy.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ Amazon Bedrockì— ë°°í¬í•©ë‹ˆë‹¤.
  5. [4_evaluation.ipynb](./notebook/4_evaluation.ipynb) ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

### ì‹¤ìŠµ ë¹„ìš©

> âš ï¸ ì£¼ì˜: ì‹¤ì œ ë¹„ìš©ì€ **ì‚¬ìš© ì‹œê°„**ê³¼ **ë¦¬ì „**ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ë¹„ìš© ë°œìƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¦¬ì†ŒìŠ¤ëŠ” ë°˜ë“œì‹œ ì •ì§€ ë˜ëŠ” ì‚­ì œí•´ì£¼ì„¸ìš”.

- Amazon SageMaker Notebook Instance (ml.t3.medium): ì‹œê°„ ë‹¹ ì•½ $0.05 (us-east-1, 2024/10 ê¸°ì¤€)
- Amazon SageMaker Training Job (ml.g5.2xlarge): ì‹œê°„ ë‹¹ ì•½ $1.515 (us-east-1, 2024/10 ê¸°ì¤€)
- Amazon Bedrock Imported Model: ìš”ê¸ˆì€ ëª¨ë¸ í¬ê¸° ë° ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [Amazon Bedrock ìš”ê¸ˆ í˜ì´ì§€](https://aws.amazon.com/ko/bedrock/pricing/)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
- Amazon Translate (Batch job) : 1ë°±ë§Œ ìë‹¹ $15.00 (us-east-1, 2024/10 ê¸°ì¤€)

#### ë¹„ìš© ì°¸ê³ 

- **Option 1** (3,200ê°œ ìƒ˜í”Œ ë°ì´í„°ì…‹): $2.871 + Amazon Bedrock Claude Sonnet/Imported Model í˜¸ì¶œ ë¹„ìš©
- **Option 2** (78,577ê°œ ì „ì²´ ë°ì´í„°ì…‹): $59.72 + Amazon Bedrock Claude Sonnet/Imported Model í˜¸ì¶œ ë¹„ìš©

## ğŸ—‚ï¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```text

.
â”œâ”€â”€ README.md
â”œâ”€â”€ datasets        # ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ ì „ì²´ ë°ì´í„°ì…‹ (78577ê°œ)
â”‚   â”œâ”€â”€ ko_test_dataset.json
â”‚   â”œâ”€â”€ ko_train_dataset.json
â”‚   â””â”€â”€ ko_validation_dataset.json
â”œâ”€â”€ images          # ì‹¤ìŠµ ê°€ì´ë“œìš© ì´ë¯¸ì§€ ì…‹
â”‚
â”œâ”€â”€ notebook        # ì‹¤ìŠµ ìˆ˜í–‰ìš© íŒŒì´ì¬ ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ 0_setup.ipynb
â”‚   â”œâ”€â”€ 1-1_full_data_preprocessing.ipynb # í”„ë¡œë•ì…˜ ìš© ì „ì²´ ë°ì´í„° ì…‹ ì „ì²˜ë¦¬ (78577ê°œ)
â”‚   â”œâ”€â”€ 1_data_preprocessing.ipynb        # ì‹¤ìŠµìš© ìƒ˜í”Œ ë°ì´í„° ì…‹ ì „ì²˜ë¦¬ (3200ê°œ)
â”‚   â”œâ”€â”€ 2_fine_tuning.ipynb
â”‚   â”œâ”€â”€ 3_deploy.ipynb
â”‚   â””â”€â”€ 4_evaluation.ipynb
â””â”€â”€ scripts         # íŒŒì¸ íŠœë‹ì— ì´ìš©í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ run_fsdp_qlora_llama3.py

```

í”„ë¡œì íŠ¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- [0_setup.ipynb](./notebook/0_setup.ipynb): ì´ˆê¸° í™˜ê²½ ì„¤ì • ê³¼ì •
- [1_data_preprocessing.ipynb](./notebook/1_data_preprocessing.ipynb): ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì • (ì‹¤ìŠµìš© ìƒ˜í”Œ ë°ì´í„° ì´ìš©, í”„ë¡œë•ì…˜ ìš© ì „ì²´ ë°ì´í„° ì…‹ì€ [1-1_full_data_preprocessing.ipynb](./notebook/1-1_full_data_preprocessing.ipynb) ë…¸íŠ¸ë¶ ì´ìš©)
- [2_fine_tuning.ipynb](./notebook/2_fine_tuning.ipynb): ëª¨ë¸ íŒŒì¸ íŠœë‹ ê³¼ì •
- [3_deploy.ipynb](./notebook/3_deploy.ipynb): Amazon Bedrockì— ëª¨ë¸ ë°°í¬ ê³¼ì •
- [4_evaluation.ipynb](./notebook/4_evaluation.ipynb): ëª¨ë¸ í‰ê°€ ê³¼ì •

## ğŸ“ References

- [SageMaker ì—ì„œ Llama3.1 8B íŒŒì¸ íŠœë‹, ëª¨ë¸ ë°°í¬ ë° ì¶”ë¡  í•˜ê¸°](https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/30_fine_tune/03-fine-tune-llama3/llama3-1)
- [Amazon Bedrock Samples](https://github.com/aws-samples/amazon-bedrock-samples/blob/main/custom_models/import_models/llama-3/customized-text-to-sql-model.ipynb)
- [Import a fine-tuned Meta Llama 3 model for SQL query generation on Amazon Bedrock](https://aws.amazon.com/blogs/machine-learning/import-a-fine-tuned-meta-llama-3-model-for-sql-query-generation-on-amazon-bedrock/)
