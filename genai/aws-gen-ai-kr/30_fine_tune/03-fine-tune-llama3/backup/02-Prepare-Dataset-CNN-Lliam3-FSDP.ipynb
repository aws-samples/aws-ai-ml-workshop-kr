{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4872e4-c90b-434b-bfe5-f88292fba385",
   "metadata": {},
   "source": [
    "# 데이터셋 준비하기\n",
    "- https://www.kaggle.com/code/mitanshuchakrawarty/fine-tune-llm-for-text-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da7aa7-1a2d-4db1-b011-59217c32a83a",
   "metadata": {},
   "source": [
    "## 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06b5f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/SageMaker/.cache/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bdcebd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_DATASETS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_HOME'] = \"/home/ec2-user/SageMaker/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a396bc4f-0b0a-4ffb-8c59-18ed6d0a968d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4b722-f752-4687-8fbe-12855566892c",
   "metadata": {},
   "source": [
    "## 2. 데이터 셋 준비\n",
    "### 데이터 셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3710c3d-71bb-47b1-97eb-a72ef6dcfd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"cnn_dailymail\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name, \"3.0.0\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b9b4f66-a1f6-484d-9cfd-c5bfe17835cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96451467-4fc0-49af-bedf-040850c11fbb",
   "metadata": {},
   "source": [
    "## 3. 데이터셋 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eda452",
   "metadata": {},
   "source": [
    "### Chat Message 형태 템플릿 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df1181ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_instruction(system_prompt: str, article: str, summary: str):\n",
    "    message = [\n",
    "            {\n",
    "                'content': system_prompt,\n",
    "                'role': 'system'\n",
    "            },\n",
    "            {\n",
    "                'content': f'Please summarize the goals for journalist in this text:\\n\\n{article}',\n",
    "                'role': 'user'\n",
    "            },\n",
    "            {\n",
    "                'content': f'{summary}',\n",
    "                'role': 'assistant'\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    return message # json.dumps(message, indent=2) # json.dumps(message, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "# system_prompt = \"You are an AI assistant specialized in news articles. Your role is to provide accurate summaries and insights. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\"\n",
    "# article = \"Within three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert's portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. \\\"We can't ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,\\\" says Rinkert.\"\n",
    "# summary = \"Scientists are studying nests hoping to learn about transitional habitats that could help restore the shoreline of San Francisco Bay.\"\n",
    "\n",
    "# print(format_instruction(system_prompt, article, summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a4269",
   "metadata": {},
   "source": [
    "### Chat Message 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b5a43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_instruction_dataset(data_point):\n",
    "    system_prompt = \"You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights.Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": format_instruction(system_prompt, data_point[\"article\"],data_point[\"highlights\"])\n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset).remove_columns(['article','highlights','id'])\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390bfdf",
   "metadata": {},
   "source": [
    "##### 전체 데이터 셋에서 일부 데티터 추출 (짧은 실습을 위해서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c75ddc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_debug_samples = 10\n",
    "test_num_debug_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0edb7874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10ec1912ccc470ea984833ddd5fa73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## APPLYING PREPROCESSING ON WHOLE DATASET\n",
    "\n",
    "dataset[\"train\"] = process_dataset(dataset[\"train\"].select(range(train_num_debug_samples)))\n",
    "dataset[\"test\"] = process_dataset(dataset[\"validation\"])\n",
    "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86f033fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1000 rows from the training split\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select([i for i in range(train_num_debug_samples)])\n",
    "\n",
    "# Select 100 rows from the test and validation splits\n",
    "test_dataset = dataset['test'].shuffle(seed=42).select([i for i in range(test_num_debug_samples)])\n",
    "validation_dataset = dataset['validation'].shuffle(seed=42).select([i for i in range(test_num_debug_samples)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc6deeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 10\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 10\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 10\n",
       " }))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset,test_dataset,validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7197aa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights.Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Please summarize the goals for journalist in this text:\\n\\nMINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. \"I probably had a 30-, 35-foot free fall. And there\\'s cars in the water, there\\'s cars on fire. The whole bridge is down.\" He said his back was injured but he determined he could move around. \"I realized there was a school bus right next to me, and me and a couple of other guys went over and started lifting the kids off the bridge. They were yelling, screaming, bleeding. I think there were some broken bones.\"  Watch a driver describe his narrow escape » . At home when he heard about the disaster, Dr. John Hink, an emergency room physician, jumped into his car and rushed to the scene in 15 minutes. He arrived at the south side of the bridge, stood on the riverbank and saw dozens of people lying dazed on an expansive deck. They were in the middle of the Mississippi River, which was churning fast, and he had no way of getting to them. He went to the north side, where there was easier access to people. Ambulances were also having a hard time driving down to the river to get closer to the scene. Working feverishly, volunteers, EMTs and other officials managed to get 55 people into ambulances in less than two hours. Occasionally, a pickup truck with a medic inside would drive to get an injured person and bring him back up even ground, Hink told CNN. The rescue effort was controlled and organized, he said; the opposite of the lightning-quick collapse. \"I could see the whole bridge as it was going down, as it was falling,\" Babineau said. \"It just gave a rumble real quick, and it all just gave way, and it just fell completely, all the way to the ground. And there was dust everywhere and it was just like everyone has been saying: It was just like out of the movies.\" Babineau said the rear of his pickup truck was dangling over the edge of a broken-off section of the bridge. He said several vehicles slid past him into the water. \"I stayed in my car for one or two seconds. I saw a couple cars fall,\" he said. \"So I stayed in my car until the cars quit falling for a second, then I got out real quick, ran in front of my truck -- because behind my truck was just a hole -- and I helped a woman off of the bridge with me. \"I just wanted off the bridge, and then I ran over to the school bus. I started grabbing kids and handing them down. It was just complete chaos.\" He said most of the children were crying or screaming. He and other rescuers set them on the ground and told them to run to the river bank, but a few needed to be carried because of their injuries.  See rescuers clamber over rubble » . Babineau said he had no rescue training. \"I just knew what I had to do at the moment.\" Melissa Hughes, 32, of Minneapolis, told The Associated Press that she was driving home when the western edge of the bridge collapsed under her. \"You know that free-fall feeling? I felt that twice,\" Hughes said. A pickup landed on top of her car, but she was not hurt. \"I had no idea there was a vehicle on my car,\" she told AP. \"It\\'s really very surreal.\" Babineau told the Minneapolis Star-Tribune: \"On the way down, I thought I was dead. I literally thought I was dead. \"My truck was completely face down, pointed toward the ground, and my truck got ripped in half. It was folded in half, and I can\\'t believe I\\'m alive.\"  See and hear eyewitness accounts » . Bernie Toivonen told CNN\\'s \"American Morning\" that his vehicle was on a part of the bridge that ended up tilted at a 45-degree angle. \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said. After the bridge settled and his car remained upright, \"I just put in park, turned the key off and said, \\'Oh, I\\'m alive,\\' \" he said. E-mail to a friend .',\n",
       "   'role': 'user'},\n",
       "  {'content': 'NEW: \"I thought I was going to die,\" driver says .\\nMan says pickup truck was folded in half; he just has cut on face .\\nDriver: \"I probably had a 30-, 35-foot free fall\"\\nMinnesota bridge collapsed during rush hour Wednesday .',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dda7e7",
   "metadata": {},
   "source": [
    "## 4. 데이터 셋을 JSON 으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8af3619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_json:  ../data/cnn_dailymail/train_dataset.json\n",
      "validation_data_json:  ../data/cnn_dailymail/validation_dataset.json\n",
      "test_data_json:  ../data/cnn_dailymail/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_folder = os.path.join(\"../data/\", huggingface_dataset_name)\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "train_data_json = os.path.join(data_folder, \"train_dataset.json\")\n",
    "validation_data_json = os.path.join(data_folder, \"validation_dataset.json\")\n",
    "test_data_json = os.path.join(data_folder, \"test_dataset.json\")\n",
    "print(\"train_data_json: \", train_data_json)\n",
    "print(\"validation_data_json: \", validation_data_json)\n",
    "print(\"test_data_json: \", test_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "79e88d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eefb7c11b4f4bd2b690cd66f0b1dc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f5e903f6b84282a22fb466dbb07bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efd820ebf1a40ed8d460c70980a6756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40884"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save datasets to disk \n",
    "train_dataset.to_json(train_data_json, orient=\"records\", force_ascii=False)\n",
    "validation_dataset.to_json(validation_data_json, orient=\"records\", force_ascii=False)\n",
    "test_dataset.to_json(test_data_json, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8245d9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파싱 오류: Extra data: line 2 column 1 (char 4595)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 파일 경로\n",
    "file_path = \"../data/cnn_dailymail/train_dataset.json\"\n",
    "\n",
    "try:\n",
    "    # 파일 열기 및 내용 읽기\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # 파일의 전체 내용을 문자열로 읽음\n",
    "        json_str = file.read()\n",
    "        \n",
    "        # JSON 파싱\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        # 첫 번째 레코드 출력 (데이터가 리스트인 경우)\n",
    "        if isinstance(data, list) and len(data) > 0:\n",
    "            first_record = data[0]\n",
    "            print(json.dumps(first_record, indent=2, ensure_ascii=False))\n",
    "        elif isinstance(data, dict):\n",
    "            # 데이터가 딕셔너리인 경우 전체 출력\n",
    "            print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "        else:\n",
    "            print(\"데이터가 비어있거나 예상치 못한 형식입니다.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON 파싱 오류: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c521c6f",
   "metadata": {},
   "source": [
    "### 다음 노트북에서 사용하기 위해 변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "70fb035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_folder' (str)\n",
      "Stored 'train_data_json' (str)\n",
      "Stored 'validation_data_json' (str)\n",
      "Stored 'test_data_json' (str)\n"
     ]
    }
   ],
   "source": [
    "%store data_folder\n",
    "%store train_data_json \n",
    "%store validation_data_json \n",
    "%store test_data_json \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5c4cc",
   "metadata": {},
   "source": [
    "## 5. Option: 데이터 셋을 ChatTemplate 형태로 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165e725",
   "metadata": {},
   "source": [
    "### Chat Template 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ea4ba09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{% if message['role'] == 'system' %}{{ message['content'] }}{% elif message['role'] == 'user' %}{{ '\\n\\nHuman: ' + message['content'] +  eos_token }}{% elif message['role'] == 'assistant' %}{{ '\\n\\nAssistant: '  + message['content'] +  eos_token  }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n\\nAssistant: ' }}{% endif %}\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLAMA_3_CHAT_TEMPLATE = (\n",
    "    \"{% for message in messages %}\"\n",
    "        \"{% if message['role'] == 'system' %}\"\n",
    "            \"{{ message['content'] }}\"\n",
    "        \"{% elif message['role'] == 'user' %}\"\n",
    "            \"{{ '\\n\\nHuman: ' + message['content'] +  eos_token }}\"\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\n",
    "            \"{{ '\\n\\nAssistant: '  + message['content'] +  eos_token  }}\"\n",
    "        \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "    \"{{ '\\n\\nAssistant: ' }}\"\n",
    "    \"{% endif %}\"\n",
    ")\n",
    "LLAMA_3_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfcc19",
   "metadata": {},
   "source": [
    "### Chat Template 으로 변형하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "54451f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e3a3cc3ad044ef8c29d82f6e48db22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer        \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE\n",
    "\n",
    "# template dataset\n",
    "def template_dataset(examples):\n",
    "    return{\"text\":  tokenizer.apply_chat_template(examples[\"messages\"], tokenize=False)}\n",
    "\n",
    "train_dataset = train_dataset.map(template_dataset, remove_columns=[\"messages\"])\n",
    "test_dataset = test_dataset.map(template_dataset, remove_columns=[\"messages\"])\n",
    "validation_dataset = validation_dataset.map(template_dataset, remove_columns=[\"messages\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fc1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0d955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "380fc688",
   "metadata": {},
   "source": [
    "### 변형된 Chat Message 형태 예시 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  6\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights.Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush's colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said. Results are expected in two to three days. All were small, less than a centimeter [half an inch] in diameter, he said. Bush is in good humor, Stanzel said, and will resume his activities at Camp David. During the procedure Vice President Dick Cheney assumed presidential power. Bush reclaimed presidential power at 9:21 a.m. after about two hours. Doctors used \"monitored anesthesia care,\" Stanzel said, so the president was asleep, but not as deeply unconscious as with a true general anesthetic. He spoke to first lady Laura Bush -- who is in Midland, Texas, celebrating her mother's birthday -- before and after the procedure, Stanzel said. Afterward, the president played with his Scottish terriers, Barney and Miss Beazley, Stanzel said. He planned to have lunch at Camp David and have briefings with National Security Adviser Stephen Hadley and White House Chief of Staff Josh Bolten, and planned to take a bicycle ride Saturday afternoon. Cheney, meanwhile, spent the morning at his home on Maryland's eastern shore, reading and playing with his dogs, Stanzel said. Nothing occurred that required him to take official action as president before Bush reclaimed presidential power. The procedure was supervised by Dr. Richard Tubb, Bush's physician, and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, the White House said. Bush's last colonoscopy was in June 2002, and no abnormalities were found, White House spokesman Tony Snow said. The president's doctor had recommended a repeat procedure in about five years. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said on Friday that Bush had polyps removed during colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver.  Watch Snow talk about Bush's procedure and his own colon cancer » . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .<|end_of_text|>\n",
      "\n",
      "Assistant: Five small polyps found during procedure; \"none worrisome,\" spokesman says .\n",
      "President reclaims powers transferred to vice president .\n",
      "Bush undergoes routine colonoscopy at Camp David .<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# print random sample\n",
    "import random\n",
    "\n",
    "for index in random.sample(range(len(train_dataset)), 1):\n",
    "    print(\"index: \", index)\n",
    "    # index = 5343\n",
    "    print(train_dataset[index][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60aaa4-b654-49b3-bb87-34ad6a9f375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('pytorch_p310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2257b1c3513dc4782645ad49f694a4b0012bebbbbc3534a56d350db8e4f89a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
