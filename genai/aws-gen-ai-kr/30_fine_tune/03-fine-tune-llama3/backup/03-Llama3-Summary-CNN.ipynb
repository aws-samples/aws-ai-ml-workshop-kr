{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4872e4-c90b-434b-bfe5-f88292fba385",
   "metadata": {},
   "source": [
    "# Fine Tune LLM for Text Summary\n",
    "- https://www.kaggle.com/code/mitanshuchakrawarty/fine-tune-llm-for-text-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da7aa7-1a2d-4db1-b011-59217c32a83a",
   "metadata": {},
   "source": [
    "## 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7274d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.2.2) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.2.2) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.2.2) (2024.2.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.2)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (69.2.0)\n",
      "Requirement already satisfied: six>1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, tensorboard-data-server, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markdown, grpcio, absl-py, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.64.1 markdown-3.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 tensorboard-2.17.0 tensorboard-data-server-0.7.2 torch-2.2.2 triton-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers==4.40.0\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets==2.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.18.0)\n",
      "Collecting accelerate==0.29.3\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting evaluate==0.4.1\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: bitsandbytes==0.43.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.43.1)\n",
      "Collecting huggingface_hub==0.22.2\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting trl==0.8.6\n",
      "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft==0.10.0\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.40.0) (4.66.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.18.0) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.18.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.18.0) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.18.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.18.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.18.0) (3.9.5)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.29.3) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.29.3) (2.2.2)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub==0.22.2) (4.10.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl==0.8.6) (0.8.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.40.0) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.5.40)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: responses, huggingface_hub, tokenizers, transformers, accelerate, trl, peft, evaluate\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.23.4\n",
      "    Uninstalling huggingface-hub-0.23.4:\n",
      "      Successfully uninstalled huggingface-hub-0.23.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.27.2\n",
      "    Uninstalling accelerate-0.27.2:\n",
      "      Successfully uninstalled accelerate-0.27.2\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.7.1\n",
      "    Uninstalling trl-0.7.1:\n",
      "      Successfully uninstalled trl-0.7.1\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.9.0\n",
      "    Uninstalling peft-0.9.0:\n",
      "      Successfully uninstalled peft-0.9.0\n",
      "Successfully installed accelerate-0.29.3 evaluate-0.4.1 huggingface_hub-0.22.2 peft-0.10.0 responses-0.18.0 tokenizers-0.19.1 transformers-4.40.0 trl-0.8.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch for FSDP and FA/SDPA\n",
    "%pip install \"torch==2.2.2\" tensorboard\n",
    "\n",
    "# Install Hugging Face libraries\n",
    "%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b5f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli login --token \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb59557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c017a08e1740a58fba119e774fecd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9442b734b14e53882f979b702445a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "784047"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Convert dataset to OAI messages\n",
    "system_message = \"\"\"You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\"\"\"\n",
    "\n",
    "def create_conversation(sample):\n",
    "    if sample[\"messages\"][0][\"role\"] == \"system\":\n",
    "        return sample\n",
    "    else:\n",
    "      sample[\"messages\"] = [{\"role\": \"system\", \"content\": system_message}] + sample[\"messages\"]\n",
    "      return sample\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"HuggingFaceH4/no_robots\")\n",
    "\n",
    "# Add system message to each conversation\n",
    "columns_to_remove = list(dataset[\"train\"].features)\n",
    "columns_to_remove.remove(\"messages\")\n",
    "dataset = dataset.map(create_conversation, remove_columns=columns_to_remove,batched=False)\n",
    "\n",
    "# Filter out conversations which are corrupted with wrong turns, keep which have even number of turns after adding system message\n",
    "dataset[\"train\"] = dataset[\"train\"].filter(lambda x: len(x[\"messages\"][1:]) % 2 == 0)\n",
    "dataset[\"test\"] = dataset[\"test\"].filter(lambda x: len(x[\"messages\"][1:]) % 2 == 0)\n",
    "\n",
    "# save datasets to disk \n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\", force_ascii=False)\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting llama_3_8b_fsdp_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile llama_3_8b_fsdp_qlora.yaml\n",
    "# script parameters\n",
    "model_id: \"meta-llama/Meta-Llama-3-8B\" # Hugging Face model id\n",
    "dataset_path: \".\"                      # path to dataset\n",
    "max_seq_len:  2048 # 3072 # 2048              # max sequence length for model and packing of the dataset\n",
    "# training parameters\n",
    "output_dir: \"./llama-3-8b-hf-no-robot\" # Temporary output directory for model checkpoints\n",
    "report_to: \"tensorboard\"               # report metrics to tensorboard\n",
    "learning_rate: 0.0002                  # learning rate 2e-4\n",
    "lr_scheduler_type: \"constant\"          # learning rate scheduler\n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "per_device_train_batch_size: 1         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "optim: adamw_torch                     # use torch adamw optimizer\n",
    "logging_steps: 10                      # log every 10 steps\n",
    "save_strategy: epoch                   # save checkpoint every epoch\n",
    "evaluation_strategy: epoch             # evaluate every epoch\n",
    "max_grad_norm: 0.3                     # max gradient norm\n",
    "warmup_ratio: 0.03                     # warmup ratio\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: true                             # use tf32 precision\n",
    "gradient_checkpointing: true           # use gradient checkpointing to save memory\n",
    "# FSDP parameters: https://huggingface.co/docs/transformers/main/en/fsdp\n",
    "fsdp: \"full_shard auto_wrap offload\" # remove offload if enough GPU memory\n",
    "fsdp_config:\n",
    "  backward_prefetch: \"backward_pre\"\n",
    "  forward_prefetch: \"false\"\n",
    "  use_orig_params: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe78db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-25 13:57:56,839] torch.distributed.run: [WARNING] \n",
      "[2024-06-25 13:57:56,839] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-06-25 13:57:56,839] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-06-25 13:57:56,839] torch.distributed.run: [WARNING] *****************************************\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "Generating train split: 9485 examples [00:00, 96453.86 examples/s]\n",
      "Generating train split: 500 examples [00:00, 98940.93 examples/s]\n",
      "tokenizer_config.json: 100%|███████████████| 50.6k/50.6k [00:00<00:00, 79.4MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 32.0MB/s]\n",
      "special_tokens_map.json: 100%|████████████████| 73.0/73.0 [00:00<00:00, 752kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map:   0%|                                      | 0/9485 [00:00<?, ? examples/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|████████████████████████| 9485/9485 [00:00<00:00, 12001.20 examples/s]\n",
      "Map: 100%|████████████████████████| 9485/9485 [00:00<00:00, 11595.02 examples/s]\n",
      "Map: 100%|████████████████████████| 9485/9485 [00:00<00:00, 12096.52 examples/s]\n",
      "Map: 100%|████████████████████████| 9485/9485 [00:00<00:00, 11945.86 examples/s]\n",
      "Map: 100%|██████████████████████████| 500/500 [00:00<00:00, 11484.20 examples/s]\n",
      "Map: 100%|██████████████████████████| 500/500 [00:00<00:00, 11261.99 examples/s]\n",
      "Map: 100%|██████████████████████████| 500/500 [00:00<00:00, 11187.73 examples/s]\n",
      "You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: Make a list of 10 weird sights to see on a road trip in Colorado.<|end_of_text|>\n",
      "\n",
      "Assistant: 1. 12-foot-tall grizzly bear in Alamosa. \n",
      "2. The childhood home that you've seen in the movie, Indiana Jones and the Last Crusade in Antonito. \n",
      "3. In the town of Arvada, you can see a horse statue wearing a hazmat mask. \n",
      "4. Bailey, CO has a diner shaped like a hot dog. \n",
      "5. You won't believe it until you see it, but in the town of Fruita, there is a dinosaur riding a bicycle. \n",
      "6. Sasquatch Museum in Bailey. A must-see. \n",
      "7. Aspen is home to Ashcroft Ghost Town. \n",
      "8. The town of Aurora has a three-legged chair at the intersection of Colfax Ave. and Dallas St.\n",
      "9. There is a statue of a Papa Burger with root beer and burger in Berthoud. The statue stands on the roof of an A&W. \n",
      "10. A fake police officer sits in a patrol car, towards the north end of town in Alma. <|end_of_text|>\n",
      "You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: I am looking for healthy snacks for a road trip. They cannot contain any nuts, as I am deathly allergic. Please give me 3 options.<|end_of_text|>\n",
      "\n",
      "Assistant: Here are three healthy road trips snacks that don't contain nuts:\n",
      "1. Apple chips: This healthy snack is a perfect snack for on the go, and you can mix it up by sprinkling cinnamon on top.\n",
      "2. Homemade trail mix: Trail mix doesn't have to contain nuts--make your own by using ingredients such as sunflower seeds, pumpkin seeds, dried fruit, and some dark chocolate chips.\n",
      "3. Fresh fruit and cheese: Pick your favorite fresh fruit and pair it with some slices of cheese.<|end_of_text|>\n",
      "You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: Make a list of 10 weird sights to see on a road trip in Colorado.<|end_of_text|>\n",
      "\n",
      "Assistant: 1. 12-foot-tall grizzly bear in Alamosa. \n",
      "2. The childhood home that you've seen in the movie, Indiana Jones and the Last Crusade in Antonito. \n",
      "3. In the town of Arvada, you can see a horse statue wearing a hazmat mask. \n",
      "4. Bailey, CO has a diner shaped like a hot dog. \n",
      "5. You won't believe it until you see it, but in the town of Fruita, there is a dinosaur riding a bicycle. \n",
      "6. Sasquatch Museum in Bailey. A must-see. \n",
      "7. Aspen is home to Ashcroft Ghost Town. \n",
      "8. The town of Aurora has a three-legged chair at the intersection of Colfax Ave. and Dallas St.\n",
      "9. There is a statue of a Papa Burger with root beer and burger in Berthoud. The statue stands on the roof of an A&W. \n",
      "10. A fake police officer sits in a patrol car, towards the north end of town in Alma. <|end_of_text|>\n",
      "You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: Make a list of 10 weird sights to see on a road trip in Colorado.<|end_of_text|>\n",
      "\n",
      "Assistant: 1. 12-foot-tall grizzly bear in Alamosa. \n",
      "2. The childhood home that you've seen in the movie, Indiana Jones and the Last Crusade in Antonito. \n",
      "3. In the town of Arvada, you can see a horse statue wearing a hazmat mask. \n",
      "4. Bailey, CO has a diner shaped like a hot dog. \n",
      "5. You won't believe it until you see it, but in the town of Fruita, there is a dinosaur riding a bicycle. \n",
      "6. Sasquatch Museum in Bailey. A must-see. \n",
      "7. Aspen is home to Ashcroft Ghost Town. \n",
      "8. The town of Aurora has a three-legged chair at the intersection of Colfax Ave. and Dallas St.\n",
      "9. There is a statue of a Papa Burger with root beer and burger in Berthoud. The statue stands on the roof of an A&W. \n",
      "10. A fake police officer sits in a patrol car, towards the north end of town in Alma. <|end_of_text|>You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: I am looking for healthy snacks for a road trip. They cannot contain any nuts, as I am deathly allergic. Please give me 3 options.<|end_of_text|>\n",
      "\n",
      "Assistant: Here are three healthy road trips snacks that don't contain nuts:\n",
      "1. Apple chips: This healthy snack is a perfect snack for on the go, and you can mix it up by sprinkling cinnamon on top.\n",
      "2. Homemade trail mix: Trail mix doesn't have to contain nuts--make your own by using ingredients such as sunflower seeds, pumpkin seeds, dried fruit, and some dark chocolate chips.\n",
      "3. Fresh fruit and cheese: Pick your favorite fresh fruit and pair it with some slices of cheese.<|end_of_text|>You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: Make a list of 10 weird sights to see on a road trip in Colorado.<|end_of_text|>\n",
      "\n",
      "Assistant: 1. 12-foot-tall grizzly bear in Alamosa. \n",
      "2. The childhood home that you've seen in the movie, Indiana Jones and the Last Crusade in Antonito. \n",
      "3. In the town of Arvada, you can see a horse statue wearing a hazmat mask. \n",
      "4. Bailey, CO has a diner shaped like a hot dog. \n",
      "5. You won't believe it until you see it, but in the town of Fruita, there is a dinosaur riding a bicycle. \n",
      "6. Sasquatch Museum in Bailey. A must-see. \n",
      "7. Aspen is home to Ashcroft Ghost Town. \n",
      "8. The town of Aurora has a three-legged chair at the intersection of Colfax Ave. and Dallas St.\n",
      "9. There is a statue of a Papa Burger with root beer and burger in Berthoud. The statue stands on the roof of an A&W. \n",
      "10. A fake police officer sits in a patrol car, towards the north end of town in Alma. <|end_of_text|>\n",
      "\n",
      "\n",
      "You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: I am looking for healthy snacks for a road trip. They cannot contain any nuts, as I am deathly allergic. Please give me 3 options.<|end_of_text|>\n",
      "\n",
      "Assistant: Here are three healthy road trips snacks that don't contain nuts:\n",
      "1. Apple chips: This healthy snack is a perfect snack for on the go, and you can mix it up by sprinkling cinnamon on top.\n",
      "2. Homemade trail mix: Trail mix doesn't have to contain nuts--make your own by using ingredients such as sunflower seeds, pumpkin seeds, dried fruit, and some dark chocolate chips.\n",
      "3. Fresh fruit and cheese: Pick your favorite fresh fruit and pair it with some slices of cheese.<|end_of_text|>You are Llama, an AI assistant created by Philipp to be helpful and honest. Your knowledge spans a wide range of topics, allowing you to engage in substantive conversations and provide analysis on complex subjects.\n",
      "\n",
      "Human: I am looking for healthy snacks for a road trip. They cannot contain any nuts, as I am deathly allergic. Please give me 3 options.<|end_of_text|>\n",
      "\n",
      "Assistant: Here are three healthy road trips snacks that don't contain nuts:\n",
      "1. Apple chips: This healthy snack is a perfect snack for on the go, and you can mix it up by sprinkling cinnamon on top.\n",
      "2. Homemade trail mix: Trail mix doesn't have to contain nuts--make your own by using ingredients such as sunflower seeds, pumpkin seeds, dried fruit, and some dark chocolate chips.\n",
      "3. Fresh fruit and cheese: Pick your favorite fresh fruit and pair it with some slices of cheese.<|end_of_text|>\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 654/654 [00:00<00:00, 7.18MB/s]\n",
      "model.safetensors.index.json: 100%|█████████| 23.9k/23.9k [00:00<00:00, 164MB/s]\n",
      "Downloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|     | 31.5M/4.98G [00:00<00:16, 292MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|     | 73.4M/4.98G [00:00<00:13, 355MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏     | 115M/4.98G [00:00<00:13, 372MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 157M/4.98G [00:00<00:22, 216MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▏     | 189M/4.98G [00:01<00:39, 120MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 231M/4.98G [00:01<00:29, 162MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 273M/4.98G [00:01<00:22, 206MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▍     | 315M/4.98G [00:01<00:18, 246MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 357M/4.98G [00:01<00:16, 284MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 409M/4.98G [00:01<00:14, 322MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 451M/4.98G [00:02<00:21, 212MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 482M/4.98G [00:02<00:29, 152MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 514M/4.98G [00:02<00:35, 125MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 535M/4.98G [00:03<00:37, 119MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 556M/4.98G [00:03<00:34, 128MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 577M/4.98G [00:03<00:41, 107MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 619M/4.98G [00:03<00:28, 152MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 671M/4.98G [00:03<00:21, 205MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▊     | 713M/4.98G [00:03<00:18, 231MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▉     | 755M/4.98G [00:03<00:16, 258MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 786M/4.98G [00:04<00:19, 210MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|▉     | 828M/4.98G [00:04<00:16, 251MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█     | 870M/4.98G [00:04<00:14, 287MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█     | 912M/4.98G [00:04<00:12, 317MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▏    | 954M/4.98G [00:04<00:11, 343MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█▏    | 996M/4.98G [00:04<00:11, 360MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|█    | 1.04G/4.98G [00:04<00:10, 372MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█    | 1.08G/4.98G [00:04<00:10, 380MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|█▏   | 1.12G/4.98G [00:04<00:09, 390MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|█▏   | 1.17G/4.98G [00:05<00:09, 400MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█▏   | 1.23G/4.98G [00:05<00:09, 408MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█▎   | 1.27G/4.98G [00:05<00:09, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|█▎   | 1.31G/4.98G [00:05<00:08, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|█▎   | 1.35G/4.98G [00:05<00:08, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.41G/4.98G [00:05<00:08, 416MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|█▍   | 1.45G/4.98G [00:05<00:08, 415MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|█▌   | 1.50G/4.98G [00:05<00:08, 416MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|█▌   | 1.55G/4.98G [00:06<00:08, 417MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|█▌   | 1.60G/4.98G [00:06<00:08, 419MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|█▋   | 1.66G/4.98G [00:06<00:07, 421MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.71G/4.98G [00:06<00:07, 421MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|█▊   | 1.76G/4.98G [00:06<00:07, 420MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.81G/4.98G [00:06<00:07, 418MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.86G/4.98G [00:06<00:07, 417MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.90G/4.98G [00:06<00:07, 416MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|█▉   | 1.94G/4.98G [00:06<00:07, 414MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|█▉   | 1.98G/4.98G [00:07<00:07, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|██   | 2.02G/4.98G [00:07<00:07, 407MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.07G/4.98G [00:07<00:07, 406MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.11G/4.98G [00:07<00:07, 407MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|██▏  | 2.15G/4.98G [00:07<00:06, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 2.19G/4.98G [00:07<00:06, 411MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|██▏  | 2.23G/4.98G [00:07<00:06, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|██▎  | 2.29G/4.98G [00:07<00:06, 417MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 2.34G/4.98G [00:07<00:06, 420MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|██▍  | 2.39G/4.98G [00:08<00:06, 421MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|██▍  | 2.44G/4.98G [00:08<00:06, 415MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|██▍  | 2.49G/4.98G [00:08<00:06, 397MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|██▌  | 2.53G/4.98G [00:08<00:06, 401MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.57G/4.98G [00:08<00:05, 406MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.61G/4.98G [00:08<00:05, 408MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.66G/4.98G [00:08<00:05, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|██▋  | 2.72G/4.98G [00:08<00:05, 415MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|██▊  | 2.76G/4.98G [00:08<00:05, 416MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.80G/4.98G [00:09<00:05, 417MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|██▊  | 2.85G/4.98G [00:09<00:05, 418MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|██▉  | 2.90G/4.98G [00:09<00:04, 419MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.95G/4.98G [00:09<00:04, 418MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|███  | 2.99G/4.98G [00:09<00:04, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|███  | 3.03G/4.98G [00:09<00:04, 411MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|███  | 3.08G/4.98G [00:09<00:04, 416MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|███▏ | 3.14G/4.98G [00:09<00:04, 420MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|███▏ | 3.18G/4.98G [00:09<00:04, 420MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|███▏ | 3.22G/4.98G [00:10<00:06, 263MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 3.27G/4.98G [00:10<00:05, 301MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|███▎ | 3.31G/4.98G [00:10<00:05, 324MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.37G/4.98G [00:10<00:04, 351MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.41G/4.98G [00:10<00:04, 366MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███▍ | 3.46G/4.98G [00:10<00:03, 384MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 3.51G/4.98G [00:10<00:03, 395MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.57G/4.98G [00:11<00:03, 402MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 3.62G/4.98G [00:11<00:03, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.67G/4.98G [00:11<00:03, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███▋ | 3.71G/4.98G [00:11<00:03, 319MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███▊ | 3.75G/4.98G [00:11<00:03, 335MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.81G/4.98G [00:11<00:03, 360MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███▊ | 3.85G/4.98G [00:11<00:03, 374MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.90G/4.98G [00:12<00:02, 390MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.95G/4.98G [00:12<00:02, 400MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████ | 4.01G/4.98G [00:12<00:02, 390MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████ | 4.05G/4.98G [00:12<00:02, 373MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.10G/4.98G [00:12<00:02, 387MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 4.14G/4.98G [00:12<00:02, 395MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.19G/4.98G [00:12<00:01, 404MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████▎| 4.25G/4.98G [00:12<00:01, 404MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 4.30G/4.98G [00:12<00:01, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 4.34G/4.98G [00:13<00:01, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 4.39G/4.98G [00:13<00:01, 415MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████▍| 4.45G/4.98G [00:13<00:01, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|████▌| 4.49G/4.98G [00:13<00:01, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 4.54G/4.98G [00:13<00:01, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 4.58G/4.98G [00:13<00:00, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 4.62G/4.98G [00:13<00:00, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|████▋| 4.67G/4.98G [00:13<00:00, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|████▋| 4.71G/4.98G [00:13<00:00, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|████▊| 4.75G/4.98G [00:14<00:01, 193MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|███▊| 4.78G/4.98G [00:15<00:02, 80.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|███▊| 4.81G/4.98G [00:16<00:02, 67.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|███▉| 4.85G/4.98G [00:16<00:01, 74.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|███▉| 4.88G/4.98G [00:17<00:02, 44.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|███▉| 4.91G/4.98G [00:18<00:01, 57.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|███▉| 4.93G/4.98G [00:18<00:00, 65.4MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|███▉| 4.95G/4.98G [00:18<00:00, 72.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|█████| 4.98G/4.98G [00:20<00:00, 243MB/s]\u001b[A\n",
      "Downloading shards:  25%|██████▎                  | 1/4 [00:20<01:01, 20.48s/it]\n",
      "model-00002-of-00004.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   0%|    | 10.5M/5.00G [00:00<04:28, 18.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|    | 31.5M/5.00G [00:00<01:36, 51.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|    | 41.9M/5.00G [00:01<03:29, 23.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|    | 52.4M/5.00G [00:02<04:07, 20.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|    | 62.9M/5.00G [00:02<03:30, 23.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|    | 73.4M/5.00G [00:02<03:22, 24.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|    | 83.9M/5.00G [00:03<03:02, 27.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|    | 94.4M/5.00G [00:03<03:14, 25.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|     | 105M/5.00G [00:04<04:15, 19.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|     | 115M/5.00G [00:05<05:02, 16.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   3%|▏    | 126M/5.00G [00:05<04:10, 19.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   3%|▏    | 157M/5.00G [00:05<01:58, 40.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▏    | 199M/5.00G [00:06<01:47, 44.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▏    | 210M/5.00G [00:06<01:44, 45.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|▎    | 252M/5.00G [00:07<01:06, 71.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|▎    | 273M/5.00G [00:07<01:31, 51.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▎    | 283M/5.00G [00:08<02:08, 36.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▎    | 294M/5.00G [00:08<01:57, 39.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▎    | 304M/5.00G [00:09<02:42, 29.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▎    | 315M/5.00G [00:10<03:41, 21.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▎    | 325M/5.00G [00:10<03:05, 25.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▎    | 346M/5.00G [00:11<02:56, 26.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▎    | 357M/5.00G [00:12<03:31, 22.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▎    | 367M/5.00G [00:12<03:11, 24.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|▍    | 398M/5.00G [00:12<01:40, 45.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▍    | 430M/5.00G [00:12<01:15, 60.5MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▍    | 451M/5.00G [00:13<01:22, 55.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▍    | 461M/5.00G [00:13<01:40, 45.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▍    | 472M/5.00G [00:14<01:57, 38.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|▌    | 503M/5.00G [00:14<01:10, 63.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|▌    | 524M/5.00G [00:14<01:18, 56.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  11%|▌    | 545M/5.00G [00:14<01:06, 66.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  11%|▌    | 566M/5.00G [00:15<01:48, 41.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▌    | 577M/5.00G [00:16<02:16, 32.5MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▌    | 587M/5.00G [00:17<02:48, 26.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▌    | 598M/5.00G [00:17<02:40, 27.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▌    | 608M/5.00G [00:17<02:38, 27.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▌    | 619M/5.00G [00:18<02:11, 33.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|▋    | 640M/5.00G [00:18<01:24, 51.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|▋    | 650M/5.00G [00:18<01:16, 56.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▋    | 682M/5.00G [00:18<00:53, 80.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▋    | 703M/5.00G [00:18<01:02, 69.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▋    | 713M/5.00G [00:19<01:00, 71.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▋    | 724M/5.00G [00:19<01:05, 65.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|▋    | 734M/5.00G [00:19<01:09, 61.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|▋    | 744M/5.00G [00:19<01:26, 49.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|▊    | 755M/5.00G [00:20<02:06, 33.5MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|▊    | 765M/5.00G [00:20<01:50, 38.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|▊    | 807M/5.00G [00:20<00:50, 82.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|▊    | 828M/5.00G [00:21<01:01, 68.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|▊    | 849M/5.00G [00:21<01:14, 55.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|▊    | 860M/5.00G [00:21<01:21, 50.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|▊    | 870M/5.00G [00:22<01:36, 42.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|▉    | 881M/5.00G [00:22<01:27, 46.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|▉    | 912M/5.00G [00:22<00:52, 77.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  19%|█▏    | 954M/5.00G [00:22<00:31, 128MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  20%|█    | 1.01G/5.00G [00:22<00:21, 189MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.06G/5.00G [00:23<00:16, 242MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|█    | 1.11G/5.00G [00:23<00:13, 286MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 1.16G/5.00G [00:23<00:11, 323MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  24%|█▏   | 1.21G/5.00G [00:23<00:11, 345MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  25%|█▏   | 1.25G/5.00G [00:23<00:15, 240MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.29G/5.00G [00:23<00:13, 273MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|█▎   | 1.33G/5.00G [00:23<00:12, 304MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|█▎   | 1.37G/5.00G [00:23<00:10, 330MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.42G/5.00G [00:24<00:10, 351MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|█▍   | 1.46G/5.00G [00:24<00:09, 367MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  30%|█▌   | 1.51G/5.00G [00:24<00:09, 385MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.56G/5.00G [00:24<00:08, 397MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  32%|█▌   | 1.60G/5.00G [00:24<00:08, 402MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.65G/5.00G [00:24<00:08, 406MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.69G/5.00G [00:24<00:08, 407MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  35%|█▋   | 1.74G/5.00G [00:24<00:07, 412MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.78G/5.00G [00:24<00:07, 413MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.82G/5.00G [00:25<00:07, 414MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.88G/5.00G [00:25<00:07, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.93G/5.00G [00:25<00:07, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  40%|█▉   | 1.98G/5.00G [00:25<00:07, 420MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  41%|██   | 2.03G/5.00G [00:25<00:07, 419MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|██   | 2.09G/5.00G [00:25<00:06, 420MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 2.14G/5.00G [00:25<00:06, 414MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 2.18G/5.00G [00:25<00:07, 390MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 2.22G/5.00G [00:26<00:07, 395MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|██▎  | 2.26G/5.00G [00:26<00:06, 399MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 2.31G/5.00G [00:26<00:06, 399MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 2.35G/5.00G [00:26<00:06, 402MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|██▍  | 2.39G/5.00G [00:26<00:07, 340MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 2.43G/5.00G [00:26<00:08, 298MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 2.47G/5.00G [00:26<00:08, 312MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.53G/5.00G [00:26<00:07, 343MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.57G/5.00G [00:27<00:06, 360MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  52%|██▌  | 2.61G/5.00G [00:27<00:06, 374MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  53%|██▋  | 2.65G/5.00G [00:27<00:06, 384MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  54%|██▋  | 2.69G/5.00G [00:27<00:05, 388MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  55%|██▋  | 2.74G/5.00G [00:27<00:05, 391MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.79G/5.00G [00:27<00:05, 401MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.84G/5.00G [00:27<00:05, 408MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  58%|██▉  | 2.89G/5.00G [00:27<00:05, 412MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.94G/5.00G [00:27<00:04, 413MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|██▉  | 2.98G/5.00G [00:28<00:04, 415MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|███  | 3.02G/5.00G [00:28<00:04, 416MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  61%|███  | 3.06G/5.00G [00:28<00:04, 415MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.10G/5.00G [00:28<00:04, 412MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  63%|███▏ | 3.15G/5.00G [00:28<00:04, 409MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 3.19G/5.00G [00:28<00:04, 409MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  65%|███▏ | 3.23G/5.00G [00:28<00:04, 412MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 3.28G/5.00G [00:28<00:04, 415MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 3.33G/5.00G [00:28<00:03, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  68%|███▍ | 3.39G/5.00G [00:29<00:03, 419MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.43G/5.00G [00:29<00:03, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.47G/5.00G [00:29<00:03, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|███▌ | 3.52G/5.00G [00:29<00:03, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 3.58G/5.00G [00:29<00:03, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 3.63G/5.00G [00:29<00:03, 419MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 3.67G/5.00G [00:29<00:03, 419MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.72G/5.00G [00:29<00:03, 422MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.77G/5.00G [00:29<00:02, 423MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.83G/5.00G [00:30<00:02, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.87G/5.00G [00:30<00:02, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███▉ | 3.92G/5.00G [00:30<00:02, 419MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.97G/5.00G [00:30<00:02, 421MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  81%|████ | 4.03G/5.00G [00:30<00:02, 420MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.08G/5.00G [00:30<00:02, 421MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  83%|████▏| 4.13G/5.00G [00:30<00:02, 422MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 4.18G/5.00G [00:30<00:01, 422MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  85%|████▏| 4.24G/5.00G [00:31<00:01, 414MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 4.28G/5.00G [00:31<00:01, 413MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.33G/5.00G [00:31<00:01, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  88%|████▍| 4.38G/5.00G [00:31<00:01, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.44G/5.00G [00:31<00:01, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|████▍| 4.48G/5.00G [00:31<00:01, 416MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|████▌| 4.52G/5.00G [00:31<00:01, 416MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|████▌| 4.57G/5.00G [00:31<00:01, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|████▌| 4.61G/5.00G [00:31<00:00, 418MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|████▋| 4.66G/5.00G [00:32<00:00, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 4.70G/5.00G [00:32<00:00, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|████▊| 4.75G/5.00G [00:32<00:00, 419MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|████▊| 4.80G/5.00G [00:32<00:00, 417MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|████▊| 4.84G/5.00G [00:32<00:00, 416MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|████▉| 4.89G/5.00G [00:32<00:00, 414MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|████▉| 4.93G/5.00G [00:32<00:00, 406MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|█████| 5.00G/5.00G [00:32<00:00, 152MB/s]\u001b[A\n",
      "Downloading shards:  50%|████████████▌            | 2/4 [00:53<00:55, 27.80s/it]\n",
      "Downloading shards:  50%|████████████▌            | 2/4 [00:53<00:55, 27.81s/it]\u001b[A\n",
      "model-00003-of-00004.safetensors:   1%|     | 41.9M/4.92G [00:00<00:12, 383MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   2%|     | 83.9M/4.92G [00:00<00:12, 396MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 126M/4.92G [00:00<00:11, 399MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 168M/4.92G [00:00<00:11, 406MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   4%|▎     | 210M/4.92G [00:00<00:13, 360MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   5%|▎     | 252M/4.92G [00:00<00:12, 371MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   6%|▎     | 294M/4.92G [00:00<00:19, 235MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 336M/4.92G [00:01<00:16, 270MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 377M/4.92G [00:01<00:15, 301MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 419M/4.92G [00:01<00:13, 330MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 472M/4.92G [00:01<00:12, 360MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 524M/4.92G [00:01<00:11, 381MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 577M/4.92G [00:01<00:11, 394MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 619M/4.92G [00:01<00:10, 399MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 661M/4.92G [00:01<00:10, 403MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  15%|▊     | 713M/4.92G [00:01<00:10, 407MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 765M/4.92G [00:02<00:10, 411MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  17%|▉     | 818M/4.92G [00:02<00:09, 415MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  18%|█     | 870M/4.92G [00:02<00:09, 420MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  19%|█▏    | 923M/4.92G [00:02<00:09, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 975M/4.92G [00:02<00:09, 420MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  21%|█    | 1.03G/4.92G [00:02<00:09, 423MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.08G/4.92G [00:02<00:09, 425MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 1.13G/4.92G [00:02<00:08, 424MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 1.18G/4.92G [00:03<00:08, 425MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  25%|█▎   | 1.24G/4.92G [00:03<00:08, 424MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  26%|█▎   | 1.29G/4.92G [00:03<00:08, 422MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.34G/4.92G [00:03<00:08, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.39G/4.92G [00:03<00:08, 419MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.44G/4.92G [00:03<00:08, 417MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  30%|█▌   | 1.48G/4.92G [00:03<00:08, 406MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.52G/4.92G [00:03<00:08, 393MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.56G/4.92G [00:04<00:08, 386MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.60G/4.92G [00:04<00:08, 379MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.65G/4.92G [00:04<00:08, 375MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  34%|█▋   | 1.69G/4.92G [00:04<00:08, 370MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  35%|█▊   | 1.73G/4.92G [00:04<00:08, 375MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  36%|█▊   | 1.78G/4.92G [00:04<00:08, 390MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.82G/4.92G [00:04<00:07, 398MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.87G/4.92G [00:04<00:07, 401MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.91G/4.92G [00:04<00:07, 405MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  40%|█▉   | 1.95G/4.92G [00:05<00:07, 408MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  41%|██   | 1.99G/4.92G [00:05<00:07, 411MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  42%|██   | 2.04G/4.92G [00:05<00:06, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  43%|██▏  | 2.10G/4.92G [00:05<00:06, 418MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.14G/4.92G [00:05<00:06, 415MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.18G/4.92G [00:05<00:07, 387MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  45%|██▎  | 2.22G/4.92G [00:05<00:06, 385MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 2.26G/4.92G [00:05<00:06, 394MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  47%|██▎  | 2.31G/4.92G [00:05<00:06, 400MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 2.35G/4.92G [00:06<00:06, 405MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 2.40G/4.92G [00:06<00:06, 410MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  50%|██▍  | 2.45G/4.92G [00:06<00:05, 414MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 2.51G/4.92G [00:06<00:05, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.55G/4.92G [00:06<00:05, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  53%|██▋  | 2.59G/4.92G [00:06<00:05, 414MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.63G/4.92G [00:06<00:05, 412MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  55%|██▋  | 2.68G/4.92G [00:06<00:05, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  56%|██▊  | 2.74G/4.92G [00:06<00:05, 417MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.78G/4.92G [00:07<00:05, 417MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.82G/4.92G [00:07<00:05, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.86G/4.92G [00:07<00:04, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.90G/4.92G [00:07<00:04, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  60%|██▉  | 2.95G/4.92G [00:07<00:04, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  61%|███  | 3.00G/4.92G [00:07<00:04, 418MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  62%|███  | 3.05G/4.92G [00:07<00:04, 402MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 3.09G/4.92G [00:07<00:05, 354MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 3.14G/4.92G [00:07<00:04, 368MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  65%|███▏ | 3.19G/4.92G [00:08<00:04, 385MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  66%|███▎ | 3.23G/4.92G [00:08<00:04, 394MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 3.27G/4.92G [00:08<00:04, 399MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.32G/4.92G [00:08<00:03, 406MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  69%|███▍ | 3.38G/4.92G [00:08<00:03, 411MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  70%|███▍ | 3.42G/4.92G [00:08<00:03, 412MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  70%|███▌ | 3.46G/4.92G [00:08<00:03, 413MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 3.50G/4.92G [00:08<00:03, 411MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 3.54G/4.92G [00:08<00:03, 411MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 3.59G/4.92G [00:09<00:03, 391MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 3.63G/4.92G [00:09<00:03, 374MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  75%|███▋ | 3.68G/4.92G [00:09<00:03, 389MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 3.73G/4.92G [00:09<00:02, 398MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 3.77G/4.92G [00:09<00:02, 397MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.82G/4.92G [00:09<00:02, 399MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.86G/4.92G [00:09<00:02, 402MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  79%|███▉ | 3.90G/4.92G [00:09<00:02, 403MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  80%|████ | 3.94G/4.92G [00:09<00:02, 406MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  81%|████ | 3.98G/4.92G [00:10<00:02, 408MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  82%|████ | 4.04G/4.92G [00:10<00:02, 415MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 4.09G/4.92G [00:10<00:01, 420MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 4.14G/4.92G [00:10<00:01, 424MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  85%|████▎| 4.19G/4.92G [00:10<00:01, 423MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 4.25G/4.92G [00:10<00:01, 424MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 4.30G/4.92G [00:10<00:01, 423MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  89%|████▍| 4.35G/4.92G [00:10<00:01, 422MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  90%|████▍| 4.40G/4.92G [00:11<00:01, 371MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  91%|████▌| 4.46G/4.92G [00:11<00:01, 386MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  92%|████▌| 4.50G/4.92G [00:11<00:01, 392MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  93%|████▋| 4.55G/4.92G [00:11<00:00, 401MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  93%|████▋| 4.59G/4.92G [00:11<00:00, 403MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  94%|████▋| 4.63G/4.92G [00:11<00:00, 406MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  95%|████▊| 4.69G/4.92G [00:11<00:00, 412MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  96%|████▊| 4.74G/4.92G [00:11<00:00, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 4.79G/4.92G [00:12<00:00, 419MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  99%|████▉| 4.84G/4.92G [00:12<00:00, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:12<00:00, 399MB/s]\u001b[A\n",
      "Downloading shards:  75%|██████████████████▊      | 3/4 [01:05<00:20, 20.75s/it]\n",
      "model-00004-of-00004.safetensors:   0%|             | 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   3%|▏    | 31.5M/1.17G [00:00<00:04, 232MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   6%|▎    | 73.4M/1.17G [00:00<00:03, 326MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  11%|▋     | 126M/1.17G [00:00<00:02, 375MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  15%|▉     | 178M/1.17G [00:00<00:02, 396MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  20%|█▏    | 231M/1.17G [00:00<00:02, 408MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  24%|█▍    | 283M/1.17G [00:00<00:02, 417MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  28%|█▋    | 325M/1.17G [00:00<00:02, 383MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  32%|█▉    | 377M/1.17G [00:00<00:01, 397MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  37%|██▏   | 430M/1.17G [00:01<00:01, 408MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  41%|██▍   | 482M/1.17G [00:01<00:01, 415MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  46%|██▋   | 535M/1.17G [00:01<00:01, 418MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  49%|██▉   | 577M/1.17G [00:01<00:01, 382MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  53%|███▏  | 619M/1.17G [00:01<00:01, 384MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  57%|███▍  | 671M/1.17G [00:01<00:01, 396MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  62%|███▋  | 724M/1.17G [00:01<00:01, 405MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  66%|███▉  | 776M/1.17G [00:01<00:00, 411MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  70%|████▏ | 818M/1.17G [00:02<00:00, 382MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  75%|████▍ | 870M/1.17G [00:02<00:00, 394MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  78%|████▋ | 912M/1.17G [00:02<00:00, 383MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  83%|████▉ | 965M/1.17G [00:02<00:00, 398MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  87%|████▎| 1.02G/1.17G [00:02<00:00, 407MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  91%|████▌| 1.06G/1.17G [00:02<00:00, 397MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  94%|████▋| 1.10G/1.17G [00:02<00:00, 402MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|█████| 1.17G/1.17G [00:02<00:00, 396MB/s]\u001b[A\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [01:08<00:00, 17.19s/it]\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [01:08<00:00, 17.19s/it]\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [01:08<00:00, 17.19s/it]\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [01:08<00:00, 17.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:05<00:00,  1.32s/it]\n",
      "generation_config.json: 100%|██████████████████| 177/177 [00:00<00:00, 1.95MB/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:06<00:00,  1.69s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:06<00:00,  1.68s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:06<00:00,  1.70s/it]\n",
      "Generating train split: 5904 examples [00:01, 3269.12 examples/s]\n",
      "Generating train split: 315 examples [00:00, 3624.27 examples/s]\n",
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5195983464188562\n",
      "{'loss': 2.1242, 'grad_norm': 0.36328125, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
      "{'loss': 1.8494, 'grad_norm': 0.205078125, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
      "{'loss': 1.8372, 'grad_norm': 0.224609375, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
      "{'loss': 1.8542, 'grad_norm': 0.205078125, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
      "{'loss': 1.8584, 'grad_norm': 0.197265625, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
      "{'loss': 1.8001, 'grad_norm': 0.21875, 'learning_rate': 0.0002, 'epoch': 0.08}  \n",
      "{'loss': 1.8118, 'grad_norm': 0.2451171875, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
      "{'loss': 1.852, 'grad_norm': 0.1572265625, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
      "{'loss': 1.7759, 'grad_norm': 0.23046875, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
      "{'loss': 1.7701, 'grad_norm': 0.279296875, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
      "{'loss': 1.829, 'grad_norm': 0.2412109375, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
      "{'loss': 1.6957, 'grad_norm': 0.173828125, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
      "{'loss': 1.8153, 'grad_norm': 0.19921875, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
      "{'loss': 1.8085, 'grad_norm': 0.1748046875, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
      "{'loss': 1.7247, 'grad_norm': 0.2177734375, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
      "{'loss': 1.7303, 'grad_norm': 0.2314453125, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 1.7854, 'grad_norm': 0.193359375, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
      "{'loss': 1.7957, 'grad_norm': 0.1728515625, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
      "{'loss': 1.8138, 'grad_norm': 0.181640625, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
      "{'loss': 1.7535, 'grad_norm': 0.16796875, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
      "{'loss': 1.7755, 'grad_norm': 0.1953125, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
      "{'loss': 1.8268, 'grad_norm': 0.2119140625, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
      "{'loss': 1.8067, 'grad_norm': 0.373046875, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
      "{'loss': 1.7172, 'grad_norm': 0.228515625, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
      "{'loss': 1.7641, 'grad_norm': 0.1865234375, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
      "{'loss': 1.8252, 'grad_norm': 0.1845703125, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
      "{'loss': 1.7929, 'grad_norm': 0.2041015625, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
      "{'loss': 1.7636, 'grad_norm': 0.2353515625, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
      "{'loss': 1.7732, 'grad_norm': 0.177734375, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
      "{'loss': 1.7253, 'grad_norm': 0.1728515625, 'learning_rate': 0.0002, 'epoch': 0.41}\n",
      "{'loss': 1.7734, 'grad_norm': 0.16796875, 'learning_rate': 0.0002, 'epoch': 0.42}\n",
      "{'loss': 1.7467, 'grad_norm': 0.2265625, 'learning_rate': 0.0002, 'epoch': 0.43}\n",
      "{'loss': 1.7815, 'grad_norm': 0.1611328125, 'learning_rate': 0.0002, 'epoch': 0.45}\n",
      "{'loss': 1.8336, 'grad_norm': 0.33203125, 'learning_rate': 0.0002, 'epoch': 0.46}\n",
      "{'loss': 1.8033, 'grad_norm': 0.240234375, 'learning_rate': 0.0002, 'epoch': 0.47}\n",
      "{'loss': 1.8314, 'grad_norm': 0.177734375, 'learning_rate': 0.0002, 'epoch': 0.49}\n",
      "{'loss': 1.7628, 'grad_norm': 0.1884765625, 'learning_rate': 0.0002, 'epoch': 0.5}\n",
      "{'loss': 1.775, 'grad_norm': 0.228515625, 'learning_rate': 0.0002, 'epoch': 0.51}\n",
      "{'loss': 1.6986, 'grad_norm': 0.169921875, 'learning_rate': 0.0002, 'epoch': 0.53}\n",
      "{'loss': 1.7577, 'grad_norm': 0.3125, 'learning_rate': 0.0002, 'epoch': 0.54}   \n",
      "{'loss': 1.7978, 'grad_norm': 0.2265625, 'learning_rate': 0.0002, 'epoch': 0.56}\n",
      "{'loss': 1.8137, 'grad_norm': 0.171875, 'learning_rate': 0.0002, 'epoch': 0.57} \n",
      "{'loss': 1.7526, 'grad_norm': 0.1875, 'learning_rate': 0.0002, 'epoch': 0.58}   \n",
      "{'loss': 1.7478, 'grad_norm': 0.1689453125, 'learning_rate': 0.0002, 'epoch': 0.6}\n",
      "{'loss': 1.7687, 'grad_norm': 0.1953125, 'learning_rate': 0.0002, 'epoch': 0.61}\n",
      "{'loss': 1.7545, 'grad_norm': 0.201171875, 'learning_rate': 0.0002, 'epoch': 0.62}\n",
      "{'loss': 1.7998, 'grad_norm': 0.1826171875, 'learning_rate': 0.0002, 'epoch': 0.64}\n",
      "{'loss': 1.6805, 'grad_norm': 0.294921875, 'learning_rate': 0.0002, 'epoch': 0.65}\n",
      "{'loss': 1.8131, 'grad_norm': 0.1767578125, 'learning_rate': 0.0002, 'epoch': 0.66}\n",
      "{'loss': 1.76, 'grad_norm': 0.173828125, 'learning_rate': 0.0002, 'epoch': 0.68}\n",
      "{'loss': 1.8203, 'grad_norm': 0.1953125, 'learning_rate': 0.0002, 'epoch': 0.69}\n",
      "{'loss': 1.7328, 'grad_norm': 0.2001953125, 'learning_rate': 0.0002, 'epoch': 0.7}\n",
      "{'loss': 1.7327, 'grad_norm': 0.2080078125, 'learning_rate': 0.0002, 'epoch': 0.72}\n",
      "{'loss': 1.7989, 'grad_norm': 0.185546875, 'learning_rate': 0.0002, 'epoch': 0.73}\n",
      "{'loss': 1.8379, 'grad_norm': 0.267578125, 'learning_rate': 0.0002, 'epoch': 0.75}\n",
      "{'loss': 1.7634, 'grad_norm': 0.2099609375, 'learning_rate': 0.0002, 'epoch': 0.76}\n",
      "{'loss': 1.7943, 'grad_norm': 0.1865234375, 'learning_rate': 0.0002, 'epoch': 0.77}\n",
      "{'loss': 1.7546, 'grad_norm': 0.220703125, 'learning_rate': 0.0002, 'epoch': 0.79}\n",
      "{'loss': 1.7802, 'grad_norm': 0.173828125, 'learning_rate': 0.0002, 'epoch': 0.8}\n",
      "{'loss': 1.7081, 'grad_norm': 0.291015625, 'learning_rate': 0.0002, 'epoch': 0.81}\n",
      "{'loss': 1.7634, 'grad_norm': 0.1748046875, 'learning_rate': 0.0002, 'epoch': 0.83}\n",
      "{'loss': 1.8005, 'grad_norm': 0.16796875, 'learning_rate': 0.0002, 'epoch': 0.84}\n",
      "{'loss': 1.7149, 'grad_norm': 0.2216796875, 'learning_rate': 0.0002, 'epoch': 0.85}\n",
      "{'loss': 1.7684, 'grad_norm': 0.1845703125, 'learning_rate': 0.0002, 'epoch': 0.87}\n",
      "{'loss': 1.7564, 'grad_norm': 0.1943359375, 'learning_rate': 0.0002, 'epoch': 0.88}\n",
      "{'loss': 1.7744, 'grad_norm': 0.1650390625, 'learning_rate': 0.0002, 'epoch': 0.89}\n",
      "{'loss': 1.7073, 'grad_norm': 0.1611328125, 'learning_rate': 0.0002, 'epoch': 0.91}\n",
      "{'loss': 1.7508, 'grad_norm': 0.248046875, 'learning_rate': 0.0002, 'epoch': 0.92}\n",
      "{'loss': 1.8209, 'grad_norm': 0.17578125, 'learning_rate': 0.0002, 'epoch': 0.93}\n",
      "{'loss': 1.74, 'grad_norm': 0.1748046875, 'learning_rate': 0.0002, 'epoch': 0.95}\n",
      "{'loss': 1.7079, 'grad_norm': 0.1953125, 'learning_rate': 0.0002, 'epoch': 0.96}\n",
      "{'loss': 1.6894, 'grad_norm': 0.169921875, 'learning_rate': 0.0002, 'epoch': 0.98}\n",
      "{'loss': 1.8022, 'grad_norm': 0.2333984375, 'learning_rate': 0.0002, 'epoch': 0.99}\n",
      "100%|███████████████████████████████████████| 738/738 [1:29:51<00:00,  7.31s/it]\n",
      "  0%|                                                    | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█                                           | 2/79 [00:01<00:42,  1.82it/s]\u001b[A\n",
      "  4%|█▋                                          | 3/79 [00:02<00:58,  1.29it/s]\u001b[A\n",
      "  5%|██▏                                         | 4/79 [00:03<01:07,  1.11it/s]\u001b[A\n",
      "  6%|██▊                                         | 5/79 [00:04<01:11,  1.03it/s]\u001b[A\n",
      "  8%|███▎                                        | 6/79 [00:05<01:13,  1.01s/it]\u001b[A\n",
      "  9%|███▉                                        | 7/79 [00:06<01:14,  1.04s/it]\u001b[A\n",
      " 10%|████▍                                       | 8/79 [00:07<01:15,  1.06s/it]\u001b[A\n",
      " 11%|█████                                       | 9/79 [00:08<01:15,  1.07s/it]\u001b[A\n",
      " 13%|█████▍                                     | 10/79 [00:09<01:14,  1.08s/it]\u001b[A\n",
      " 14%|█████▉                                     | 11/79 [00:10<01:14,  1.09s/it]\u001b[A\n",
      " 15%|██████▌                                    | 12/79 [00:12<01:13,  1.09s/it]\u001b[A\n",
      " 16%|███████                                    | 13/79 [00:13<01:12,  1.09s/it]\u001b[A\n",
      " 18%|███████▌                                   | 14/79 [00:14<01:11,  1.10s/it]\u001b[A\n",
      " 19%|████████▏                                  | 15/79 [00:15<01:10,  1.09s/it]\u001b[A\n",
      " 20%|████████▋                                  | 16/79 [00:16<01:09,  1.10s/it]\u001b[A\n",
      " 22%|█████████▎                                 | 17/79 [00:17<01:07,  1.10s/it]\u001b[A\n",
      " 23%|█████████▊                                 | 18/79 [00:18<01:06,  1.10s/it]\u001b[A\n",
      " 24%|██████████▎                                | 19/79 [00:19<01:05,  1.09s/it]\u001b[A\n",
      " 25%|██████████▉                                | 20/79 [00:20<01:04,  1.09s/it]\u001b[A\n",
      " 27%|███████████▍                               | 21/79 [00:21<01:03,  1.09s/it]\u001b[A\n",
      " 28%|███████████▉                               | 22/79 [00:23<01:02,  1.09s/it]\u001b[A\n",
      " 29%|████████████▌                              | 23/79 [00:24<01:01,  1.09s/it]\u001b[A\n",
      " 30%|█████████████                              | 24/79 [00:25<01:00,  1.09s/it]\u001b[A\n",
      " 32%|█████████████▌                             | 25/79 [00:26<00:59,  1.09s/it]\u001b[A\n",
      " 33%|██████████████▏                            | 26/79 [00:27<00:58,  1.10s/it]\u001b[A\n",
      " 34%|██████████████▋                            | 27/79 [00:28<00:57,  1.10s/it]\u001b[A\n",
      " 35%|███████████████▏                           | 28/79 [00:29<00:56,  1.10s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 29/79 [00:30<00:55,  1.10s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 30/79 [00:31<00:53,  1.10s/it]\u001b[A\n",
      " 39%|████████████████▊                          | 31/79 [00:32<00:52,  1.10s/it]\u001b[A\n",
      " 41%|█████████████████▍                         | 32/79 [00:34<00:51,  1.10s/it]\u001b[A\n",
      " 42%|█████████████████▉                         | 33/79 [00:35<00:50,  1.10s/it]\u001b[A\n",
      " 43%|██████████████████▌                        | 34/79 [00:36<00:49,  1.10s/it]\u001b[A\n",
      " 44%|███████████████████                        | 35/79 [00:37<00:48,  1.10s/it]\u001b[A\n",
      " 46%|███████████████████▌                       | 36/79 [00:38<00:47,  1.10s/it]\u001b[A\n",
      " 47%|████████████████████▏                      | 37/79 [00:39<00:46,  1.10s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 38/79 [00:40<00:45,  1.10s/it]\u001b[A\n",
      " 49%|█████████████████████▏                     | 39/79 [00:41<00:43,  1.10s/it]\u001b[A\n",
      " 51%|█████████████████████▊                     | 40/79 [00:42<00:42,  1.10s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 41/79 [00:43<00:41,  1.10s/it]\u001b[A\n",
      " 53%|██████████████████████▊                    | 42/79 [00:45<00:40,  1.10s/it]\u001b[A\n",
      " 54%|███████████████████████▍                   | 43/79 [00:46<00:39,  1.10s/it]\u001b[A\n",
      " 56%|███████████████████████▉                   | 44/79 [00:47<00:38,  1.10s/it]\u001b[A\n",
      " 57%|████████████████████████▍                  | 45/79 [00:48<00:37,  1.09s/it]\u001b[A\n",
      " 58%|█████████████████████████                  | 46/79 [00:49<00:35,  1.09s/it]\u001b[A\n",
      " 59%|█████████████████████████▌                 | 47/79 [00:50<00:34,  1.09s/it]\u001b[A\n",
      " 61%|██████████████████████████▏                | 48/79 [00:51<00:33,  1.09s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 49/79 [00:52<00:32,  1.09s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 50/79 [00:53<00:31,  1.09s/it]\u001b[A\n",
      " 65%|███████████████████████████▊               | 51/79 [00:54<00:30,  1.09s/it]\u001b[A\n",
      " 66%|████████████████████████████▎              | 52/79 [00:55<00:29,  1.09s/it]\u001b[A\n",
      " 67%|████████████████████████████▊              | 53/79 [00:57<00:28,  1.09s/it]\u001b[A\n",
      " 68%|█████████████████████████████▍             | 54/79 [00:58<00:27,  1.09s/it]\u001b[A\n",
      " 70%|█████████████████████████████▉             | 55/79 [00:59<00:26,  1.09s/it]\u001b[A\n",
      " 71%|██████████████████████████████▍            | 56/79 [01:00<00:25,  1.09s/it]\u001b[A\n",
      " 72%|███████████████████████████████            | 57/79 [01:01<00:24,  1.09s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 58/79 [01:02<00:22,  1.09s/it]\u001b[A\n",
      " 75%|████████████████████████████████           | 59/79 [01:03<00:21,  1.09s/it]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 60/79 [01:04<00:20,  1.09s/it]\u001b[A\n",
      " 77%|█████████████████████████████████▏         | 61/79 [01:05<00:19,  1.09s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▋         | 62/79 [01:06<00:18,  1.09s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▎        | 63/79 [01:07<00:17,  1.09s/it]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 64/79 [01:09<00:16,  1.09s/it]\u001b[A\n",
      " 82%|███████████████████████████████████▍       | 65/79 [01:10<00:15,  1.09s/it]\u001b[A\n",
      " 84%|███████████████████████████████████▉       | 66/79 [01:11<00:14,  1.09s/it]\u001b[A\n",
      " 85%|████████████████████████████████████▍      | 67/79 [01:12<00:13,  1.09s/it]\u001b[A\n",
      " 86%|█████████████████████████████████████      | 68/79 [01:13<00:12,  1.09s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▌     | 69/79 [01:14<00:10,  1.09s/it]\u001b[A\n",
      " 89%|██████████████████████████████████████     | 70/79 [01:15<00:09,  1.10s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 71/79 [01:16<00:08,  1.09s/it]\u001b[A\n",
      " 91%|███████████████████████████████████████▏   | 72/79 [01:17<00:07,  1.09s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▋   | 73/79 [01:18<00:06,  1.09s/it]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 74/79 [01:19<00:05,  1.09s/it]\u001b[A\n",
      " 95%|████████████████████████████████████████▊  | 75/79 [01:21<00:04,  1.09s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 76/79 [01:22<00:03,  1.09s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▉ | 77/79 [01:23<00:02,  1.09s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████████▍| 78/79 [01:24<00:01,  1.09s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.7918243408203125, 'eval_runtime': 86.8946, 'eval_samples_per_second': 3.625, 'eval_steps_per_second': 0.909, 'epoch': 1.0}\n",
      "100%|███████████████████████████████████████| 738/738 [1:31:17<00:00,  7.31s/it]\n",
      "100%|███████████████████████████████████████████| 79/79 [01:25<00:00,  1.09s/it]\u001b[A\n",
      "                                                                                \u001b[A[rank0]:[2024-06-25 15:30:56,887] torch.distributed.fsdp._debug_utils: [WARNING] FSDP _optim_state_dict() profiling:  defaultdict(<class 'float'>, {'preprocessing': 0.23992481701134238, 'preprocessing_with_comm': 0.13168101699557155, 'state_converting': 0.20831730400095694, <Type.ALL: 'all'>: 0.5909609230002388})\n",
      "{'train_runtime': 5492.6204, 'train_samples_per_second': 1.075, 'train_steps_per_second': 0.134, 'train_loss': 1.7807904336510636, 'epoch': 1.0}\n",
      "100%|███████████████████████████████████████| 738/738 [1:31:32<00:00,  7.44s/it]\n"
     ]
    }
   ],
   "source": [
    "!ACCELERATE_USE_FSDP=1 FSDP_CPU_RAM_EFFICIENT_LOADING=1 torchrun --nproc_per_node=4 ./scripts/run_fsdp_qlora.py --config llama_3_8b_fsdp_qlora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675a4f33-a8ef-498a-9755-c4aefb99be77",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.31\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.31) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (2024.2.2)\n",
      "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.38.2\n",
      "    Uninstalling transformers-4.38.2:\n",
      "      Successfully uninstalled transformers-4.38.2\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.31.0\n",
      "Requirement already satisfied: peft in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (2.1.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (4.31.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (0.27.2)\n",
      "Requirement already satisfied: safetensors in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (0.23.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q -U bitsandbytes\n",
    "# !pip install transformers==4.31\n",
    "# !pip install peft\n",
    "# !pip install -q datasets\n",
    "# !pip install -qqq trl==0.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a396bc4f-0b0a-4ffb-8c59-18ed6d0a968d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4b722-f752-4687-8fbe-12855566892c",
   "metadata": {},
   "source": [
    "## 2. 데이터 셋 준비\n",
    "### 데이터 셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3710c3d-71bb-47b1-97eb-a72ef6dcfd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"cnn_dailymail\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name, \"3.0.0\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9b4f66-a1f6-484d-9cfd-c5bfe17835cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96451467-4fc0-49af-bedf-040850c11fbb",
   "metadata": {},
   "source": [
    "### 데이터텟 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c0f824-8a38-4df6-9a53-460f52a66f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_instruction(dialogue: str, summary: str):\n",
    "    return f\"\"\"### Instruction:\n",
    "Summarize the following conversation.\n",
    "\n",
    "### Input:\n",
    "{dialogue.strip()}\n",
    "\n",
    "### Summary:\n",
    "{summary}\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_instruction_dataset(data_point):\n",
    "\n",
    "    return {\n",
    "        \"article\": data_point[\"article\"],\n",
    "        \"highlights\": data_point[\"highlights\"],\n",
    "        \"text\": format_instruction(data_point[\"article\"],data_point[\"highlights\"])\n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset).remove_columns(['id'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0e2f3d-2c64-4bd4-9796-e32497a7c781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3270f9ecdd2f4247869c739226985fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adb80188fe64fa188de74add8f605c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['article', 'highlights', 'text'],\n",
       "     num_rows: 1000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['article', 'highlights', 'text'],\n",
       "     num_rows: 100\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['article', 'highlights', 'text'],\n",
       "     num_rows: 100\n",
       " }))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## APPLYING PREPROCESSING ON WHOLE DATASET\n",
    "dataset[\"train\"] = process_dataset(dataset[\"train\"])\n",
    "dataset[\"test\"] = process_dataset(dataset[\"validation\"])\n",
    "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])\n",
    "\n",
    "# Select 1000 rows from the training split\n",
    "train_data = dataset['train'].shuffle(seed=42).select([i for i in range(1000)])\n",
    "\n",
    "# Select 100 rows from the test and validation splits\n",
    "test_data = dataset['test'].shuffle(seed=42).select([i for i in range(100)])\n",
    "validation_data = dataset['validation'].shuffle(seed=42).select([i for i in range(100)])\n",
    "\n",
    "train_data,test_data,validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78f53c-d21d-4fca-b69d-6a85d966353c",
   "metadata": {},
   "source": [
    "## 3. 베이스 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47341964-d43d-4835-b650-316320567f84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c2d70bcfac49d5bb0019eb38deccbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4867594125478e9d0a94b6d3aefc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b408514f4d4a378d92aad0d8d999cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d4787e9bd4484eb1c4f159e3d2d5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16dec4d48a44db1a8b3b1f7e5b3537d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06037fa8dd94aa4a20f84860dd90877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78044860fd864586ad0a375424988368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de92a5cafd034ef3bd23b2d1de0cac6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b4ea22fddf4eb58cb5ec526cd5fa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26b8114f7664cbbb14b57725f523a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada29a512922451ca2b2fdee5966d4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"beomi/Llama-3-Open-Ko-8B\"\n",
    "# model_id =  \"NousResearch/Llama-2-7b-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441607e4-f93f-438e-8985-99a76233fe47",
   "metadata": {},
   "source": [
    "### 베이스 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f0471b-27a6-4cbb-a44c-f7e71aef3c39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "A federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France . University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro . Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro . The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "The court's order after video of fraternity students at the school engaged in a racist chant spread across the Internet .\n",
      "The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris .\n",
      "Meyer says she entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis .\n",
      "Swiss records show Meyer's father, Raoul Meyer,  had owned the painting in Paris .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "A federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France . University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro . Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro . The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "The federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "dialogue = test_data['article'][index]\n",
    "summary = test_data['highlights'][index]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "### Input:\n",
    "{dialogue}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=100,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd060a15-6c13-4c47-a34f-2648cdceab3a",
   "metadata": {},
   "source": [
    "### 모델을 LoRA 를 사용할 수 있게 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d6a3db-b8b3-4213-8914-b0f37eba1068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfdbfc-f5f5-4c00-8de2-24fc5fc8a58d",
   "metadata": {},
   "source": [
    "### PEFT 모델로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d716e1d4-a4c9-42ca-b8b3-a61cdc1f0249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], #specific to Llama models.\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe112b1-6bb2-40d4-8ff9-43e315ad0f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16777216 || all params: 3517190144 || trainable%: 0.477006226934315\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13dfc45-65a7-4997-81e4-52dcefcbdffa",
   "metadata": {},
   "source": [
    "## 4. 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ae17c43-d23e-4639-9a6c-a116f88da6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "OUTPUT_DIR = \"llama2-docsum-adapter\"\n",
    "epoch = 1\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=epoch,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    # report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9fb7f9-5a2a-42e0-875b-0c57b096a562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fadfd704c2e48e0b72313afa6f8b60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a5d72fe6f946d39fcdd3e800a2d9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a1f50a-9185-4043-a57d-39b272f1b694",
   "metadata": {},
   "source": [
    "## 5. 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef76c46-357b-4484-a6d3-6884045cb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 24:39, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>1.702714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.683600</td>\n",
       "      <td>1.681730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.650200</td>\n",
       "      <td>1.665679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.824100</td>\n",
       "      <td>1.664270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62, training_loss=1.7030385963378414, metrics={'train_runtime': 1506.7086, 'train_samples_per_second': 0.664, 'train_steps_per_second': 0.041, 'total_flos': 1.775314653954048e+16, 'train_loss': 1.7030385963378414, 'epoch': 0.99})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af4770-553a-4bba-a809-c40e4ff92373",
   "metadata": {},
   "source": [
    "## 6. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecfd8052-6448-4bee-ba32-e1120d54b2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-dialogue-summary/tokenizer_config.json',\n",
       " './peft-dialogue-summary/special_tokens_map.json',\n",
       " './peft-dialogue-summary/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path=\"./peft-dialogue-summary\"\n",
    "\n",
    "trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc3561d7-ad92-4e9a-a172-fe8cd85b0921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "total 66M\n",
      "drwxrwxr-x 2 ec2-user ec2-user  165 Jun 25 12:29 .\n",
      "drwxrwxr-x 5 ec2-user ec2-user  138 Jun 25 12:29 ..\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  650 Jun 25 12:30 adapter_config.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  65M Jun 25 12:30 adapter_model.safetensors\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 5.0K Jun 25 12:30 README.md\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  434 Jun 25 12:30 special_tokens_map.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  695 Jun 25 12:30 tokenizer_config.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 1.8M Jun 25 12:30 tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "! ls {peft_model_path} -al -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd98ed-f3a6-41ba-939c-9f54e65c17a8",
   "metadata": {},
   "source": [
    "## 7.Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22ba6172-d121-40df-a555-23a7d564f1d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec4e3e-cae5-40c1-8e5a-93c60a82e04c",
   "metadata": {},
   "source": [
    "### 훈련된 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f971571-2ec6-4e7d-b71a-b6ccbdc47666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18383fab8d6640978ee52d77f70b9269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "peft_model_dir = \"peft-dialogue-summary\"\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    peft_model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f049247-6160-41c6-b127-c8fad69fc210",
   "metadata": {},
   "source": [
    "### 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "742528e4-5208-406b-89ba-8307dc264ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 51\n",
    "\n",
    "dialogue = train_data['article'][index][:10000]\n",
    "summary = train_data['highlights'][index]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "### Input:\n",
    "{dialogue}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "def inference_model(tokenizer,prompt, model ):\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt',truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=200, )\n",
    "    output= tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
    "\n",
    "    dash_line = '-'.join('' for x in range(100))\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{prompt}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "    print(dash_line)\n",
    "    print(f'TRAINED MODEL GENERATED TEXT :\\n{output}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e642bb0-d131-4536-ae94-a2d37a43437e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "You might expect polar bears, the Artic Circle's apex predators, to be dab hands at dancing on ice. But as this specimen in Svalbard shows, even after thousands of years of evolutionary adaptation, some still suffer from two-left feet on the frozen ocean. Heinrich Eggenfellner, a 49-year-old videographer from Norway, said: 'I have encountered polar bears many times every year since I live up here and am used to them. 'This episode, however, was extraordinary.' Born slippy: A polar walks across thin sea ice in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the slippery surface . Spreading its weight: The polar bear does its best not to collapse through the fragile ice by spreading out . In its element: The beast finally gave up and pushed a hole in the ice to dive into the freezing water . Mr Eggenfellner and his friend Svein Wik spent hours in Norway's northernmost territory hunting for a polar bear to film and photograph, then hours more waiting for the slumbering beast to wake up. It was time well spent. The patient duo were treated to a farcical display of slipping and sliding across the frozen sea, with their subject falling flat on its face at least once. 'Maybe we waited 3-4 hours before the bear woke up and came out onto thinner and thinner ice,' Mr Wik told Caters News Agency. 'At one point, it spread out on all four legs to prevent falling thorough the ice until finally the bear gave up, pushed through the ice and started to swim. 'He dived for a few seconds and showed up again, looking up and then started to shake of the water.' Proud: Polar bears are the Arctic Circle's apex predators and have adapted to the habitat over millennia . Evolution: Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice . Brains: However this beast seems to have realised that big feet are not enough to stop it smashing through the thin ice and is trying to spread its weight to lessen the pressure beneath it . Weighty: Polar bears can weigh up to 1,100lbs, more than enough to smash through thin layers of frozen sea . Taking a dip: The polar bear pictured just after deciding it was better off taking a swim in the freezing sea . Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice. They can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea that would easily hold a man. Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of the most charismatic animals in the world. 'It was a rare and very interesting situation to watch everything and this was, without doubt, the ultimate wilderness experience for me.' Stunning: Photographer Svein Wik and videographer Heinrich Eggenfellner spent hours trying to find a polar bear to document in the stark frozen landscape of Svalbard, the Norwegian Arctic territory .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Polar bears have evolved special large, flat paws for walking on sea ice .\n",
      "But this specimen from Svalbard nevertheless struggled with its footing .\n",
      "The Arctic killer ventured off the thick ice that can support his weight .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TRAINED MODEL GENERATED TEXT :\n",
      "Polar bear is filmed slipping and sliding across thin sea ice in Svalbard, Norway .\n",
      "The beast falls flat on its face at least once as it tries to walk across the ice .\n",
      "It finally gives up and pushes a hole in the ice to dive into the freezing water .\n",
      "Polar bears are regarded as marine mammals because of the many months they spend at sea .\n",
      "They have adapted large, flat paws to distribute their bulk as they pad across thin ice .\n",
      "Polar bears can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea .\n",
      "\n",
      "### Input:\n",
      "Polar bears are regarded as marine mammals because of the many months they spend at sea .\n",
      "They have adapted large, flat paws to distribute their bulk as they pad across thin ice .\n",
      "Polar bears can weigh up to\n"
     ]
    }
   ],
   "source": [
    "inference_model(tokenizer = tokenizer,\n",
    "                prompt = prompt, \n",
    "                model = trained_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "084e2b86-aa67-4acf-b2d2-d197a2fc7c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "You might expect polar bears, the Artic Circle's apex predators, to be dab hands at dancing on ice. But as this specimen in Svalbard shows, even after thousands of years of evolutionary adaptation, some still suffer from two-left feet on the frozen ocean. Heinrich Eggenfellner, a 49-year-old videographer from Norway, said: 'I have encountered polar bears many times every year since I live up here and am used to them. 'This episode, however, was extraordinary.' Born slippy: A polar walks across thin sea ice in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the slippery surface . Spreading its weight: The polar bear does its best not to collapse through the fragile ice by spreading out . In its element: The beast finally gave up and pushed a hole in the ice to dive into the freezing water . Mr Eggenfellner and his friend Svein Wik spent hours in Norway's northernmost territory hunting for a polar bear to film and photograph, then hours more waiting for the slumbering beast to wake up. It was time well spent. The patient duo were treated to a farcical display of slipping and sliding across the frozen sea, with their subject falling flat on its face at least once. 'Maybe we waited 3-4 hours before the bear woke up and came out onto thinner and thinner ice,' Mr Wik told Caters News Agency. 'At one point, it spread out on all four legs to prevent falling thorough the ice until finally the bear gave up, pushed through the ice and started to swim. 'He dived for a few seconds and showed up again, looking up and then started to shake of the water.' Proud: Polar bears are the Arctic Circle's apex predators and have adapted to the habitat over millennia . Evolution: Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice . Brains: However this beast seems to have realised that big feet are not enough to stop it smashing through the thin ice and is trying to spread its weight to lessen the pressure beneath it . Weighty: Polar bears can weigh up to 1,100lbs, more than enough to smash through thin layers of frozen sea . Taking a dip: The polar bear pictured just after deciding it was better off taking a swim in the freezing sea . Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice. They can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea that would easily hold a man. Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of the most charismatic animals in the world. 'It was a rare and very interesting situation to watch everything and this was, without doubt, the ultimate wilderness experience for me.' Stunning: Photographer Svein Wik and videographer Heinrich Eggenfellner spent hours trying to find a polar bear to document in the stark frozen landscape of Svalbard, the Norwegian Arctic territory .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Polar bears have evolved special large, flat paws for walking on sea ice .\n",
      "But this specimen from Svalbard nevertheless struggled with its footing .\n",
      "The Arctic killer ventured off the thick ice that can support his weight .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TRAINED MODEL GENERATED TEXT :\n",
      "Polar bear caught on camera slipping and sliding across thin sea ice .\n",
      "Norwegian videographer Heinrich Eggenfellner filmed the beast .\n",
      "He said: 'I have encountered polar bears many times every year since I live up here and am used to them' .\n",
      "Mr Eggenfellner and his friend Svein Wik spent hours in Norway's northernmost territory hunting for a polar bear to film and photograph .\n",
      "They were treated to a farcical display of slipping and sliding across the frozen sea, with their subject falling flat on its face at least once .\n",
      "Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of the most charismatic animals in the world' .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inference_model(tokenizer = tokenizer,\n",
    "                prompt = prompt, \n",
    "                model = model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60aaa4-b654-49b3-bb87-34ad6a9f375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('pytorch_p310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2257b1c3513dc4782645ad49f694a4b0012bebbbbc3534a56d350db8e4f89a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
