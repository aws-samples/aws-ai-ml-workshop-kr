{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Hosting Strands Agents with Amazon Bedrock models in Amazon Bedrock AgentCore Runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will learn how to host your existing agent, using Amazon Bedrock AgentCore Runtime. We will provide examples using Amazon Bedrock models and non-Bedrock models such as Azure OpenAI and Gemini.\n",
    "\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "\n",
    "| Information         | Details                                                                          |\n",
    "|:--------------------|:---------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Conversational                                                                   |\n",
    "| Agent type          | Single                                                                           |\n",
    "| Agentic Framework   | Strands Agents                                                                   |\n",
    "| LLM model           | Anthropic Claude Sonnet 4                                                        |\n",
    "| Tutorial components | Hosting agent on AgentCore Runtime. Using Strands Agent and Amazon Bedrock Model |\n",
    "| Tutorial vertical   | Cross-vertical                                                                   |\n",
    "| Example complexity  | Easy                                                                             |\n",
    "| SDK used            | Amazon BedrockAgentCore Python SDK and boto3                                     |\n",
    "\n",
    "### Tutorial Architecture\n",
    "\n",
    "In this tutorial we will describe how to deploy an existing agent to AgentCore runtime. \n",
    "\n",
    "For demonstration purposes, we will  use a Strands Agent using Amazon Bedrock models\n",
    "\n",
    "In our example we will use a very simple agent with two tools: `get_weather` and `get_time`. \n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_runtime.png\" width=\"50%\"/>\n",
    "</div>\n",
    "\n",
    "### Tutorial Key Features\n",
    "\n",
    "* Hosting Agents on Amazon Bedrock AgentCore Runtime\n",
    "* Using Amazon Bedrock models\n",
    "* Using Strands Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To execute this tutorial you will need:\n",
    "* Python 3.10+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* Strands Agents\n",
    "* Docker running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#!uv add -r requirements.txt --active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## Creating your agents and experimenting locally\n",
    "\n",
    "Before we deploy our agents to AgentCore Runtime, let's develop and run them locally for experimentation purposes.\n",
    "\n",
    "For production agentic applications we will need to decouple the agent creation process from the agent invocation one. With AgentCore Runtime, we will decorate the invocation part of our agent with the `@app.entrypoint` decorator and have it as the entry point for our runtime. Let's first look how each agent is developed during the experimentation phase.\n",
    "\n",
    "The architecture here will look as following:\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_local.png\" width=\"50%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d386ab54e85e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting strands_claude_stream.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile strands_claude_stream.py\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from botocore.config import Config\n",
    "\n",
    "# You'll need to import these from your project\n",
    "# from src.utils.bedrock import bedrock_info\n",
    "\n",
    "class bedrock_info:\n",
    "    @staticmethod\n",
    "    def get_model_id(model_name):\n",
    "        # Placeholder - replace with actual implementation\n",
    "        model_mapping = {\n",
    "            \"Claude-V3-5-V-2-Sonnet-CRI\": \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "            \"Claude-V3-7-Sonnet-CRI\": \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        }\n",
    "        return model_mapping.get(model_name, model_name)\n",
    "\n",
    "def get_model(**kwargs):\n",
    "    llm_type = kwargs[\"llm_type\"]\n",
    "    cache_type = kwargs[\"cache_type\"]\n",
    "    enable_reasoning = kwargs[\"enable_reasoning\"]\n",
    "\n",
    "    if llm_type == \"reasoning\":    \n",
    "        llm = BedrockModel(\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-7-Sonnet-CRI\"),\n",
    "            streaming=True,\n",
    "            max_tokens=8192*5,\n",
    "            stop_sequences=[\"\\n\\nHuman\"],\n",
    "            temperature=1 if enable_reasoning else 0.01, \n",
    "            additional_request_fields={\n",
    "                \"thinking\": {\n",
    "                    \"type\": \"enabled\" if enable_reasoning else \"disabled\", \n",
    "                    **({\"budget_tokens\": 8192} if enable_reasoning else {}),\n",
    "                }\n",
    "            },\n",
    "            cache_prompt=cache_type,\n",
    "            boto_client_config=Config(\n",
    "                read_timeout=900,\n",
    "                connect_timeout=900,\n",
    "                retries=dict(max_attempts=50, mode=\"adaptive\"),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    elif llm_type == \"basic\":\n",
    "        llm = BedrockModel(\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-V-2-Sonnet-CRI\"),\n",
    "            streaming=True,\n",
    "            max_tokens=8192,\n",
    "            stop_sequences=[\"\\n\\nHuman\"],\n",
    "            temperature=0.01,\n",
    "            cache_prompt=cache_type,\n",
    "            boto_client_config=Config(\n",
    "                read_timeout=900,\n",
    "                connect_timeout=900,\n",
    "                retries=dict(max_attempts=50, mode=\"standard\"),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown LLM type: {llm_type}\")\n",
    "        \n",
    "    return llm\n",
    "\n",
    "class Colors:\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def apply_prompt_template(prompt_name: str, prompt_context={}) -> str:\n",
    "    try:\n",
    "        system_prompts = open(os.path.join(\"./prompts\", f\"{prompt_name}.md\")).read()    \n",
    "    except FileNotFoundError:\n",
    "        # Fallback system prompt\n",
    "        system_prompts = \"You are a helpful AI assistant.\"\n",
    "    \n",
    "    context = {\"CURRENT_TIME\": datetime.now().strftime(\"%a %b %d %Y %H:%M:%S %z\")}\n",
    "    context.update(prompt_context)\n",
    "    system_prompts = system_prompts.format(**context)\n",
    "    return system_prompts\n",
    "\n",
    "def get_agent(**kwargs):\n",
    "    agent_name, system_prompts = kwargs[\"agent_name\"], kwargs[\"system_prompts\"]\n",
    "    agent_type = kwargs.get(\"agent_type\", \"basic\")\n",
    "    prompt_cache_info = kwargs.get(\"prompt_cache_info\", (False, None))\n",
    "    tools = kwargs.get(\"tools\", None)\n",
    "    streaming = kwargs.get(\"streaming\", True)\n",
    "        \n",
    "    if \"reasoning\" in agent_type: \n",
    "        enable_reasoning = True\n",
    "    else: \n",
    "        enable_reasoning = False\n",
    "\n",
    "    prompt_cache, cache_type = prompt_cache_info\n",
    "    if prompt_cache: \n",
    "        print(f\"{Colors.GREEN}{agent_name.upper()} - Prompt Cache Enabled{Colors.END}\")\n",
    "    else: \n",
    "        print(f\"{Colors.GREEN}{agent_name.upper()} - Prompt Cache Disabled{Colors.END}\")\n",
    "\n",
    "    llm = get_model(llm_type=agent_type, cache_type=cache_type, enable_reasoning=enable_reasoning)\n",
    "    llm.config[\"streaming\"] = streaming\n",
    "\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        system_prompt=system_prompts,\n",
    "        tools=tools,\n",
    "        callback_handler=None\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "async def _convert_to_agentcore_event(\n",
    "    strands_event: Dict[str, Any],\n",
    "    agent_name: str,\n",
    "    session_id: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Strands Ïù¥Î≤§Ìä∏Î•º AgentCore Ïä§Ìä∏Î¶¨Î∞ç ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\"\"\"\n",
    "    \n",
    "    base_event = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"session_id\": session_id,\n",
    "        \"agent_name\": agent_name,\n",
    "        \"source\": \"strands_data_analysis_graph\"\n",
    "    }\n",
    "    \n",
    "    # ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Ïù¥Î≤§Ìä∏\n",
    "    if \"data\" in strands_event:\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_text_stream\",\n",
    "            \"event_type\": \"text_chunk\",\n",
    "            \"data\": strands_event[\"data\"],\n",
    "            \"chunk_size\": len(strands_event[\"data\"])\n",
    "        }\n",
    "    \n",
    "    # ÎèÑÍµ¨ ÏÇ¨Ïö© Ïù¥Î≤§Ìä∏\n",
    "    elif \"current_tool_use\" in strands_event:\n",
    "        tool_info = strands_event[\"current_tool_use\"]\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_tool_stream\",\n",
    "            \"event_type\": \"tool_use\",\n",
    "            \"tool_name\": tool_info.get(\"name\", \"unknown\"),\n",
    "            \"tool_id\": tool_info.get(\"toolUseId\"),\n",
    "            \"tool_input\": tool_info.get(\"input\", {})\n",
    "        }\n",
    "    \n",
    "    # Ï∂îÎ°† Ïù¥Î≤§Ìä∏\n",
    "    elif \"reasoning\" in strands_event and strands_event.get(\"reasoning\"):\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_reasoning_stream\",\n",
    "            \"event_type\": \"reasoning\",\n",
    "            \"reasoning_text\": strands_event.get(\"reasoningText\", \"\")[:200]\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "async def process_agent_stream(agent, message):\n",
    "    coordinator_result = \"\"\n",
    "    agent_stream = agent.stream_async(message)\n",
    "    session_id = \"123\"\n",
    "\n",
    "    async for event in agent_stream:\n",
    "        #Strands Ïù¥Î≤§Ìä∏Î•º AgentCore ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "        agentcore_event = await _convert_to_agentcore_event(\n",
    "            event, \"coordinator\", session_id\n",
    "        )\n",
    "        if agentcore_event:\n",
    "            yield agentcore_event\n",
    "\n",
    "            # Í≤∞Í≥º ÌÖçÏä§Ìä∏ ÎàÑÏ†Å\n",
    "            if agentcore_event.get(\"event_type\") == \"text_chunk\":\n",
    "                coordinator_result += agentcore_event.get(\"data\", \"\")\n",
    "\n",
    "async def node(agent, message):\n",
    "    async for event in process_agent_stream(agent, message):\n",
    "        yield event\n",
    "\n",
    "# Create agent instance\n",
    "agent = get_agent(\n",
    "    agent_name=\"task_agent\",\n",
    "    system_prompts=apply_prompt_template(prompt_name=\"task_agent\", prompt_context={}),\n",
    "    agent_type=\"reasoning\",\n",
    "    prompt_cache_info=(True, \"default\"),\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "async def strands_agent_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    async for event in node(agent, user_input):\n",
    "        #print(f\"Event: {event}\")\n",
    "        yield event\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    async def main():\n",
    "        async for event in strands_agent_bedrock(json.loads(args.payload)):\n",
    "            print(f\"Final event: {event}\")\n",
    "    \n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68499675-db8d-47c6-8c0c-5d66dcb06229",
   "metadata": {},
   "source": [
    "#### Invoking local agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1226d59e6b56c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:52:06.461281Z",
     "start_time": "2025-06-29T21:52:06.456854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTASK_AGENT - Prompt Cache Enabled\u001b[0m\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.176343', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'The'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.176569', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' user has'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.176851', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' greeted me'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.176884', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' in Korean'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.177027', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ', saying'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.177056', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' \"I'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.177080', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' am J'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.177440', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'ang Don'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.177594', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'gjin\"'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.177751', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' (ÎÇò'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.177921', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'Îäî Ïû•Îèô'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.178078', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'ÏßÑÏù¥Ïïº).'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.178303', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': '\\n\\nThis'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:52.178332', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' is a simple'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.358994', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' greeting/introduction, so'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.359046', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' I don'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.359815', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': \"'t nee\"}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.360047', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'd to use'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.360327', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' any of the tools'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.360629', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' for this.'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.361183', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' I shoul'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.361777', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'd respond in a friendly manner'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.362458', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ', acknowle'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.362916', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': \"dging the user's\"}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.363905', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' introduction.'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.364333', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' Since the'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.365984', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' user has written to'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.366151', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' me in Korean,'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.366648', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': \" I'll respond in\"}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.367292', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' Korean as well,'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.368132', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' but I'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.368938', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': \"'ll also\"}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.369587', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' include English'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.370452', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' to ensure clear'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.371356', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' communication.'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.372523', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': '\\n\\nLet me craft'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.373348', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' a friendly response'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.373531', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ':'}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.374245', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ''}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.376058', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'ÏïàÎÖïÌïòÏÑ∏', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.376246', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'Ïöî, Ïû•', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.376412', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'ÎèôÏßÑÎãò', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.376780', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '! Îßå', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.377191', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'ÎÇòÏÑú Î∞ò', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.378101', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'Í∞ëÏäµÎãàÎã§', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.378470', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '.\\n\\nHello, Jang', 'chunk_size': 14}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.378967', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' Dongjin', 'chunk_size': 8}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.379792', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': \"! It's nice\", 'chunk_size': 11}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.380643', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' to meet you.', 'chunk_size': 13}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.381328', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': \" I'm\", 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.381968', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' Bedrock-Manus, an', 'chunk_size': 18}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.382545', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' AI assistant develope', 'chunk_size': 22}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.383520', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'd by AWS AIML Specialist', 'chunk_size': 24}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.383936', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' SA Dongjin', 'chunk_size': 11}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.384844', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' Jang.', 'chunk_size': 6}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.387435', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' How can I help', 'chunk_size': 15}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.387592', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' you today? Feel', 'chunk_size': 16}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.387747', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' free to ask me questions', 'chunk_size': 25}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.387899', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' or let me know if you', 'chunk_size': 22}\n",
      "Final event: {'timestamp': '2025-08-23T11:12:55.388038', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' need assistance with anything.', 'chunk_size': 31}\n"
     ]
    }
   ],
   "source": [
    "!python strands_claude_stream.py '{\"prompt\": \"ÎÇòÎäî Ïû•ÎèôÏßÑÏù¥Ïïº\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## Preparing your agent for deployment on AgentCore Runtime\n",
    "\n",
    "Let's now deploy our agents to AgentCore Runtime. To do so we need to:\n",
    "* Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "* Initialize the App in our code with `app = BedrockAgentCoreApp()`\n",
    "* Decorate the invocation function with the `@app.entrypoint` decorator\n",
    "* Let AgentCoreRuntime control the running of the agent with `app.run()`\n",
    "\n",
    "### Strands Agents with Amazon Bedrock model\n",
    "Let's start with our Strands Agent using Amazon Bedrock model. All the others will work exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile strands_claude.py\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator # Import the calculator tool\n",
    "import argparse\n",
    "import json\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Create a custom tool \n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\" Get weather \"\"\" # Dummy implementation\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "model_id = \"us.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    ")\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    tools=[calculator, weather],\n",
    "    system_prompt=\"You're a helpful assistant. You can do simple math calculation, and tell the weather.\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def strands_agent_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    print(\"User input:\", user_input)\n",
    "    response = agent(user_input)\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b381a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting strands_claude_stream.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile strands_claude_stream.py\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "\n",
    "# You'll need to import these from your project\n",
    "# from src.utils.bedrock import bedrock_info\n",
    "\n",
    "class bedrock_info:\n",
    "    @staticmethod\n",
    "    def get_model_id(model_name):\n",
    "        # Placeholder - replace with actual implementation\n",
    "        model_mapping = {\n",
    "            \"Claude-V3-5-V-2-Sonnet-CRI\": \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "            \"Claude-V3-7-Sonnet-CRI\": \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        }\n",
    "        return model_mapping.get(model_name, model_name)\n",
    "\n",
    "def get_model(**kwargs):\n",
    "    llm_type = kwargs[\"llm_type\"]\n",
    "    cache_type = kwargs[\"cache_type\"]\n",
    "    enable_reasoning = kwargs[\"enable_reasoning\"]\n",
    "\n",
    "    if llm_type == \"reasoning\":    \n",
    "        llm = BedrockModel(\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-7-Sonnet-CRI\"),\n",
    "            streaming=True,\n",
    "            max_tokens=8192*5,\n",
    "            stop_sequences=[\"\\n\\nHuman\"],\n",
    "            temperature=1 if enable_reasoning else 0.01, \n",
    "            additional_request_fields={\n",
    "                \"thinking\": {\n",
    "                    \"type\": \"enabled\" if enable_reasoning else \"disabled\", \n",
    "                    **({\"budget_tokens\": 8192} if enable_reasoning else {}),\n",
    "                }\n",
    "            },\n",
    "            cache_prompt=cache_type,\n",
    "            boto_client_config=Config(\n",
    "                read_timeout=900,\n",
    "                connect_timeout=900,\n",
    "                retries=dict(max_attempts=50, mode=\"adaptive\"),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    elif llm_type == \"basic\":\n",
    "        llm = BedrockModel(\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-V-2-Sonnet-CRI\"),\n",
    "            streaming=True,\n",
    "            max_tokens=8192,\n",
    "            stop_sequences=[\"\\n\\nHuman\"],\n",
    "            temperature=0.01,\n",
    "            cache_prompt=cache_type,\n",
    "            boto_client_config=Config(\n",
    "                read_timeout=900,\n",
    "                connect_timeout=900,\n",
    "                retries=dict(max_attempts=50, mode=\"standard\"),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown LLM type: {llm_type}\")\n",
    "        \n",
    "    return llm\n",
    "\n",
    "class Colors:\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def apply_prompt_template(prompt_name: str, prompt_context={}) -> str:\n",
    "    try:\n",
    "        system_prompts = open(os.path.join(\"./prompts\", f\"{prompt_name}.md\")).read()    \n",
    "    except FileNotFoundError:\n",
    "        # Fallback system prompt\n",
    "        system_prompts = \"You are a helpful AI assistant.\"\n",
    "    \n",
    "    context = {\"CURRENT_TIME\": datetime.now().strftime(\"%a %b %d %Y %H:%M:%S %z\")}\n",
    "    context.update(prompt_context)\n",
    "    system_prompts = system_prompts.format(**context)\n",
    "    return system_prompts\n",
    "\n",
    "def get_agent(**kwargs):\n",
    "    agent_name, system_prompts = kwargs[\"agent_name\"], kwargs[\"system_prompts\"]\n",
    "    agent_type = kwargs.get(\"agent_type\", \"basic\")\n",
    "    prompt_cache_info = kwargs.get(\"prompt_cache_info\", (False, None))\n",
    "    tools = kwargs.get(\"tools\", None)\n",
    "    streaming = kwargs.get(\"streaming\", True)\n",
    "        \n",
    "    if \"reasoning\" in agent_type: \n",
    "        enable_reasoning = True\n",
    "    else: \n",
    "        enable_reasoning = False\n",
    "\n",
    "    prompt_cache, cache_type = prompt_cache_info\n",
    "    if prompt_cache: \n",
    "        print(f\"{Colors.GREEN}{agent_name.upper()} - Prompt Cache Enabled{Colors.END}\")\n",
    "    else: \n",
    "        print(f\"{Colors.GREEN}{agent_name.upper()} - Prompt Cache Disabled{Colors.END}\")\n",
    "\n",
    "    llm = get_model(llm_type=agent_type, cache_type=cache_type, enable_reasoning=enable_reasoning)\n",
    "    llm.config[\"streaming\"] = streaming\n",
    "\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        system_prompt=system_prompts,\n",
    "        tools=tools,\n",
    "        callback_handler=None\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "async def _convert_to_agentcore_event(\n",
    "    strands_event: Dict[str, Any],\n",
    "    agent_name: str,\n",
    "    session_id: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Strands Ïù¥Î≤§Ìä∏Î•º AgentCore Ïä§Ìä∏Î¶¨Î∞ç ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\"\"\"\n",
    "    \n",
    "    base_event = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"session_id\": session_id,\n",
    "        \"agent_name\": agent_name,\n",
    "        \"source\": \"strands_data_analysis_graph\"\n",
    "    }\n",
    "    \n",
    "    # ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Ïù¥Î≤§Ìä∏\n",
    "    if \"data\" in strands_event:\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_text_stream\",\n",
    "            \"event_type\": \"text_chunk\",\n",
    "            \"data\": strands_event[\"data\"],\n",
    "            \"chunk_size\": len(strands_event[\"data\"])\n",
    "        }\n",
    "    \n",
    "    # ÎèÑÍµ¨ ÏÇ¨Ïö© Ïù¥Î≤§Ìä∏\n",
    "    elif \"current_tool_use\" in strands_event:\n",
    "        tool_info = strands_event[\"current_tool_use\"]\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_tool_stream\",\n",
    "            \"event_type\": \"tool_use\",\n",
    "            \"tool_name\": tool_info.get(\"name\", \"unknown\"),\n",
    "            \"tool_id\": tool_info.get(\"toolUseId\"),\n",
    "            \"tool_input\": tool_info.get(\"input\", {})\n",
    "        }\n",
    "    \n",
    "    # Ï∂îÎ°† Ïù¥Î≤§Ìä∏\n",
    "    elif \"reasoning\" in strands_event and strands_event.get(\"reasoning\"):\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_reasoning_stream\",\n",
    "            \"event_type\": \"reasoning\",\n",
    "            \"reasoning_text\": strands_event.get(\"reasoningText\", \"\")[:200]\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "async def process_agent_stream(agent, message):\n",
    "    coordinator_result = \"\"\n",
    "    agent_stream = agent.stream_async(message)\n",
    "    session_id = \"123\"\n",
    "\n",
    "    async for event in agent_stream:\n",
    "        #Strands Ïù¥Î≤§Ìä∏Î•º AgentCore ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "        agentcore_event = await _convert_to_agentcore_event(\n",
    "            event, \"coordinator\", session_id\n",
    "        )\n",
    "        if agentcore_event:\n",
    "            yield agentcore_event\n",
    "\n",
    "            # Í≤∞Í≥º ÌÖçÏä§Ìä∏ ÎàÑÏ†Å\n",
    "            if agentcore_event.get(\"event_type\") == \"text_chunk\":\n",
    "                coordinator_result += agentcore_event.get(\"data\", \"\")\n",
    "\n",
    "async def node(agent, message):\n",
    "    async for event in process_agent_stream(agent, message):\n",
    "        yield event\n",
    "\n",
    "# Create agent instance\n",
    "agent = get_agent(\n",
    "    agent_name=\"task_agent\",\n",
    "    system_prompts=apply_prompt_template(prompt_name=\"task_agent\", prompt_context={}),\n",
    "    agent_type=\"reasoning\",\n",
    "    prompt_cache_info=(True, \"default\"),\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "async def strands_agent_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    async for event in node(agent, user_input):\n",
    "        #print(f\"Event: {event}\")\n",
    "        #yield f\"ss:{event}\"\n",
    "        if \"data\" in event:\n",
    "            yield event[\"data\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    app.run()\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"payload\", type=str)\n",
    "    # args = parser.parse_args()\n",
    "    \n",
    "    # async def main():\n",
    "    #     async for event in strands_agent_bedrock(json.loads(args.payload)):\n",
    "    #         print(f\"Final event: {event}\")\n",
    "    \n",
    "    # asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "## What happens behind the scenes?\n",
    "\n",
    "When you use `BedrockAgentCoreApp`, it automatically:\n",
    "\n",
    "* Creates an HTTP server that listens on the port 8080\n",
    "* Implements the required `/invocations` endpoint for processing the agent's requirements\n",
    "* Implements the `/ping` endpoint for health checks (very important for asynchronous agents)\n",
    "* Handles proper content types and response formats\n",
    "* Manages error handling according to the AWS standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "## Deploying the agent to AgentCore Runtime\n",
    "\n",
    "The `CreateAgentRuntime` operation supports comprehensive configuration options, letting you specify container images, environment variables and encryption settings. You can also configure protocol settings (HTTP, MCP) and authorization mechanisms to control how your clients communicate with the agent. \n",
    "\n",
    "**Note:** Operations best practice is to package code as container and push to ECR using CI/CD pipelines and IaC\n",
    "\n",
    "In this tutorial can will the Amazon Bedrock AgentCore Python SDK to easily package your artifacts and deploy them to AgentCore runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0861401-a111-4ade-9e02-50f52fdfa9b1",
   "metadata": {},
   "source": [
    "### Creating runtime role\n",
    "\n",
    "Before starting, let's create an IAM role for our AgentCore Runtime. We will do so using the utils function pre-developed for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0]: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials\n",
      "Role already exists -- deleting and creating it again\n",
      "policies: {'PolicyNames': ['AgentCorePolicy'], 'IsTruncated': False, 'ResponseMetadata': {'RequestId': '9f9b4e3d-7cbf-4a88-9526-6c2f77655df5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 23 Aug 2025 11:23:34 GMT', 'x-amzn-requestid': '9f9b4e3d-7cbf-4a88-9526-6c2f77655df5', 'content-type': 'text/xml', 'content-length': '380'}, 'RetryAttempts': 0}}\n",
      "deleting agentcore-agentcore_strands-role\n",
      "recreating agentcore-agentcore_strands-role\n",
      "attaching role policy agentcore-agentcore_strands-role\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook's directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "\n",
    "utils_dir = os.path.join(current_dir, '..')\n",
    "utils_dir = os.path.join(utils_dir, '..')\n",
    "utils_dir = os.path.abspath(utils_dir)\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, utils_dir)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from utils import create_agentcore_role\n",
    "\n",
    "agent_name=\"agentcore_strands\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "### Configure AgentCore Runtime deployment\n",
    "\n",
    "Next we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/configure.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials/01-AgentCore-runtime/01-hosting-agent/01-strands-with-bedrock-model/strands_claude_stream.py, bedrock_agentcore_name=strands_claude_stream\n",
      "Configuring BedrockAgentCore agent: agentcore_strands\n",
      "Generated Dockerfile: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials/01-AgentCore-runtime/01-hosting-agent/01-strands-with-bedrock-model/Dockerfile\n",
      "Generated .dockerignore: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials/01-AgentCore-runtime/01-hosting-agent/01-strands-with-bedrock-model/.dockerignore\n",
      "Keeping 'agentcore_strands' as default agent\n",
      "Bedrock AgentCore configured: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials/01-AgentCore-runtime/01-hosting-agent/01-strands-with-bedrock-model/.bedrock_agentcore.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigureResult(config_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials/01-AgentCore-runtime/01-hosting-agent/01-strands-with-bedrock-model/.bedrock_agentcore.yaml'), dockerfile_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials/01-AgentCore-runtime/01-hosting-agent/01-strands-with-bedrock-model/Dockerfile'), dockerignore_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/13_agentcore/tutorials/01-AgentCore-runtime/01-hosting-agent/01-strands-with-bedrock-model/.dockerignore'), runtime='Docker', region='us-west-2', account_id='615299776985', execution_role='arn:aws:iam::615299776985:role/agentcore-agentcore_strands-role', ecr_repository=None, auto_create_ecr=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "region\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"strands_claude_stream.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### Launching agent to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "   ‚Ä¢ Build ARM64 containers in the cloud with CodeBuild\n",
      "   ‚Ä¢ No local Docker required\n",
      "üí° Available deployment modes:\n",
      "   ‚Ä¢ runtime.launch()                           ‚Üí CodeBuild (current)\n",
      "   ‚Ä¢ runtime.launch(local=True)                 ‚Üí Local development\n",
      "   ‚Ä¢ runtime.launch(local_build=True)           ‚Üí Local build + cloud deploy (NEW)\n",
      "Starting CodeBuild ARM64 deployment for agent 'agentcore_strands' to account 615299776985 (us-west-2)\n",
      "Starting CodeBuild ARM64 deployment for agent 'agentcore_strands' to account 615299776985 (us-west-2)\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: agentcore_strands\n",
      "‚úÖ ECR repository available: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-agentcore_strands\n",
      "Using execution role from config: arn:aws:iam::615299776985:role/agentcore-agentcore_strands-role\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reusing existing ECR repository: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-agentcore_strands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚úÖ Execution role validation passed: arn:aws:iam::615299776985:role/agentcore-agentcore_strands-role\n",
      "Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: agentcore_strands\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-5b70b9d456\n",
      "Reusing existing CodeBuild execution role: arn:aws:iam::615299776985:role/AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-5b70b9d456\n",
      "Using .dockerignore with 44 patterns\n",
      "Uploaded source to S3: agentcore_strands/20250823-112336.zip\n",
      "Updated CodeBuild project: bedrock-agentcore-agentcore_strands-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "üîÑ QUEUED started (total: 0s)\n",
      "‚úÖ QUEUED completed in 5.0s\n",
      "üîÑ PROVISIONING started (total: 5s)\n",
      "‚úÖ PROVISIONING completed in 10.1s\n",
      "üîÑ PRE_BUILD started (total: 15s)\n",
      "‚úÖ PRE_BUILD completed in 10.1s\n",
      "üîÑ BUILD started (total: 25s)\n",
      "‚úÖ BUILD completed in 60.3s\n",
      "üîÑ POST_BUILD started (total: 86s)\n",
      "‚úÖ POST_BUILD completed in 10.1s\n",
      "üîÑ COMPLETED started (total: 96s)\n",
      "‚úÖ COMPLETED completed in 0.0s\n",
      "üéâ CodeBuild completed successfully in 1m 35s\n",
      "CodeBuild completed successfully\n",
      "‚úÖ CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "‚ö†Ô∏è Session ID will be reset to connect to the updated agent. The previous agent remains accessible via the original session ID: de1545fd-0eba-4444-b199-ac16d53f4ab0\n",
      "‚úÖ Agent created/updated: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/agentcore_strands-R7MnezAFRn\n",
      "Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/agentcore_strands-R7MnezAFRn/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/agentcore_strands-R7MnezAFRn\n",
      "Built with CodeBuild: bedrock-agentcore-agentcore_strands-builder:689bb54a-ebb3-4aca-96c1-d41c2bf2a315\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/agentcore_strands-R7MnezAFRn\n",
      "ECR image: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-agentcore_strands\n",
      "üîç Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/agentcore_strands-R7MnezAFRn-DEFAULT\n",
      "   /aws/bedrock-agentcore/runtimes/agentcore_strands-R7MnezAFRn-DEFAULT/runtime-logs\n",
      "üí° Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/agentcore_strands-R7MnezAFRn-DEFAULT --follow\n",
      "üí° Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/agentcore_strands-R7MnezAFRn-DEFAULT --since 1h\n"
     ]
    }
   ],
   "source": [
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "### Checking for the AgentCore Runtime Status\n",
    "Now that we've deployed the AgentCore Runtime, let's check for it's deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: agentcore_strands\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'READY'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime\n",
    "\n",
    "Finally, we can invoke our AgentCore Runtime with a payload\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/invoke.png\" width=75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "796d9857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invoking BedrockAgentCore agent 'agentcore_strands' via cloud endpoint\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏïàÎÖïÌïò</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏïàÎÖïÌïò\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏÑ∏Ïöî,</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏÑ∏Ïöî,\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Ïû•</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Ïû•\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÎèôÏßÑÎãò</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎèôÏßÑÎãò\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">! Îßå</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m! Îßå\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÎÇòÏÑú Î∞ò</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎÇòÏÑú Î∞ò\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Í∞ëÏäµÎãàÎã§</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÍ∞ëÏäµÎãàÎã§\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">.</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m.\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Ï†ÄÎäî </span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Ï†ÄÎäî \u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">AI Ïñ¥Ïãú</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mAI Ïñ¥Ïãú\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïä§ÌÑ¥Ìä∏</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏä§ÌÑ¥Ìä∏\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏûÖÎãàÎã§.</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏûÖÎãàÎã§.\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Ïò§</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Ïò§\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Îäò Ïñ¥</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎäò Ïñ¥\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Îñª</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎñª\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Í≤å ÎèÑÏôÄ</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÍ≤å ÎèÑÏôÄ\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÎìúÎ¶¥Íπå</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎìúÎ¶¥Íπå\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïöî?</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏöî?\u001b[0m\n",
       "\n",
       "\u001b[1;36m(\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Hello, J</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mHello, J\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ang Dongj</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mang Dongj\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">in! Nice</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36min! Nice\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> to meet you.</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m to meet you.\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> I am an AI</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m I am an AI\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> assistant. How can</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m assistant. How can\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> I help</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m I help\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> you today?)</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m you today?\u001b[0m\u001b[1;36m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for event in agentcore_runtime.invoke({\"prompt\": \"ÏïàÎÖï ÎÇòÎäî Ïû•ÎèôÏßÑÏù¥Ïïº\"}):\n",
    "    print (\"11\", event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invoking BedrockAgentCore agent 'agentcore_strands' via cloud endpoint\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏïàÎÖïÌïòÏÑ∏</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏïàÎÖïÌïòÏÑ∏\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïöî Ïû•</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏöî Ïû•\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÎèôÏßÑÎãò</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎèôÏßÑÎãò\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">, Îã§</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m, Îã§\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïãú Ïù∏</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏãú Ïù∏\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏÇ¨Îìú</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏÇ¨Îìú\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Î¶ΩÎãàÎã§!</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎ¶ΩÎãàÎã§!\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Î¨¥</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Î¨¥\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏóáÏùÑ </span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏóáÏùÑ \u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÎèÑÏôÄÎìú</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎèÑÏôÄÎìú\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Î¶¥ÍπåÏöî?</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎ¶¥ÍπåÏöî?\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> </span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m \u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïßà</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏßà\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Î¨∏Ïù¥ Ïûà</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎ¨∏Ïù¥ Ïûà\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏúºÏãú</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏúºÏãú\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Í±∞</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÍ±∞\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÎÇò</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎÇò\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> ÎåÄ</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m ÎåÄ\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÌôîÎ•º ÎÇò</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÌôîÎ•º ÎÇò\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÎàÑÍ≥† </span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÎàÑÍ≥† \u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïã∂Ïúº</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏã∂Ïúº\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïã†</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏã†\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Ï£º</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Ï£º\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ï†úÍ∞Ä Ïûà</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏ†úÍ∞Ä Ïûà\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ÏúºÏã†</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏúºÏã†\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Í∞Ä</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÍ∞Ä\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Ïöî?</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mÏöî?\u001b[0m\n",
       "\n",
       "\u001b[1;36m(\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Hello Mr</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mHello Mr\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">. Jang</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m. Jang\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Dongjin</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Dongjin\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">, greeting you</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m, greeting you\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> again! How</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m again! How\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> can I help you</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m can I help you\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">? Do you have</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m? Do you have\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> any questions or topics</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m any questions or topics\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> you'd like to</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m you'd like to\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> discuss?)</span></pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m discuss?\u001b[0m\u001b[1;36m)\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"ÏïàÎÖï ÎÇòÎäî Ïû•ÎèôÏßÑÏù¥Ïïº\"})\n",
    "#invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa840a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "### Processing invocation results\n",
    "\n",
    "We can now process our invocation results to include it in an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249103-cfb3-47b5-970d-981a977a225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "response_text = json.loads(invoke_response['response'][0].decode(\"utf-8\"))\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime with boto3\n",
    "\n",
    "Now that your AgentCore Runtime was created you can invoke it with any AWS SDK. For instance, you can use the boto3 `invoke_agent_runtime` method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84e68d-6c04-41b9-bf5b-60edc3fa0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps({\"prompt\": \"What is 2+2?\"})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        if line:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data: \"):\n",
    "                line = line[6:]\n",
    "                logger.info(line)\n",
    "                content.append(line)\n",
    "    display(Markdown(\"\\n\".join(content)))\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c243e86-a214-483c-aef1-d5243f28ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id,\n",
    "    \n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "iam_response = iam_client.delete_role(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-bedrock-agentcore (UV)",
   "language": "python",
   "name": "env-bedrock-agentcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
