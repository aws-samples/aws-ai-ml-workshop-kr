import sys, os
module_path = ".."
sys.path.append(os.path.abspath(module_path))

import inspect
import streamlit as st
from typing import Callable, TypeVar
from streamlit.delta_generator import DeltaGenerator
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from streamlit.runtime.scriptrunner import add_script_run_ctx, get_script_run_ctx

##################### Title ########################
st.set_page_config(page_title="GenAI-driven Analytics ğŸ’¬", page_icon="ğŸ’¬", layout="wide")
st.title("GenAI-driven Analytics ğŸ’¬")
st.markdown('''- This chatbot is implemented using Amazon Bedrock Claude v3.5 Sonnet.''')
st.markdown('''
            - You can find the source code in 
            [this Github](https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/20_applications/09_genai_analytics)
            ''')

from main import execution
import io

##################### Functions ########################
def display_chat_history():
    node_names = ["coordinator", "planner", "supervisor", "coder", "reporter"]
    node_descriptions = {
        "coordinator": "ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¡°ì • ë° ìµœì¢… ì‘ë‹µ ìƒì„±",
        "planner": "ë¶„ì„ ê³„íš ìˆ˜ë¦½ ë° ì‘ì—… ë¶„ë°°",
        "supervisor": "ì½”ë“œ ë° ê²°ê³¼ë¬¼ ê²€ì¦",
        "coder": "ë°ì´í„° ì²˜ë¦¬ ë° ì‹œê°í™” ì½”ë“œ ì‘ì„±",
        "reporter": "ë¶„ì„ ê²°ê³¼ í•´ì„ ë° ë³´ê³ ì„œ ì‘ì„±"
    }
    
    st.session_state["history_ask"].append(st.session_state["recent_ask"])

    recent_answer = {}
    for node_name in node_names:
        print("node_name", node_name)
        if node_name != "chart_generation": 
            recent_answer[node_name] = st.session_state["ai_results"][node_name].get("text", "None")
        else:
            if st.session_state["ai_results"][node_name] != {}:
                recent_answer[node_name] = io.BytesIO(st.session_state["ai_results"][node_name])
            else: 
                recent_answer[node_name] = "None"
        st.session_state["ai_results"][node_name] = {} ## reset
    st.session_state["history_answer"].append(recent_answer)

    for i, (user, assistant) in enumerate(zip(st.session_state["history_ask"], st.session_state["history_answer"])):
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.write(user)
        
        # ì‘ë‹µ í‘œì‹œ - ì „ì²´ í™”ë©´ìœ¼ë¡œ
        with st.chat_message("assistant"):
            # ê°€ì¥ ì¤‘ìš”í•œ ê²°ê³¼ë¥¼ ë¨¼ì € í‘œì‹œ
            st.write(assistant["coordinator"])
            
            # êµ¬ë¶„ì„  ì¶”ê°€
            st.divider()
            
            st.subheader("Process Details")
            
            # ê° ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í‘œì‹œ
            for node_name in node_names:
                if node_name != "coordinator":  # coordinatorëŠ” ì´ë¯¸ í‘œì‹œí–ˆìœ¼ë¯€ë¡œ ì œì™¸
                    with st.expander(f"ğŸ¤– {node_name.upper()}: {node_descriptions[node_name]}", expanded=False):
                        if node_name == "chart_generation" and assistant[node_name] != "None":
                            st.image(assistant[node_name])
                        else:
                            st.write(assistant[node_name])

T = TypeVar("T")
def get_streamlit_cb(parent_container: DeltaGenerator):
    
    def decor(fn: Callable[..., T]) -> Callable[..., T]:
        ctx = get_script_run_ctx()

        def wrapper(*args, **kwargs) -> T:
            add_script_run_ctx(ctx=ctx)
            return fn(*args, **kwargs)

        return wrapper

    st_cb = StreamlitCallbackHandler(parent_container=parent_container)

    for name, fn in inspect.getmembers(st_cb, predicate=inspect.ismethod):
        if name.startswith("on_"):
            setattr(st_cb, name, decor(fn))

    return st_cb

####################### Initialization ###############################
# Store the initial value of widgets in session state
if "messages" not in st.session_state: st.session_state["messages"] = []
if "history_ask" not in st.session_state: st.session_state["history_ask"] = []
if "history_answer" not in st.session_state: st.session_state["history_answer"] = []
if "ai_results" not in st.session_state: st.session_state["ai_results"] = {"coordinator": {}, "planner": {}, "supervisor": {}, "coder": {}, "reporter": {}}

for i in range(10):
    if f"ph{i}" not in st.session_state: st.session_state[f"ph{i}"] = st.empty()
    
####################### Application ###############################
if len(st.session_state["history_ask"]) > 0: 
    display_chat_history()

if user_input := st.chat_input(): # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    st.chat_message("user").write(user_input)
    st.session_state["recent_ask"] = user_input
    
    node_names = ["coordinator", "planner", "supervisor", "coder", "reporter"]
    node_descriptions = {
        "coordinator": "ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¡°ì • ë° ìµœì¢… ì‘ë‹µ ìƒì„±",
        "planner": "ë¶„ì„ ê³„íš ìˆ˜ë¦½ ë° ì‘ì—… ë¶„ë°°",
        "supervisor": "ì½”ë“œ ë° ê²°ê³¼ë¬¼ ê²€ì¦",
        "coder": "ë°ì´í„° ì²˜ë¦¬ ë° ì‹œê°í™” ì½”ë“œ ì‘ì„±",
        "reporter": "ë¶„ì„ ê²°ê³¼ í•´ì„ ë° ë³´ê³ ì„œ ì‘ì„±"
    }
    
    # ì‘ë‹µ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    with st.chat_message("assistant"):
        # ì´ˆê¸° ë©”ì‹œì§€
        main_response = st.empty()
        main_response.write("ë¶„ì„ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")        
        # ê° ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•  expander ìƒì„±
        if "process_containers" not in st.session_state:
            st.session_state["process_containers"] = {}
            st.session_state["tool_containers"] = {}
        for node_name in node_names:
            with st.expander(f"ğŸ”„ {node_name.upper()}: {node_descriptions[node_name]}", expanded=True):
                st.session_state["process_containers"][node_name] = st.empty()
                st.session_state["process_containers"][node_name].info(f"Waiting...")

                # ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•˜ëŠ” íˆ´ ê²°ê³¼ë¥¼ í‘œì‹œí•  ì»¨í…Œì´ë„ˆ
                st.markdown(f"ğŸ”§ íˆ´ ì‚¬ìš© í˜„í™©")
                st.session_state["tool_containers"][node_name] = {}
                st.session_state["tool_containers"][node_name]["input"] = st.empty()
                st.session_state["tool_containers"][node_name]["output"] = st.empty()
                st.session_state["tool_containers"][node_name]["input"].info(f"Tool not used yet")
                st.session_state["tool_containers"][node_name]["output"].info(f"Tool not used yet")
                
                #st.session_state["tool_containers"][node_name] = st.empty()
                #st.session_state["tool_containers"][node_name].info(f"Tool not used yet")
        
        # ì°¨íŠ¸ë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ (í•„ìš”í•œ ê²½ìš°)
        chart_container = st.empty()
        
        with st.spinner('ë¶„ì„ ì¤‘...'):
            # ì‹¤í–‰ ë° ê²°ê³¼ ì²˜ë¦¬
            execution(user_query=user_input)
            
            # ê° ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ ì—…ë°ì´íŠ¸
            for node_name in node_names:
                if node_name == "chart_generation" and st.session_state["ai_results"].get(node_name, {}) != {}:
                    chart_data = io.BytesIO(st.session_state["ai_results"][node_name])
                    st.session_state["process_containers"][node_name].image(chart_data)
                    # ë©”ì¸ ì˜ì—­ì—ë„ ì°¨íŠ¸ í‘œì‹œ
                    chart_container.image(chart_data)
                else:
                    result_text = st.session_state["ai_results"].get(node_name, {}).get("text", "ì²˜ë¦¬ ì™„ë£Œ")
                    st.session_state["process_containers"][node_name].write(result_text)
            
            # ë©”ì¸ ì‘ë‹µ ì—…ë°ì´íŠ¸ (coordinatorì˜ ê²°ê³¼)
            coordinator_result = st.session_state["ai_results"].get("coordinator", {}).get("text", "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            main_response.write(coordinator_result)
        
        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° íˆìŠ¤í† ë¦¬ ì €ì¥
        display_chat_history()

# import sys, os
# module_path = ".."
# sys.path.append(os.path.abspath(module_path))

# import inspect
# import streamlit as st
# from typing import Callable, TypeVar
# from streamlit.delta_generator import DeltaGenerator
# from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
# from streamlit.runtime.scriptrunner import add_script_run_ctx, get_script_run_ctx

# ##################### Title ########################
# st.set_page_config(page_title="GenAI-driven Analytics ğŸ’¬", page_icon="ğŸ’¬", layout="wide")  # layoutì„ wideë¡œ ë³€ê²½
# st.title("GenAI-driven Analytics ğŸ’¬")
# st.markdown('''- This chatbot is implemented using Amazon Bedrock Claude v3.5 Sonnet.''')
# st.markdown('''
#             - You can find the source code in 
#             [this Github](https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/20_applications/09_genai_analytics)
#             ''')

# from main import execution
# import io

# ##################### Functions ########################
# def display_chat_history():
#     node_names = ["coordinator", "planner", "supervisor", "coder", "reporter"]
#     st.session_state["history_ask"].append(st.session_state["recent_ask"])

#     recent_answer = {}
#     for node_name in node_names:
#         print ("node_name", node_name)
#         if node_name != "chart_generation": recent_answer[node_name] = st.session_state["ai_results"][node_name].get("text", "None")
#         else:
#             if st.session_state["ai_results"][node_name] != {}:
#                 recent_answer[node_name] = io.BytesIO(st.session_state["ai_results"][node_name])
#             else: recent_answer[node_name] = "None"
#         st.session_state["ai_results"][node_name] = {} ## reset
#     st.session_state["history_answer"].append(recent_answer)

#     for i, (user, assistant) in enumerate(zip(st.session_state["history_ask"], st.session_state["history_answer"])):
        
#         # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
#         with st.chat_message("user"):
#             st.write(user)
        
#         # ì‘ë‹µì„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„í• 
#         left_col, right_col = st.columns([1, 1])
        
#         # ì™¼ìª½ ì»¬ëŸ¼ - ì£¼ìš” LLM ì¶œë ¥
#         with left_col:
#             with st.chat_message("assistant"):
#                 # ê¸°ë³¸ìœ¼ë¡œ í‘œì‹œí•  ë…¸ë“œ ì„ íƒ (ì˜ˆ: agent ë˜ëŠ” chart_description)
#                 main_output = assistant["agent"]
#                 st.write(main_output)
                
#                 # ì°¨íŠ¸ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ í‘œì‹œ
#                 if assistant["chart_generation"] != "None":
#                     st.image(assistant["chart_generation"])
        
#         # ì˜¤ë¥¸ìª½ ì»¬ëŸ¼ - í”„ë¡œì„¸ìŠ¤ ìƒì„¸ ì •ë³´
#         with right_col:
#             with st.container():
#                 st.subheader("Process Details")
#                 # íƒ­ìœ¼ë¡œ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ë‹¨ê³„ í‘œì‹œ
#                 tabs = st.tabs(node_names)
#                 for tab, node_name in zip(tabs, node_names):
#                     with tab:
#                         if node_name == "chart_generation" and assistant[node_name] != "None":
#                             st.image(assistant[node_name])
#                         else:
#                             st.write(assistant[node_name])

# T = TypeVar("T")
# def get_streamlit_cb(parent_container: DeltaGenerator):
    
#     def decor(fn: Callable[..., T]) -> Callable[..., T]:
#         ctx = get_script_run_ctx()

#         def wrapper(*args, **kwargs) -> T:
#             add_script_run_ctx(ctx=ctx)
#             return fn(*args, **kwargs)

#         return wrapper

#     st_cb = StreamlitCallbackHandler(parent_container=parent_container)

#     for name, fn in inspect.getmembers(st_cb, predicate=inspect.ismethod):
#         if name.startswith("on_"):
#             setattr(st_cb, name, decor(fn))

#     return st_cb

# ####################### Initialization ###############################
# # Store the initial value of widgets in session state
# if "messages" not in st.session_state: st.session_state["messages"] = []
# if "history_ask" not in st.session_state: st.session_state["history_ask"] = []
# if "history_answer" not in st.session_state: st.session_state["history_answer"] = []
# if "ai_results" not in st.session_state: st.session_state["ai_results"] = {"coordinator": {}, "planner": {}, "supervisor": {}, "coder": {}, "reporter": {}}

# for i in range(10):
#     if f"ph{i}" not in st.session_state: st.session_state[f"ph{i}"] = st.empty()
    
# ####################### Application ###############################
# if len(st.session_state["history_ask"]) > 0: 
#     display_chat_history()

# if user_input := st.chat_input(): # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
#     st.chat_message("user").write(user_input)
#     st.session_state["recent_ask"] = user_input
    
#     # ì²˜ë¦¬ ì¤‘ UI êµ¬ì„± - ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ ì‚¬ìš©
#     left_col, right_col = st.columns([1, 1])
    
#     # ì™¼ìª½ ì»¬ëŸ¼ - ë©”ì¸ ì‘ë‹µì„ ìœ„í•œ ì¤€ë¹„
#     with left_col:
#         with st.chat_message("assistant"):
#             main_response_container = st.empty()
#             main_response_container.write("ì²˜ë¦¬ ì¤‘...")
            
#             # ì´ë¯¸ì§€ë¥¼ ìœ„í•œ ìë¦¬ í™•ë³´
#             image_container = st.empty()
    
#     # ì˜¤ë¥¸ìª½ ì»¬ëŸ¼ - í”„ë¡œì„¸ìŠ¤ ë‹¨ê³„ ëª¨ë‹ˆí„°ë§
#     with right_col:
#         with st.container():
#             st.subheader("Processing Steps")
#             # ê° í”„ë¡œì„¸ìŠ¤ ë‹¨ê³„ë¥¼ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
#             if "process_containers" not in st.session_state:
#                 st.session_state["process_containers"] = {}
#                 node_names = ["coordinator", "planner", "supervisor", "coder", "reporter"]
#                 for node_name in node_names:
#                     st.session_state["process_containers"][node_name] = st.empty()
#                     st.session_state["process_containers"][node_name].info(f"{node_name}: Waiting...")

#     with st.spinner(f'Thinking...'):
#         # ì—¬ê¸°ì„œ execution í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê³  ê° ë‹¨ê³„ë§ˆë‹¤ í•´ë‹¹ ì»¨í…Œì´ë„ˆ ì—…ë°ì´íŠ¸
#         execution(user_query=user_input)
        
#         # ê²°ê³¼ ì—…ë°ì´íŠ¸ - ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê° ë‹¨ê³„ì—ì„œ ì»¨í…Œì´ë„ˆë¥¼ ì§ì ‘ ì—…ë°ì´íŠ¸ í•„ìš”
#         for node_name in node_names:
#             if node_name != "chart_generation":
#                 result_text = st.session_state["ai_results"][node_name].get("text", "None")
#                 process_containers[node_name].write(f"{node_name}: {result_text}")
#             else:
#                 if st.session_state["ai_results"][node_name] != {}:
#                     chart_data = io.BytesIO(st.session_state["ai_results"][node_name])
#                     process_containers[node_name].image(chart_data)
#                 else:
#                     process_containers[node_name].info(f"{node_name}: No chart generated")
        
#         # ë©”ì¸ ì¶œë ¥ ì—…ë°ì´íŠ¸
#         main_response_container.write(st.session_state["ai_results"]["agent"].get("text", "ì²˜ë¦¬ ì™„ë£Œ"))
        
#         # ì°¨íŠ¸ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
#         if st.session_state["ai_results"]["chart_generation"] != {}:
#             chart_data = io.BytesIO(st.session_state["ai_results"]["chart_generation"])
#             image_container.image(chart_data)
        
#         # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° íˆìŠ¤í† ë¦¬ ì €ì¥
#         display_chat_history()

