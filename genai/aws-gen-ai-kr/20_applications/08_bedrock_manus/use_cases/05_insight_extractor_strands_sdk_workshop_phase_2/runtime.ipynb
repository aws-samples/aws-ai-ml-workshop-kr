{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Hosting Strands + LangGraph agent with Amazon Bedrock models in Amazon Bedrock AgentCore Runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will learn how to host your existing agent, using Amazon Bedrock AgentCore Runtime. \n",
    "\n",
    "We will focus on a LangGraph with Amazon Bedrock model example. For Strands Agents with Amazon Bedrock model check [here](../01-strands-with-bedrock-model)\n",
    "and for a Strands Agents with an OpenAI model check [here](../03-strands-with-openai-model).\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                      |\n",
    "|:--------------------|:-----------------------------------------------------------------------------|\n",
    "| Tutorial type       | Conversational                                                               |\n",
    "| Agent type          | Single                                                                       |\n",
    "| Agentic Framework   | Strands + LangGraph                                                                    |\n",
    "| LLM model           | Anthropic Claude Sonnet 3                                                    |\n",
    "| Tutorial components | Hosting agent on AgentCore Runtime. Using Strands + LangGraph and Amazon Bedrock Model |\n",
    "| Tutorial vertical   | Cross-vertical                                                               |\n",
    "| Example complexity  | Easy                                                                         |\n",
    "| SDK used            | Amazon BedrockAgentCore Python SDK and boto3                                 |\n",
    "\n",
    "### Tutorial Architecture\n",
    "\n",
    "In this tutorial we will describe how to deploy an existing agent to AgentCore runtime. \n",
    "\n",
    "For demonstration purposes, we will  use a LangGraph agent using Amazon Bedrock models\n",
    "\n",
    "In our example we will use a very simple agent with two tools: `get_weather` and `get_time`. \n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_runtime.png\" width=\"50%\"/>\n",
    "</div>\n",
    "\n",
    "### Tutorial Key Features\n",
    "\n",
    "* Hosting Agents on Amazon Bedrock AgentCore Runtime\n",
    "* Using Amazon Bedrock models\n",
    "* Using LangGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To execute this tutorial you will need:\n",
    "* Python 3.10+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* LangGraph\n",
    "* Docker running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## Creating your agents and experimenting locally\n",
    "\n",
    "Before we deploy our agents to AgentCore Runtime, let's develop and run them locally for experimentation purposes.\n",
    "\n",
    "For production agentic applications we will need to decouple the agent creation process from the agent invocation one. With AgentCore Runtime, we will decorate the invocation part of our agent with the `@app.entrypoint` decorator and have it as the entry point for our runtime. Let's first look how each agent is developed during the experimentation phase.\n",
    "\n",
    "The architecture here will look as following:\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_local.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2e9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a5e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../../../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## Preparing your agent for deployment on AgentCore Runtime\n",
    "\n",
    "Let's now deploy our agents to AgentCore Runtime. To do so we need to:\n",
    "* Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "* Initialize the App in our code with `app = BedrockAgentCoreApp()`\n",
    "* Decorate the invocation function with the `@app.entrypoint` decorator\n",
    "* Let AgentCoreRuntime control the running of the agent with `app.run()`\n",
    "\n",
    "### Strands Agent SDK + LangGraph with Amazon Bedrock model\n",
    "Let's start with our Strands Agent SDK + LangGraph using Amazon Bedrock model. Other examples with different frameworks and models are available in the parent directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17f452",
   "metadata": {},
   "source": [
    "### Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0261f0a",
   "metadata": {},
   "outputs": [],
   "source": "%%writefile runtime.py\n\n\"\"\"\nAgentCore Runtime for Bedrock-Manus Multi-Agent System\nConverted from main.py to use AgentCore Runtime API with unified event streaming\n\"\"\"\nimport os\nimport shutil\nimport asyncio\nfrom bedrock_agentcore.runtime import BedrockAgentCoreApp\nfrom src.graph.builder import build_graph\nfrom src.utils.strands_sdk_utils import strands_utils\n\n# Import event queue for unified event processing\nfrom src.utils.event_queue import clear_queue\n\napp = BedrockAgentCoreApp()\n\ndef remove_artifact_folder(folder_path=\"./artifacts/\"):\n    \"\"\"\n    ./artifact/ í´ë”ê°€ ì¡´ì¬í•˜ë©´ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜\n    \n    Args:\n        folder_path (str): ì‚­ì œí•  í´ë” ê²½ë¡œ\n    \"\"\"\n    if os.path.exists(folder_path):\n        print(f\"'{folder_path}' í´ë”ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤...\")\n        try:\n            shutil.rmtree(folder_path)\n            print(f\"'{folder_path}' í´ë”ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n        except Exception as e: \n            print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n    else:\n        print(f\"'{folder_path}' í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n\ndef _setup_execution():\n    \"\"\"Initialize execution environment\"\"\"\n    remove_artifact_folder()\n    clear_queue()\n    print(\"\\n=== Starting AgentCore Runtime Event Stream ===\")\n\ndef _print_conversation_history():\n    \"\"\"Print final conversation history\"\"\"\n    print(\"\\n=== Conversation History ===\")\n    from src.graph.nodes import _global_node_states\n    shared_state = _global_node_states.get('shared', {})\n    history = shared_state.get('history', [])\n    \n    if history:\n        for hist_item in history:\n            print(f\"[{hist_item['agent']}] {hist_item['message']}\")\n    else:\n        print(\"No conversation history found\")\n\n@app.entrypoint\nasync def graph_streaming_execution(payload):\n    \"\"\"\n    Execute full graph streaming workflow through AgentCore Runtime\n    Queue-only event processing compatible with AgentCore API\n    \"\"\"\n    # Get user query from payload\n    user_query = payload.get(\"prompt\", \"\")\n    \n    if not user_query:\n        # Use default query if none provided\n        user_query = \"ë„ˆê°€ ì‘ì„±í•  ê²ƒì€ moon market ì˜ íŒë§¤ í˜„í™© ë³´ê³ ì„œì•¼. ì„¸ì¼ì¦ˆ ë° ë§ˆì¼€íŒ… ê´€ì ìœ¼ë¡œ ë¶„ì„ì„ í•´ì£¼ê³ , ì°¨íŠ¸ ìƒì„± ë° ì¸ì‚¬ì´íŠ¸ë„ ë½‘ì•„ì„œ pdf íŒŒì¼ë¡œ ë§Œë“¤ì–´ì¤˜. ë¶„ì„ëŒ€ìƒì€ './data/Dat-fresh-food-claude.csv' íŒŒì¼ ì…ë‹ˆë‹¤. Coder ì—ì´ì „íŠ¸ê°€ í• ì¼ì€ ìµœëŒ€í•œ ì‘ê²Œ í•´ì¤˜. ì™œëƒí•˜ë©´ reporter ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì¤‘ì´ë¼ ë¹¨ë¦¬ ì½”ë” ë‹¨ê³„ë¥¼ ë„˜ì–´ ê°€ì•¼ í•˜ê±°ë“ . ë¶€íƒí•´.\"\n    \n    _setup_execution()\n    \n    # Build graph and use stream_async method\n    graph = build_graph()\n    event_count = 0\n    \n    # Stream events from graph execution\n    async for event in graph.stream_async({\n        \"request\": user_query,\n        \"request_prompt\": f\"Here is a user request: <user_request>{user_query}</user_request>\"\n    }):\n        event_count += 1\n        # Add AgentCore runtime metadata\n        event[\"event_id\"] = event_count\n        event[\"runtime_source\"] = \"bedrock_manus_agentcore\"\n        \n        # Mark final event\n        if event.get(\"type\") == \"workflow_complete\":\n            event[\"total_events\"] = event_count\n            event[\"message\"] = \"All events processed through global queue via AgentCore Runtime\"\n        \n        yield event\n    \n    _print_conversation_history()\n    print(\"=== AgentCore Runtime Event Stream Complete ===\")\n\n\nif __name__ == \"__main__\":\n    app.run()\n    \n    \n"
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "## What happens behind the scenes?\n",
    "\n",
    "When you use `BedrockAgentCoreApp`, it automatically:\n",
    "\n",
    "* Creates an HTTP server that listens on the port 8080\n",
    "* Implements the required `/invocations` endpoint for processing the agent's requirements\n",
    "* Implements the `/ping` endpoint for health checks (very important for asynchronous agents)\n",
    "* Handles proper content types and response formats\n",
    "* Manages error handling according to the AWS standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "## Deploying the agent to AgentCore Runtime\n",
    "\n",
    "The `CreateAgentRuntime` operation supports comprehensive configuration options, letting you specify container images, environment variables and encryption settings. You can also configure protocol settings (HTTP, MCP) and authorization mechanisms to control how your clients communicate with the agent. \n",
    "\n",
    "**Note:** Operations best practice is to package code as container and push to ECR using CI/CD pipelines and IaC\n",
    "\n",
    "In this tutorial can will the Amazon Bedrock AgentCode Python SDK to easily package your artifacts and deploy them to AgentCore runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0861401-a111-4ade-9e02-50f52fdfa9b1",
   "metadata": {},
   "source": [
    "### Creating runtime role\n",
    "\n",
    "Before starting, let's create an IAM role for our AgentCore Runtime. We will do so using the utils function pre-developed for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0]: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications\n",
      "Role already exists -- deleting and creating it again\n",
      "policies: {'PolicyNames': ['AgentCorePolicy'], 'IsTruncated': False, 'ResponseMetadata': {'RequestId': 'c0789510-86f0-434a-8830-3b9522bd314f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 03 Sep 2025 09:20:05 GMT', 'x-amzn-requestid': 'c0789510-86f0-434a-8830-3b9522bd314f', 'content-type': 'text/xml', 'content-length': '380'}, 'RetryAttempts': 0}}\n",
      "deleting agentcore-runtime-role\n",
      "recreating agentcore-runtime-role\n",
      "attaching role policy agentcore-runtime-role\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook's directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "\n",
    "utils_dir = os.path.join(current_dir, '..')\n",
    "utils_dir = os.path.join(utils_dir, '..')\n",
    "utils_dir = os.path.abspath(utils_dir)\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, utils_dir)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from src.utils.agentcore import create_agentcore_role\n",
    "\n",
    "agent_name=\"runtime\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "### Configure AgentCore Runtime deployment\n",
    "\n",
    "Next we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/configure.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fd644",
   "metadata": {},
   "source": [
    "**Signature:**\n",
    "```python\n",
    "agentcore_runtime.configure(\n",
    "    entrypoint: str,\n",
    "    execution_role: Optional[str] = None,\n",
    "    agent_name: Optional[str] = None,\n",
    "    requirements: Optional[List[str]] = None,\n",
    "    requirements_file: Optional[str] = None,\n",
    "    ecr_repository: Optional[str] = None,\n",
    "    container_runtime: Optional[str] = None,\n",
    "    auto_create_ecr: bool = True,\n",
    "    auto_create_execution_role: bool = False,\n",
    "    authorizer_configuration: Optional[Dict[str, Any]] = None,\n",
    "    region: Optional[str] = None,\n",
    "    protocol: Optional[Literal['HTTP', 'MCP']] = None,\n",
    ") -> bedrock_agentcore_starter_toolkit.operations.runtime.models.ConfigureResult\n",
    "```\n",
    "\n",
    "**Docstring:**  \n",
    "Configure Bedrock AgentCore from notebook using an entrypoint file.\n",
    "\n",
    "**Args:**\n",
    "- **entrypoint**: Path to Python file with optional Bedrock AgentCore name (e.g., \"handler.py\" or \"handler.py:bedrock_agentcore\")\n",
    "- **execution_role**: AWS IAM execution role ARN or name (optional if auto_create_execution_role=True)\n",
    "- **agent_name**: name of the agent\n",
    "- **requirements**: Optional list of requirements to generate requirements.txt\n",
    "- **requirements_file**: Optional path to existing requirements file\n",
    "- **ecr_repository**: Optional ECR repository URI\n",
    "- **container_runtime**: Optional container runtime (docker/podman)\n",
    "- **auto_create_ecr**: Whether to auto-create ECR repository\n",
    "- **auto_create_execution_role**: Whether to auto-create execution role (makes execution_role optional)\n",
    "- **authorizer_configuration**: JWT authorizer configuration dictionary\n",
    "- **region**: AWS region for deployment\n",
    "- **protocol**: agent server protocol, must be either HTTP or MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/runtime.py, bedrock_agentcore_name=runtime\n",
      "Configuring BedrockAgentCore agent: runtime\n",
      "Generated Dockerfile: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/Dockerfile\n",
      "Generated .dockerignore: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.dockerignore\n",
      "Keeping 'runtime' as default agent\n",
      "Bedrock AgentCore configured: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.bedrock_agentcore.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigureResult(config_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.bedrock_agentcore.yaml'), dockerfile_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/Dockerfile'), dockerignore_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.dockerignore'), runtime='Docker', region='us-west-2', account_id='615299776985', execution_role='arn:aws:iam::615299776985:role/agentcore-runtime-role', ecr_repository=None, auto_create_ecr=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "region\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    agent_name=agent_name,\n",
    "    entrypoint=\"runtime.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### Launching agent to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸš€ CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "   â€¢ Build ARM64 containers in the cloud with CodeBuild\n",
      "   â€¢ No local Docker required\n",
      "ğŸ’¡ Available deployment modes:\n",
      "   â€¢ runtime.launch()                           â†’ CodeBuild (current)\n",
      "   â€¢ runtime.launch(local=True)                 â†’ Local development\n",
      "   â€¢ runtime.launch(local_build=True)           â†’ Local build + cloud deploy (NEW)\n",
      "Starting CodeBuild ARM64 deployment for agent 'runtime' to account 615299776985 (us-west-2)\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: runtime\n",
      "âœ… ECR repository available: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-runtime\n",
      "Using execution role from config: arn:aws:iam::615299776985:role/agentcore-runtime-role\n",
      "Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: runtime\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-d92c6a81b2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reusing existing ECR repository: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing existing CodeBuild execution role: arn:aws:iam::615299776985:role/AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-d92c6a81b2\n",
      "Using .dockerignore with 43 patterns\n",
      "Uploaded source to S3: runtime/source.zip\n",
      "Updated CodeBuild project: bedrock-agentcore-runtime-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "ğŸ”„ QUEUED started (total: 0s)\n",
      "âœ… QUEUED completed in 1.0s\n",
      "ğŸ”„ PROVISIONING started (total: 1s)\n",
      "âœ… PROVISIONING completed in 8.2s\n",
      "ğŸ”„ DOWNLOAD_SOURCE started (total: 9s)\n",
      "âœ… DOWNLOAD_SOURCE completed in 1.0s\n",
      "ğŸ”„ INSTALL started (total: 10s)\n",
      "âœ… INSTALL completed in 1.0s\n",
      "ğŸ”„ BUILD started (total: 11s)\n",
      "âœ… BUILD completed in 37.0s\n",
      "ğŸ”„ POST_BUILD started (total: 48s)\n",
      "âœ… POST_BUILD completed in 45.2s\n",
      "ğŸ”„ FINALIZING started (total: 94s)\n",
      "âœ… FINALIZING completed in 1.0s\n",
      "ğŸ”„ COMPLETED started (total: 95s)\n",
      "âœ… COMPLETED completed in 0.0s\n",
      "ğŸ‰ CodeBuild completed successfully in 1m 34s\n",
      "CodeBuild completed successfully\n",
      "âœ… CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "âœ… Agent created/updated: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\n",
      "Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\n",
      "Built with CodeBuild: bedrock-agentcore-runtime-builder:1761e23a-575f-483f-9689-17c00c4a1240\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\n",
      "ECR image: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-runtime\n",
      "ğŸ” Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT\n",
      "   /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT --log-stream-names otel-rt-logs\n",
      "ğŸ’¡ Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT --follow\n",
      "ğŸ’¡ Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT --since 1h\n"
     ]
    }
   ],
   "source": [
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4491351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine: aarch64\n",
      "Processor: aarch64\n",
      "Architecture: ('64bit', 'ELF')\n",
      "Platform: Linux-6.8.0-1033-aws-aarch64-with-glibc2.35\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(f\"Machine: {platform.machine()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Architecture: {platform.architecture()}\")\n",
    "print(f\"Platform: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "### Checking for the AgentCore Runtime Status\n",
    "Now that we've deployed the AgentCore Runtime, let's check for it's deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: runtime\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'READY'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime\n",
    "\n",
    "Finally, we can invoke our AgentCore Runtime with a payload\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/invoke.png\" width=75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78945203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97mhan\u001b[0m\u001b[97mdoff_to_\u001b[0m\u001b[97mplanner: I'll need to cons\u001b[0m\u001b[97mult our planning system\u001b[0m\u001b[97m for this request.\u001b[0m\u001b[97m\n",
      "\n",
      "This request\u001b[0m\u001b[97m involves complex data analysis tasks\u001b[0m\u001b[97m including:\n",
      "- Reading\u001b[0m\u001b[97m and analyzing Amazon sales\u001b[0m\u001b[97m data\n",
      "- Performing\u001b[0m\u001b[97m exploratory data analysis\u001b[0m\u001b[97m\n",
      "- Analyzing sales\u001b[0m\u001b[97m trends and variable relationships\n",
      "- Creating\u001b[0m\u001b[97m visualizations and charts\u001b[0m\u001b[97m\n",
      "- Generating\u001b[0m\u001b[97m marketing insights\n",
      "- Producing\u001b[0m\u001b[97m a PDF report\n",
      "\n",
      "I\u001b[0m\u001b[97m'll pass this to\u001b[0m\u001b[97m our planning system to handle these\u001b[0m\u001b[97m technical requirements\u001b[0m\u001b[97m properly.\u001b[0m\u001b[96mThis user\u001b[0m\u001b[96m request asks\u001b[0m\u001b[96m for an analysis of Amazon fresh\u001b[0m\u001b[96m food product data from\u001b[0m\u001b[96m a CSV\u001b[0m\u001b[96m file locate\u001b[0m\u001b[96md at \"./\u001b[0m\u001b[96mdata/Dat-fresh\u001b[0m\u001b[96m-foo\u001b[0m\u001b[96md-claude.csv\". The\u001b[0m\u001b[96m goal is to extract\u001b[0m\u001b[96m marketing\u001b[0m\u001b[96m insights through\u001b[0m\u001b[96m a variety of analyses\u001b[0m\u001b[96m including\u001b[0m\u001b[96m basic\u001b[0m\u001b[96m explor\u001b[0m\u001b[96matory data analysis (\u001b[0m\u001b[96mEDA), sales\u001b[0m\u001b[96m trend analysis, variable\u001b[0m\u001b[96m relationship analysis, an\u001b[0m\u001b[96md potentially\u001b[0m\u001b[96m additional\u001b[0m\u001b[96m analyses\u001b[0m\u001b[96m based on initial\u001b[0m\u001b[96m findings. The\u001b[0m\u001b[96m request also spec\u001b[0m\u001b[96mifies that the final\u001b[0m\u001b[96m report should include\u001b[0m\u001b[96m visualizations/\u001b[0m\u001b[96mcharts an\u001b[0m\u001b[96md be\u001b[0m\u001b[96m save\u001b[0m\u001b[96md as a PDF.\u001b[0m\u001b[96m\n",
      "\n",
      "Let\u001b[0m\u001b[96m me break\u001b[0m\u001b[96m down what\u001b[0m\u001b[96m needs\u001b[0m\u001b[96m to be done an\u001b[0m\u001b[96md plan\u001b[0m\u001b[96m accordingly:\n",
      "\n",
      "1\u001b[0m\u001b[96m. Data\u001b[0m\u001b[96m Loading\u001b[0m\u001b[96m an\u001b[0m\u001b[96md Initial\u001b[0m\u001b[96m Exploration:\u001b[0m\u001b[96m\n",
      "   - Load the\u001b[0m\u001b[96m CSV file\u001b[0m\u001b[96m\n",
      "   - Examine\u001b[0m\u001b[96m basic\u001b[0m\u001b[96m data properties\u001b[0m\u001b[96m (shape\u001b[0m\u001b[96m, columns, data\u001b[0m\u001b[96m types, missing values)\n",
      "   \u001b[0m\u001b[96m- Get descript\u001b[0m\u001b[96mive statistics\n",
      "   - Understan\u001b[0m\u001b[96md the dataset structure\n",
      "\n",
      "2.\u001b[0m\u001b[96m Exploratory Data\u001b[0m\u001b[96m Analysis:\u001b[0m\u001b[96m\n",
      "   - Distribution\u001b[0m\u001b[96m of key\u001b[0m\u001b[96m variables\n",
      "   -\u001b[0m\u001b[96m Temporal\u001b[0m\u001b[96m analysis if\u001b[0m\u001b[96m time data\u001b[0m\u001b[96m is available\n",
      "   -\u001b[0m\u001b[96m Category/product\u001b[0m\u001b[96m analysis\n",
      "   -\u001b[0m\u001b[96m Sales metrics analysis\n",
      "\n",
      "3.\u001b[0m\u001b[96m Trend Analysis:\u001b[0m\u001b[96m\n",
      "   - Sales trends\u001b[0m\u001b[96m over time (\u001b[0m\u001b[96mif temporal data exists\u001b[0m\u001b[96m)\n",
      "   -\u001b[0m\u001b[96m Seasonal patterns\n",
      "   -\u001b[0m\u001b[96m Product performance trends\u001b[0m\u001b[96m\n",
      "\n",
      "4. Variable\u001b[0m\u001b[96m Relationships:\n",
      "   - Correlation\u001b[0m\u001b[96m analysis\n",
      "   - Relationship\u001b[0m\u001b[96m between sales and other\u001b[0m\u001b[96m variables\u001b[0m\u001b[96m\n",
      "   - Potential\u001b[0m\u001b[96m factors affecting sales\n",
      "\n",
      "5\u001b[0m\u001b[96m. Advance\u001b[0m\u001b[96md Analysis:\n",
      "   -\u001b[0m\u001b[96m Customer segmentation if\u001b[0m\u001b[96m customer data is available\u001b[0m\u001b[96m\n",
      "   - Product\u001b[0m\u001b[96m affinity analysis (which\u001b[0m\u001b[96m products are bought together\u001b[0m\u001b[96m)\n",
      "   -\u001b[0m\u001b[96m Any additional analysis based on\u001b[0m\u001b[96m initial findings\n",
      "\n",
      "6\u001b[0m\u001b[96m. Insight\u001b[0m\u001b[96m Generation:\n",
      "   -\u001b[0m\u001b[96m Identify\u001b[0m\u001b[96m key marketing\u001b[0m\u001b[96m insights\n",
      "   -\u001b[0m\u001b[96m Formulate recommendations\u001b[0m\u001b[96m base\u001b[0m\u001b[96md on the\u001b[0m\u001b[96m data\u001b[0m\u001b[96m\n",
      "   - Create action\u001b[0m\u001b[96mable take\u001b[0m\u001b[96maways\u001b[0m\u001b[96m\n",
      "\n",
      "7.\u001b[0m\u001b[96m Visualization and Reporting:\n",
      "   \u001b[0m\u001b[96m- Create appropriate visualizations\n",
      "   \u001b[0m\u001b[96m- Compile findings\u001b[0m\u001b[96m into a comprehensive\u001b[0m\u001b[96m report\n",
      "   - Save\u001b[0m\u001b[96m the report as PDF\u001b[0m\u001b[96m\n",
      "\n",
      "Based on this breakdown\u001b[0m\u001b[96m, I'll create\u001b[0m\u001b[96m a detailed plan with\u001b[0m\u001b[96m agent assignments.\u001b[0m\u001b[96m Since this is primarily\u001b[0m\u001b[96m a data analysis task\u001b[0m\u001b[96m, the Coder will\u001b[0m\u001b[96m handle most of the technical work\u001b[0m\u001b[96m, while the Reporter\u001b[0m\u001b[96m will create the final\u001b[0m\u001b[96m report.\n",
      "\n",
      "I\u001b[0m\u001b[96m need to ensure\u001b[0m\u001b[96m I follow the\u001b[0m\u001b[96m execution rules and avoi\u001b[0m\u001b[96md calling the same agent consecut\u001b[0m\u001b[96mively, combining\u001b[0m\u001b[96m related tasks for each agent.\u001b[0m\u001b[96m\u001b[0m\u001b[97m# Plan\u001b[0m\u001b[97m\n",
      "\n",
      "## thought\n",
      "This\u001b[0m\u001b[97m project requires a comprehensive analysis\u001b[0m\u001b[97m of Amazon fresh food sales\u001b[0m\u001b[97m data to extract\u001b[0m\u001b[97m marketing insights.\u001b[0m\u001b[97m The data is located at \"./\u001b[0m\u001b[97mdata/Dat\u001b[0m\u001b[97m-fresh-foo\u001b[0m\u001b[97md-claude.csv\u001b[0m\u001b[97m\". I\u001b[0m\u001b[97m'll\u001b[0m\u001b[97m need to organize\u001b[0m\u001b[97m a\u001b[0m\u001b[97m thor\u001b[0m\u001b[97mough data analysis\u001b[0m\u001b[97m workflow\u001b[0m\u001b[97m from\u001b[0m\u001b[97m initial exploration\u001b[0m\u001b[97m to final reporting,\u001b[0m\u001b[97m making sure all\u001b[0m\u001b[97m technical analyses are groupe\u001b[0m\u001b[97md together and the\u001b[0m\u001b[97m final report includes visual\u001b[0m\u001b[97mizations and insights\u001b[0m\u001b[97m in PDF\u001b[0m\u001b[97m format.\n",
      "\n",
      "##\u001b[0m\u001b[97m title:\n",
      "Amazon\u001b[0m\u001b[97m Fresh Food Sales Data\u001b[0m\u001b[97m Analysis for\u001b[0m\u001b[97m Marketing Insights\u001b[0m\u001b[97m\n",
      "\n",
      "## steps:\u001b[0m\u001b[97m\n",
      "### 1.\u001b[0m\u001b[97m Coder: Comprehensive\u001b[0m\u001b[97m Data Analysis an\u001b[0m\u001b[97md Visualization\n",
      "- [\u001b[0m\u001b[97m ] Load the dataset\u001b[0m\u001b[97m from \"./\u001b[0m\u001b[97mdata/Dat\u001b[0m\u001b[97m-fresh-foo\u001b[0m\u001b[97md-claude.csv\u001b[0m\u001b[97m\"\n",
      "- [\u001b[0m\u001b[97m ] Perform\u001b[0m\u001b[97m initial data\u001b[0m\u001b[97m exploration (\u001b[0m\u001b[97mshape, data types,\u001b[0m\u001b[97m missing values)\u001b[0m\u001b[97m\n",
      "- [ ] Generate descriptive statistics for\u001b[0m\u001b[97m key variables\n",
      "-\u001b[0m\u001b[97m [ ] Clean\u001b[0m\u001b[97m and preprocess the data as\u001b[0m\u001b[97m needed\n",
      "- [ ]\u001b[0m\u001b[97m Conduct explor\u001b[0m\u001b[97matory data analysis with\u001b[0m\u001b[97m visualizations\n",
      "- [\u001b[0m\u001b[97m ] Analyze\u001b[0m\u001b[97m sales trends over time\u001b[0m\u001b[97m (if temporal\u001b[0m\u001b[97m data exists)\n",
      "- [\u001b[0m\u001b[97m ] Identify patterns in product categories\u001b[0m\u001b[97m an\u001b[0m\u001b[97md performance\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Explore relationships between\u001b[0m\u001b[97m variables\u001b[0m\u001b[97m using\u001b[0m\u001b[97m correlation analysis\n",
      "-\u001b[0m\u001b[97m [ ]\u001b[0m\u001b[97m Perform\u001b[0m\u001b[97m customer\u001b[0m\u001b[97m/product segmentation analysis\u001b[0m\u001b[97m if appropriate\u001b[0m\u001b[97m\n",
      "- [ ] Create visual\u001b[0m\u001b[97mizations for\u001b[0m\u001b[97m all key\u001b[0m\u001b[97m findings (\u001b[0m\u001b[97mcharts, graphs\u001b[0m\u001b[97m, h\u001b[0m\u001b[97meatmaps)\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Identify\u001b[0m\u001b[97m top-\u001b[0m\u001b[97mperforming products and potential\u001b[0m\u001b[97m growth areas\n",
      "- [\u001b[0m\u001b[97m ] Extract preliminary\u001b[0m\u001b[97m marketing insights based on\u001b[0m\u001b[97m the analysis\u001b[0m\u001b[97m\n",
      "- [ ] Save\u001b[0m\u001b[97m all visual\u001b[0m\u001b[97mizations for inclusion in the final\u001b[0m\u001b[97m report\n",
      "\n",
      "### 2. Reporter:\u001b[0m\u001b[97m Final Marketing\u001b[0m\u001b[97m Insights Report Creation\n",
      "- [ ]\u001b[0m\u001b[97m Compile all analysis\u001b[0m\u001b[97m results an\u001b[0m\u001b[97md insights into a comprehensive\u001b[0m\u001b[97m report\n",
      "- [\u001b[0m\u001b[97m ] Structure the report with\u001b[0m\u001b[97m clear\u001b[0m\u001b[97m sections (Executive\u001b[0m\u001b[97m Summary,\u001b[0m\u001b[97m Methodology\u001b[0m\u001b[97m,\u001b[0m\u001b[97m Findings, etc\u001b[0m\u001b[97m.)\n",
      "- [\u001b[0m\u001b[97m ]\u001b[0m\u001b[97m Incorporate all\u001b[0m\u001b[97m relevant\u001b[0m\u001b[97m visualizations from the\u001b[0m\u001b[97m analysis\n",
      "- [ ]\u001b[0m\u001b[97m Provide detaile\u001b[0m\u001b[97md interpretation of data\u001b[0m\u001b[97m patterns an\u001b[0m\u001b[97md trends\n",
      "- [\u001b[0m\u001b[97m ] Articulate\u001b[0m\u001b[97m key marketing insights\u001b[0m\u001b[97m derived from the analysis\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Develop actionable recommendations for marketing\u001b[0m\u001b[97m strategy\u001b[0m\u001b[97m\n",
      "- [ ] Format\u001b[0m\u001b[97m the document with professional\u001b[0m\u001b[97m styling and layout\u001b[0m\u001b[97m\n",
      "- [ ] Generate\u001b[0m\u001b[97m and save the final report\u001b[0m\u001b[97m as a PDF \u001b[0m\u001b[97mdocument\u001b[0m\u001b[97mI'll\u001b[0m\u001b[97m help\u001b[0m\u001b[97m you execute\u001b[0m\u001b[97m this\u001b[0m\u001b[97m Amazon\u001b[0m\u001b[97m Fresh Food Sales Data\u001b[0m\u001b[97m Analysis project\u001b[0m\u001b[97m according\u001b[0m\u001b[97m to the plan.\u001b[0m\u001b[97m Looking\u001b[0m\u001b[97m at the full\u001b[0m\u001b[97m plan, we\u001b[0m\u001b[97m nee\u001b[0m\u001b[97md to start\u001b[0m\u001b[97m with\u001b[0m\u001b[97m the\u001b[0m\u001b[97m data\u001b[0m\u001b[97m analysis\u001b[0m\u001b[97m tasks\u001b[0m\u001b[97m before\u001b[0m\u001b[97m moving to the reporting\u001b[0m\u001b[97m phase\u001b[0m\u001b[97m.\u001b[0m\u001b[97m\n",
      "\n",
      "Let\u001b[0m\u001b[97m's begin\u001b[0m\u001b[97m with the first\u001b[0m\u001b[97m step -\u001b[0m\u001b[97m having\u001b[0m\u001b[97m the\u001b[0m\u001b[97m Coder agent\u001b[0m\u001b[97m perform\u001b[0m\u001b[97m the\u001b[0m\u001b[97m comprehensive\u001b[0m\u001b[97m data analysis and visualization\u001b[0m\u001b[97m.\u001b[0m\u001b[97m#\u001b[0m\u001b[97m Amazon Fresh Food íŒë§¤ ë°ì´\u001b[0m\u001b[97mí„° ë¶„ì„\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸\u001b[0m\u001b[97mìš”! Amazon Fresh Food íŒë§¤ \u001b[0m\u001b[97më°ì´í„°ë¥¼ ë¶„ì„í•˜\u001b[0m\u001b[97mì—¬ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼\u001b[0m\u001b[97m ë„ì¶œí•˜ëŠ” ì‘\u001b[0m\u001b[97mì—…ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\u001b[0m\u001b[97m ë°ì´í„° íŒŒì¼ \u001b[0m\u001b[97m\"./data/Dat-fresh-\u001b[0m\u001b[97mfood-claude.csv\"ë¥¼ \u001b[0m\u001b[97më¶„ì„í•˜ì—¬ ë‹¤ì–‘\u001b[0m\u001b[97mí•œ ë§ˆì¼€íŒ… \u001b[0m\u001b[97mì¸ì‚¬ì´íŠ¸ë¥¼\u001b[0m\u001b[97m ì¶”ì¶œí•˜ê² ìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\n",
      "\n",
      "## 1\u001b[0m\u001b[97m. ë°ì´í„° ë¡œ\u001b[0m\u001b[97më“œ ë° ê¸°\u001b[0m\u001b[97më³¸ íƒìƒ‰\u001b[0m\u001b[97m\n",
      "\n",
      "ë¨¼ì € ë°ì´í„°ë¥¼\u001b[0m\u001b[97m ë¡œë“œí•˜ê³  ê¸°ë³¸\u001b[0m\u001b[97mì ì¸ êµ¬ì¡°ë¥¼ ì‚´\u001b[0m\u001b[97mí´ë³´ê² ìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "\n",
      "# ë°ì´í„° ë¡œë“œ\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "try:\n",
      "    df = pd.read_csv(file_path)\n",
      "    print(\"ë°ì´í„° ë¡œë“œ ì„±ê³µ!\")\n",
      "    \n",
      "    # ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸\n",
      "    print(\"\\në°ì´í„° í¬ê¸°:\", df.shape)\n",
      "    print(\"\\në°ì´í„° ì»¬ëŸ¼:\", df.columns.tolist())\n",
      "    print(\"\\në°ì´í„° íƒ€ì…:\")\n",
      "    print(df.dtypes)\n",
      "    print(\"\\nì²˜ìŒ 5ê°œ í–‰:\")\n",
      "    print(df.head())\n",
      "    \n",
      "except FileNotFoundError:\n",
      "    print(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
      "except Exception as e:\n",
      "    print(f\"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "ë°ì´í„° ë¡œë“œ ì„±ê³µ!\n",
      "\n",
      "ë°ì´í„° í¬ê¸°: (1220, 18)\n",
      "\n",
      "ë°ì´í„° ì»¬ëŸ¼: ['index', 'Date', 'Status', 'Fulfilment', 'ship-service-level', 'Style', 'SKU', 'Category', 'Size', 'Courier Status', 'Qty', 'Amount', 'ship-city', 'ship-state', 'ship-postal-code', 'promotion-ids', 'Gender', 'Age Group']\n",
      "\n",
      "ë°ì´í„° íƒ€ì…:\n",
      "index                  int64\n",
      "Date                  object\n",
      "Status                object\n",
      "Fulfilment            object\n",
      "ship-service-level    object\n",
      "Style                 object\n",
      "SKU                   object\n",
      "Category              object\n",
      "Size                  object\n",
      "Courier Status        object\n",
      "Qty                    int64\n",
      "Amount                 int64\n",
      "ship-city             object\n",
      "ship-state            object\n",
      "ship-postal-code       int64\n",
      "promotion-ids         object\n",
      "Gender                object\n",
      "Age Group             object\n",
      "dtype: object\n",
      "\n",
      "ì²˜ìŒ 5ê°œ í–‰:\n",
      "   index    Date   Status  ... promotion-ids Gender Age Group\n",
      "0      1  1/1/24  Shipped  ...   FRUITPROMO5      F       30ëŒ€\n",
      "1      2  1/1/24  Shipped  ...           NaN      M       40ëŒ€\n",
      "2      3  1/1/24  Shipped  ...    FRESH10OFF      F       50ëŒ€\n",
      "3      4  1/1/24  Shipped  ...   FRUITPROMO5      M       30ëŒ€\n",
      "4      5  1/1/24  Shipped  ...    VEGGIESALE      F       50ëŒ€\n",
      "\n",
      "[5 rows x 18 columns]\n",
      "\n",
      "\u001b[0m\u001b[97mì´ì œ\u001b[0m\u001b[97m ê²°ì¸¡ì¹˜ì™€\u001b[0m\u001b[97m ê¸°ë³¸ í†µ\u001b[0m\u001b[97mê³„ ì •ë³´ë¥¼ \u001b[0m\u001b[97mí™•ì¸í•´ë³´ê² ìŠµë‹ˆ\u001b[0m\u001b[97më‹¤.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
      "print(\"ê²°ì¸¡ì¹˜ ê°œìˆ˜:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "# ê¸°ë³¸ í†µê³„ ì •ë³´\n",
      "print(\"\\nê¸°ë³¸ í†µê³„ ì •ë³´:\")\n",
      "print(df.describe())\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"<string>\", line 3, in <module>\n",
      "NameError: name 'df' is not defined\n",
      "\n",
      "\u001b[0m\u001b[97mì£„ì†¡í•©ë‹ˆ\u001b[0m\u001b[97më‹¤. ë°\u001b[0m\u001b[97mì´í„°í”„\u001b[0m\u001b[97më ˆì„ì„\u001b[0m\u001b[97m ë‹¤\u001b[0m\u001b[97mì‹œ ë¡œ\u001b[0m\u001b[97më“œí•˜ê³ \u001b[0m\u001b[97m ê²°\u001b[0m\u001b[97mì¸¡ì¹˜ì™€\u001b[0m\u001b[97m ê¸°ë³¸ \u001b[0m\u001b[97mí†µê³„ ì •\u001b[0m\u001b[97më³´ë¥¼ í™•\u001b[0m\u001b[97mì¸í•˜\u001b[0m\u001b[97mê² ìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ë°ì´í„° ë¡œë“œ\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
      "print(\"ê²°ì¸¡ì¹˜ ê°œìˆ˜:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "# ê¸°ë³¸ í†µê³„ ì •ë³´\n",
      "print(\"\\nê¸°ë³¸ í†µê³„ ì •ë³´:\")\n",
      "print(df.describe())\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "ê²°ì¸¡ì¹˜ ê°œìˆ˜:\n",
      "index                   0\n",
      "Date                    0\n",
      "Status                  0\n",
      "Fulfilment              0\n",
      "ship-service-level      0\n",
      "Style                   0\n",
      "SKU                     0\n",
      "Category                0\n",
      "Size                    0\n",
      "Courier Status          0\n",
      "Qty                     0\n",
      "Amount                  0\n",
      "ship-city               0\n",
      "ship-state              0\n",
      "ship-postal-code        0\n",
      "promotion-ids         103\n",
      "Gender                  0\n",
      "Age Group               0\n",
      "dtype: int64\n",
      "\n",
      "ê¸°ë³¸ í†µê³„ ì •ë³´:\n",
      "             index          Qty        Amount  ship-postal-code\n",
      "count  1220.000000  1220.000000   1220.000000       1220.000000\n",
      "mean    419.434426     1.794262   7064.877049      13582.980328\n",
      "std     280.003340     0.831773   3750.569930      21037.061393\n",
      "min       0.000000     1.000000   2900.000000       1000.000000\n",
      "25%     152.750000     1.000000   4500.000000       3000.000000\n",
      "50%     410.500000     2.000000   5990.000000       5000.000000\n",
      "75%     655.250000     3.000000   8500.000000      10300.000000\n",
      "max     935.000000     3.000000  23700.000000      99821.000000\n",
      "\n",
      "\u001b[0m\u001b[97mì´\u001b[0m\u001b[97mì œ ë°ì´í„°ì˜\u001b[0m\u001b[97m ê° \u001b[0m\u001b[97mì»¬ëŸ¼ì— ëŒ€í•œ\u001b[0m\u001b[97m ê³ ìœ ê°’ê³¼\u001b[0m\u001b[97m ë¶„í¬ë¥¼ í™•\u001b[0m\u001b[97mì¸í•´ë³´ê² ìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ë°ì´í„° ë¡œë“œ\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê³ ìœ ê°’ í™•ì¸\n",
      "categorical_columns = ['Status', 'Fulfilment', 'ship-service-level', 'Category', 'Size', 'Courier Status', 'Gender', 'Age Group']\n",
      "\n",
      "for col in categorical_columns:\n",
      "    print(f\"\\n{col} ê³ ìœ ê°’:\")\n",
      "    print(df[col].value_counts())\n",
      "    \n",
      "# Date ì»¬ëŸ¼ í™•ì¸\n",
      "print(\"\\nDate ê³ ìœ ê°’ ê°œìˆ˜:\", df['Date'].nunique())\n",
      "print(\"Date ë²”ìœ„:\", df['Date'].min(), \"~\", df['Date'].max())\n",
      "\n",
      "# promotion-ids í™•ì¸\n",
      "print(\"\\npromotion-ids ê³ ìœ ê°’:\")\n",
      "print(df['promotion-ids'].value_counts().head(10))  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "\n",
      "Status ê³ ìœ ê°’:\n",
      "Status\n",
      "Shipped    1220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fulfilment ê³ ìœ ê°’:\n",
      "Fulfilment\n",
      "Coupang         312\n",
      "Market Kurly    307\n",
      "SSG.com         302\n",
      "Amazon          299\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ship-service-level ê³ ìœ ê°’:\n",
      "ship-service-level\n",
      "Standard     588\n",
      "Expedited    403\n",
      "Priority     229\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Category ê³ ìœ ê°’:\n",
      "Category\n",
      "ì±„ì†Œ     458\n",
      "ê³¼ì¼     414\n",
      "ìœ ì œí’ˆ    348\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Size ê³ ìœ ê°’:\n",
      "Size\n",
      "300g    237\n",
      "500g    104\n",
      "200g    103\n",
      "1kg     100\n",
      "3ê°œì…      69\n",
      "1L       68\n",
      "400g     68\n",
      "1í†µ       68\n",
      "XL       54\n",
      "M        51\n",
      "L        48\n",
      "S        47\n",
      "1ê°œ       34\n",
      "5ê°œì…      34\n",
      "6ê°œì…      34\n",
      "2ê°œì…      34\n",
      "4ê°œì…      34\n",
      "250g     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Courier Status ê³ ìœ ê°’:\n",
      "Courier Status\n",
      "Delivered     1017\n",
      "In Transit     203\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Gender ê³ ìœ ê°’:\n",
      "Gender\n",
      "F    612\n",
      "M    608\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Age Group ê³ ìœ ê°’:\n",
      "Age Group\n",
      "30ëŒ€    412\n",
      "50ëŒ€    301\n",
      "40ëŒ€    298\n",
      "20ëŒ€    112\n",
      "60ëŒ€     96\n",
      "40       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date ê³ ìœ ê°’ ê°œìˆ˜: 182\n",
      "Date ë²”ìœ„: 1/1/24 ~ 6/9/24\n",
      "\n",
      "promotion-ids ê³ ìœ ê°’:\n",
      "promotion-ids\n",
      "VEGGIESALE     271\n",
      "DAIRYPROMO     270\n",
      "FRUITPROMO5    205\n",
      "SUMMERFRUIT    136\n",
      "EARLY5          53\n",
      "NONE            47\n",
      "SPRING24        44\n",
      "FRESH10OFF      35\n",
      "FRESH10         35\n",
      "BUNDLE15        21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\u001b[0m\u001b[97mì´\u001b[0m\u001b[97mì œ\u001b[0m\u001b[97m Date\u001b[0m\u001b[97m ì»¬\u001b[0m\u001b[97mëŸ¼ì„\u001b[0m\u001b[97m ë‚ \u001b[0m\u001b[97mì§œ í˜•\u001b[0m\u001b[97mì‹ìœ¼ë¡œ \u001b[0m\u001b[97më³€í™˜í•˜ê³ \u001b[0m\u001b[97m,\u001b[0m\u001b[97m \u001b[0m\u001b[97më°\u001b[0m\u001b[97mì´í„° ì „\u001b[0m\u001b[97mì²˜ë¦¬ë¥¼ \u001b[0m\u001b[97mì§„í–‰í•˜\u001b[0m\u001b[97mê² ìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from datetime import datetime\n",
      "\n",
      "# ë°ì´í„° ë¡œë“œ\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Date ì»¬ëŸ¼ì„ ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
      "\n",
      "# ë‚ ì§œ ê´€ë ¨ ì¶”ê°€ ì»¬ëŸ¼ ìƒì„±\n",
      "df['Month'] = df['Date'].dt.month\n",
      "df['Day'] = df['Date'].dt.day\n",
      "df['Weekday'] = df['Date'].dt.day_name()\n",
      "\n",
      "# promotion-idsì˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
      "df['promotion-ids'].fillna('NONE', inplace=True)\n",
      "\n",
      "# ë°ì´í„° ì „ì²˜ë¦¬ ê²°ê³¼ í™•ì¸\n",
      "print(\"ë°ì´í„° ì „ì²˜ë¦¬ í›„ ì •ë³´:\")\n",
      "print(df.info())\n",
      "\n",
      "# ë‚ ì§œ ë³€í™˜ í™•ì¸\n",
      "print(\"\\në‚ ì§œ ë³€í™˜ ê²°ê³¼:\")\n",
      "print(df[['Date', 'Month', 'Day', 'Weekday']].head())\n",
      "\n",
      "# ì›”ë³„ ë°ì´í„° ìˆ˜ í™•ì¸\n",
      "print(\"\\nì›”ë³„ ë°ì´í„° ìˆ˜:\")\n",
      "print(df['Month'].value_counts().sort_index())\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "ë°ì´í„° ì „ì²˜ë¦¬ í›„ ì •ë³´:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1220 entries, 0 to 1219\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   index               1220 non-null   int64         \n",
      " 1   Date                1220 non-null   datetime64[ns]\n",
      " 2   Status              1220 non-null   object        \n",
      " 3   Fulfilment          1220 non-null   object        \n",
      " 4   ship-service-level  1220 non-null   object        \n",
      " 5   Style               1220 non-null   object        \n",
      " 6   SKU                 1220 non-null   object        \n",
      " 7   Category            1220 non-null   object        \n",
      " 8   Size                1220 non-null   object        \n",
      " 9   Courier Status      1220 non-null   object        \n",
      " 10  Qty                 1220 non-null   int64         \n",
      " 11  Amount              1220 non-null   int64         \n",
      " 12  ship-city           1220 non-null   object        \n",
      " 13  ship-state          1220 non-null   object        \n",
      " 14  ship-postal-code    1220 non-null   int64         \n",
      " 15  promotion-ids       1220 non-null   object        \n",
      " 16  Gender              1220 non-null   object        \n",
      " 17  Age Group           1220 non-null   object        \n",
      " 18  Month               1220 non-null   int32         \n",
      " 19  Day                 1220 non-null   int32         \n",
      " 20  Weekday             1220 non-null   object        \n",
      "dtypes: datetime64[ns](1), int32(2), int64(4), object(14)\n",
      "memory usage: 190.8+ KB\n",
      "None\n",
      "\n",
      "ë‚ ì§œ ë³€í™˜ ê²°ê³¼:\n",
      "        Date  Month  Day Weekday\n",
      "0 2024-01-01      1    1  Monday\n",
      "1 2024-01-01      1    1  Monday\n",
      "2 2024-01-01      1    1  Monday\n",
      "3 2024-01-01      1    1  Monday\n",
      "4 2024-01-01      1    1  Monday\n",
      "\n",
      "ì›”ë³„ ë°ì´í„° ìˆ˜:\n",
      "Month\n",
      "1    191\n",
      "2    177\n",
      "3    193\n",
      "4    204\n",
      "5    259\n",
      "6    196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\u001b[0m\u001b[97mì´\u001b[0m\u001b[97mì œ ë°ì´í„°\u001b[0m\u001b[97më¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤\u001b[0m\u001b[97mì–‘í•œ ë¶„ì„\u001b[0m\u001b[97mì„ ì§„í–‰í•˜\u001b[0m\u001b[97mê² ìŠµë‹ˆë‹¤.\u001b[0m\u001b[97m ë¨¼ì € íŒ\u001b[0m\u001b[97më§¤ íŠ¸ë Œë“œë¥¼\u001b[0m\u001b[97m ë¶„ì„í•´ë³´\u001b[0m\u001b[97mê² ìŠµë‹ˆë‹¤.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import os\n",
      "\n",
      "# ë°ì´í„° ë¡œë“œ\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Date ì»¬ëŸ¼ì„ ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
      "\n",
      "# ë‚ ì§œ ê´€ë ¨ ì¶”ê°€ ì»¬ëŸ¼ ìƒì„±\n",
      "df['Month'] = df['Date'].dt.month\n",
      "df['Day'] = df['Date'].dt.day\n",
      "df['Weekday'] = df['Date'].dt.day_name()\n",
      "\n",
      "# ì›”ë³„ íŒë§¤ëŸ‰ ë° ë§¤ì¶œì•¡ ë¶„ì„\n",
      "monthly_sales = df.groupby('Month').agg({\n",
      "    'Qty': 'sum',\n",
      "    'Amount': 'sum'\n",
      "}).reset_index()\n",
      "\n",
      "# ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ íŒë§¤ëŸ‰ ë¶„ì„\n",
      "category_monthly_sales = df.groupby(['Month', 'Category']).agg({\n",
      "    'Qty': 'sum',\n",
      "    'Amount': 'sum'\n",
      "}).reset_index()\n",
      "\n",
      "# ìš”ì¼ë³„ íŒë§¤ëŸ‰ ë¶„ì„\n",
      "weekday_sales = df.groupby('Weekday').agg({\n",
      "    'Qty': 'sum',\n",
      "    'Amount': 'sum'\n",
      "}).reset_index()\n",
      "\n",
      "# ìš”ì¼ ìˆœì„œ ì •ì˜\n",
      "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
      "weekday_sales['Weekday'] = pd.Categorical(weekday_sales['Weekday'], categories=weekday_order, ordered=True)\n",
      "weekday_sales = weekday_sales.sort_values('Weekday')\n",
      "\n",
      "# ì‹œê°í™”ë¥¼ ìœ„í•œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
      "plt.rc('font', family='NanumGothic')\n",
      "plt.rcParams['axes.unicode_minus'] = False\n",
      "\n",
      "# ì›”ë³„ íŒë§¤ëŸ‰ ì‹œê°í™”\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "plt.plot(monthly_sales['Month'], monthly_sales['Qty'], marker='o', linewidth=2, color='#3498db')\n",
      "plt.title('ì›”ë³„ íŒë§¤ëŸ‰ ì¶”ì´', fontsize=16)\n",
      "plt.xlabel('ì›”', fontsize=14)\n",
      "plt.ylabel('íŒë§¤ëŸ‰', fontsize=14)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.xticks(monthly_sales['Month'])\n",
      "plt.savefig('./artifacts/monthly_sales_qty.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# ì›”ë³„ ë§¤ì¶œì•¡ ì‹œê°í™”\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "plt.plot(monthly_sales['Month'], monthly_sales['Amount'] / 1000, marker='o', linewidth=2, color='#e74c3c')\n",
      "plt.title('ì›”ë³„ ë§¤ì¶œì•¡ ì¶”ì´', fontsize=16)\n",
      "plt.xlabel('ì›”', fontsize=14)\n",
      "plt.ylabel('ë§¤ì¶œì•¡ (ì²œì›)', fontsize=14)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.xticks(monthly_sales['Month'])\n",
      "plt.savefig('./artifacts/monthly_sales_amount.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ íŒë§¤ëŸ‰ ì‹œê°í™”\n",
      "plt.figure(figsize=(14, 7), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "\n",
      "for category in df['Category'].unique():\n",
      "    data = category_monthly_sales[category_monthly_sales['Category'] == category]\n",
      "    plt.plot(data['Month'], data['Qty'], marker='o', linewidth=2, label=category)\n",
      "\n",
      "plt.title('ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ íŒë§¤ëŸ‰ ì¶”ì´', fontsize=16)\n",
      "plt.xlabel('ì›”', fontsize=14)\n",
      "plt.ylabel('íŒë§¤ëŸ‰', fontsize=14)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.xticks(monthly_sales['Month'])\n",
      "plt.legend(fontsize=12)\n",
      "plt.savefig('./artifacts/category_monthly_sales.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# ìš”ì¼ë³„ íŒë§¤ëŸ‰ ì‹œê°í™”\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "plt.bar(weekday_sales['Weekday'], weekday_sales['Qty'], color='#2ecc71')\n",
      "plt.title('ìš”ì¼ë³„ íŒë§¤ëŸ‰', fontsize=16)\n",
      "plt.xlabel('ìš”ì¼', fontsize=14)\n",
      "plt.ylabel('íŒë§¤ëŸ‰', fontsize=14)\n",
      "plt.grid(True, alpha=0.3, axis='y')\n",
      "plt.savefig('./artifacts/weekday_sales_qty.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# ê²°ê³¼ ì¶œë ¥\n",
      "print(\"ì›”ë³„ íŒë§¤ëŸ‰ ë° ë§¤ì¶œì•¡:\")\n",
      "print(monthly_sales)\n",
      "\n",
      "print(\"\\nì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ íŒë§¤ëŸ‰:\")\n",
      "print(category_monthly_sales)\n",
      "\n",
      "print(\"\\nìš”ì¼ë³„ íŒë§¤ëŸ‰ ë° ë§¤ì¶œì•¡:\")\n",
      "print(weekday_sales)\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "ì›”ë³„ íŒë§¤ëŸ‰ ë° ë§¤ì¶œì•¡:\n",
      "   Month  Qty   Amount\n",
      "0      1  351  1357640\n",
      "1      2  318  1301850\n",
      "2      3  342  1355050\n",
      "3      4  363  1423340\n",
      "4      5  468  1834730\n",
      "5      6  347  1346540\n",
      "\n",
      "ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ íŒë§¤ëŸ‰:\n",
      "    Month Category  Qty  Amount\n",
      "0       1       ê³¼ì¼  122  639540\n",
      "1       1      ìœ ì œí’ˆ   98  361400\n",
      "2       1       ì±„ì†Œ  131  356700\n",
      "3       2       ê³¼ì¼  116  644650\n",
      "4       2      ìœ ì œí’ˆ   86  332800\n",
      "5       2       ì±„ì†Œ  116  324400\n",
      "6       3       ê³¼ì¼  112  585150\n",
      "7       3      ìœ ì œí’ˆ   99  396700\n",
      "8       3       ì±„ì†Œ  131  373200\n",
      "9       4       ê³¼ì¼  118  638240\n",
      "10      4      ìœ ì œí’ˆ   93  329400\n",
      "11      4       ì±„ì†Œ  152  455700\n",
      "12      5       ê³¼ì¼  160  846630\n",
      "13      5      ìœ ì œí’ˆ  129  491200\n",
      "14      5       ì±„ì†Œ  179  496900\n",
      "15      6       ê³¼ì¼  115  613140\n",
      "16      6      ìœ ì œí’ˆ   97  350600\n",
      "17      6       ì±„ì†Œ  135  382800\n",
      "\n",
      "ìš”ì¼ë³„ íŒë§¤ëŸ‰ ë° ë§¤ì¶œì•¡:\n",
      "     Weekday  Qty   Amount\n",
      "1     Monday  316  1246450\n",
      "5    Tuesday  296  1162160\n",
      "6  Wednesday  304  1214360\n",
      "4   Thursday  311  1229250\n",
      "0     Friday  315  1262840\n",
      "2   Saturday  303  1166750\n",
      "3     Sunday  344  1337340\n",
      "\n",
      "\u001b[0m\u001b[97mì´\u001b[0m\u001b[97mì œ íŒ\u001b[0m\u001b[97më§¤ íŠ¸\u001b[0m\u001b[97më Œë“œ \u001b[0m\u001b[97më¶„ì„ \u001b[0m\u001b[97mê²°ê³¼ë¥¼ \u001b[0m\u001b[97mì €ì¥í•˜ê³ ,\u001b[0m\u001b[97m ì¹´í…Œê³ ë¦¬ë³„\u001b[0m\u001b[97m ë¶„ì„ì„\u001b[0m\u001b[97m ë”\u001b[0m\u001b[97m ì\u001b[0m\u001b[97mì„¸íˆ ì§„\u001b[0m\u001b[97mí–‰í•˜ê² \u001b[0m\u001b[97mìŠµë‹ˆë‹¤.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "# Result accumulation storage section\n",
      "import os\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "\n",
      "# Create artifacts directory\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Result file path\n",
      "results_file = './artifacts/all_results.txt'\n",
      "backup_file = './artifacts/all_results_backup_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "\n",
      "# Current analysis parameters - modify these values according to your actual analysis\n",
      "stage_name = \"íŒë§¤ íŠ¸ë Œë“œ ë¶„ì„\"\n",
      "result_description = \"\"\"\n",
      "1. ì›”ë³„ íŒë§¤ëŸ‰ ë° ë§¤ì¶œì•¡ ë¶„ì„:\n",
      "   - 5ì›”ì— ê°€ì¥ ë†’ì€ íŒë§¤ëŸ‰(468ê°œ)ê³¼ ë§¤ì¶œì•¡(1,834,730ì›)ì„ ê¸°ë¡\n",
      "   - 1ì›”ë¶€í„° 5ì›”ê¹Œì§€ íŒë§¤ëŸ‰ì´ ì¦ê°€í•˜ë‹¤ê°€ 6ì›”ì— ê°ì†Œí•˜ëŠ” ì¶”ì„¸\n",
      "   - íŒë§¤ëŸ‰ê³¼ ë§¤ì¶œì•¡ì€ ë¹„ë¡€í•˜ëŠ” ê²½í–¥ì„ ë³´ì„\n",
      "\n",
      "2. ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ íŒë§¤ëŸ‰ ë¶„ì„:\n",
      "   - ì±„ì†Œ ì¹´í…Œê³ ë¦¬: 1ì›”(131ê°œ), 2ì›”(116ê°œ), 3ì›”(131ê°œ), 4ì›”(152ê°œ), 5ì›”(179ê°œ), 6ì›”(135ê°œ)\n",
      "   - ê³¼ì¼ ì¹´í…Œê³ ë¦¬: 1ì›”(122ê°œ), 2ì›”(116ê°œ), 3ì›”(112ê°œ), 4ì›”(118ê°œ), 5ì›”(160ê°œ), 6ì›”(115ê°œ)\n",
      "   - ìœ ì œí’ˆ ì¹´í…Œê³ ë¦¬: 1ì›”(98ê°œ), 2ì›”(86ê°œ), 3ì›”(99ê°œ), 4ì›”(93ê°œ), 5ì›”(129ê°œ), 6ì›”(97ê°œ)\n",
      "   - ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ 5ì›”ì— íŒë§¤ëŸ‰ì´ ê°€ì¥ ë†’ìŒ\n",
      "\n",
      "3. ìš”ì¼ë³„ íŒë§¤ëŸ‰ ë¶„ì„:\n",
      "   - ì¼ìš”ì¼ì— ê°€ì¥ ë†’ì€ íŒë§¤ëŸ‰(344ê°œ)ê³¼ ë§¤ì¶œì•¡(1,337,340ì›)ì„ ê¸°ë¡\n",
      "   - í™”ìš”ì¼ì— ê°€ì¥ ë‚®ì€ íŒë§¤ëŸ‰(296ê°œ)ê³¼ ë§¤ì¶œì•¡(1,162,160ì›)ì„ ê¸°ë¡\n",
      "   - ì£¼ë§(ê¸ˆ-ì¼)ì— íŒë§¤ëŸ‰ì´ ì¦ê°€í•˜ëŠ” ê²½í–¥ì„ ë³´ì„\n",
      "\"\"\"\n",
      "\n",
      "# [CRITICAL] Key findings and insights from analysis - ALWAYS include this section\n",
      "key_insights = \"\"\"\n",
      "[DISCOVERY & INSIGHTS]:\n",
      "- Discovery 1: 5ì›”ì— ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ íŒë§¤ëŸ‰ê³¼ ë§¤ì¶œì•¡ì´ ê¸‰ì¦í•˜ëŠ” í˜„ìƒì´ ë°œê²¬ë¨\n",
      "- Insight 1: 5ì›”ì€ ê°€ì •ì˜ ë‹¬ë¡œ ì„ ë¬¼ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³ , ë‚ ì”¨ê°€ ë”°ëœ»í•´ì§€ë©´ì„œ ì‹ ì„ ì‹í’ˆ ì†Œë¹„ê°€ ì¦ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •ë¨\n",
      "- Discovery 2: ì¼ìš”ì¼ì— íŒë§¤ëŸ‰ì´ ê°€ì¥ ë†’ê³ , í™”ìš”ì¼ì— ê°€ì¥ ë‚®ì€ íŒ¨í„´ì´ ë°œê²¬ë¨\n",
      "- Insight 2: ì£¼ë§ì— ì¥ì„ ë³´ëŠ” ì†Œë¹„ì í–‰ë™ íŒ¨í„´ì´ ë°˜ì˜ëœ ê²ƒìœ¼ë¡œ ë³´ì´ë©°, ì£¼ë§ ë§ˆì¼€íŒ… ê°•í™” ì „ëµì´ íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŒ\n",
      "- Discovery 3: ì±„ì†Œ ì¹´í…Œê³ ë¦¬ê°€ ì „ë°˜ì ìœ¼ë¡œ ê°€ì¥ ë†’ì€ íŒë§¤ëŸ‰ì„ ë³´ì´ì§€ë§Œ, ê³¼ì¼ ì¹´í…Œê³ ë¦¬ê°€ ë” ë†’ì€ ë§¤ì¶œì•¡ì„ ê¸°ë¡í•¨\n",
      "- Insight 3: ê³¼ì¼ ì œí’ˆì˜ ë‹¨ê°€ê°€ ë” ë†’ì•„ ìˆ˜ìµì„±ì´ ì¢‹ìœ¼ë¯€ë¡œ, ê³¼ì¼ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ í”„ë¡œëª¨ì…˜ ê°•í™”ê°€ ë§¤ì¶œ ì¦ëŒ€ì— íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŒ\n",
      "- Methodology insight: ì‹œê³„ì—´ ë¶„ì„ì„ í†µí•´ ì›”ë³„, ìš”ì¼ë³„ íŒ¨í„´ì„ íŒŒì•…í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ì— í™œìš©í•  ìˆ˜ ìˆìŒ\n",
      "- Business implication: 5ì›” íŠ¹ë³„ í”„ë¡œëª¨ì…˜ ê°•í™”, ì£¼ë§ ë§ˆì¼€íŒ… ì§‘ì¤‘, ê³¼ì¼ ì¹´í…Œê³ ë¦¬ í”„ë¡œëª¨ì…˜ì„ í†µí•œ ë§¤ì¶œ ì¦ëŒ€ ì „ëµ ìˆ˜ë¦½ í•„ìš”\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/monthly_sales_qty.png\", \"ì›”ë³„ íŒë§¤ëŸ‰ ì¶”ì´ ê·¸ë˜í”„\"],\n",
      "    [\"./artifacts/monthly_sales_amount.png\", \"ì›”ë³„ ë§¤ì¶œì•¡ ì¶”ì´ ê·¸ë˜í”„\"],\n",
      "    [\"./artifacts/category_monthly_sales.png\", \"ì¹´í…Œê³ ë¦¬ë³„ ì›”ë³„ íŒë§¤ëŸ‰ ì¶”ì´ ê·¸ë˜í”„\"],\n",
      "    [\"./artifacts/weekday_sales_qty.png\", \"ìš”ì¼ë³„ íŒë§¤ëŸ‰ ê·¸ë˜í”„\"]\n",
      "]\n",
      "\n",
      "# Direct generation of result text without using a function\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = \"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {0}\n",
      "## Execution Time: {1}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{2}\n",
      "--------------------------------------------------\n",
      "Key Findings & Insights:\n",
      "{3}\n",
      "\"\"\".format(stage_name, current_time, result_description, key_insights)\n",
      "\n",
      "if artifact_files:\n",
      "    current_result_text += \"--------------------------------------------------\\nGenerated Files:\\n\"\n",
      "    for file_path, file_desc in artifact_files:\n",
      "        current_result_text += \"- {} : {}\\n\".format(file_path, file_desc)\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Backup existing result file and accumulate results\n",
      "if os.path.exists(results_file):\n",
      "    try:\n",
      "        # Check file size\n",
      "        if os.path.getsize(results_file) > 0:\n",
      "            # Create backup\n",
      "            with open(results_file, 'r', encoding='utf-8') as f_src:\n",
      "                with open(backup_file, 'w', encoding='utf-8') as f_dst:\n",
      "                    f_dst.write(f_src.read())\n",
      "            print(\"Created backup of existing results file: {}\".format(backup_file))\n",
      "    except Exception as e:\n",
      "        print(\"Error occurred during file backup: {}\".format(e))\n",
      "\n",
      "# Add new results (accumulate to existing file)\n",
      "try:\n",
      "    with open(results_file, 'a', encoding='utf-8') as f:\n",
      "        f.write(current_result_text)\n",
      "    print(\"Results successfully saved.\")\n",
      "except Exception as e:\n",
      "    print(\"Error occurred while saving results: {}\".format(e))\n",
      "    # Try saving to temporary file in case of error\n",
      "    try:\n",
      "        temp_file = './artifacts/result_emergency_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "        with open(temp_file, 'w', encoding='utf-8') as f:\n",
      "            f.write(current_result_text)\n",
      "        print(\"Results saved to temporary file: {}\".format(temp_file))\n",
      "    except Exception as e2:\n",
      "        print(\"Temporary file save also failed: {}\".format(e2))\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Results successfully saved.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ReadTimeoutError",
     "evalue": "Read timeout on endpoint URL: \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:779\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:473\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:597\u001b[39m, in \u001b[36mHTTPResponse._read_chunked\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    598\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt <= chunk_left:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:579\u001b[39m, in \u001b[36mHTTPResponse._get_chunk_left\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     chunk_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:539\u001b[39m, in \u001b[36mHTTPResponse._read_next_chunk_size\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    538\u001b[39m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:98\u001b[39m, in \u001b[36mStreamingBody.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:903\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m    904\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._fp_read(amt, read1=read1) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:784\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\u001b[38;5;28mself\u001b[39m._pool, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mRead timed out.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BaseSSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    787\u001b[39m     \u001b[38;5;66;03m# FIXME: Is there a better way to differentiate between SSLErrors?\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: AWSHTTPSConnectionPool(host='bedrock-agentcore.us-west-2.amazonaws.com', port=443): Read timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtext/event-stream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m boto3_response.get(\u001b[33m\"\u001b[39m\u001b[33mcontentType\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     54\u001b[39m     content = []\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mboto3_response\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_sse_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None ì²´í¬ ì¶”ê°€\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:157\u001b[39m, in \u001b[36mStreamingBody.iter_lines\u001b[39m\u001b[34m(self, chunk_size, keepends)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an iterator to yield lines from the raw stream.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m \u001b[33;03mThis is achieved by reading chunk of bytes (of size chunk_size) at a\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03mtime from the raw stream, and then yielding lines from there.\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m pending = \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:170\u001b[39m, in \u001b[36mStreamingBody.iter_chunks\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an iterator to yield chunks of chunk_size bytes from the raw\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03mstream.\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     current_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m current_chunk == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:101\u001b[39m, in \u001b[36mStreamingBody.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m     98\u001b[39m     chunk = \u001b[38;5;28mself\u001b[39m._raw_stream.read(amt)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(endpoint_url=e.url, error=e)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResponseStreamingError(error=e)\n",
      "\u001b[31mReadTimeoutError\u001b[39m: Read timeout on endpoint URL: \"None\""
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "from src.utils.strands_sdk_utils import strands_utils\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "def parse_sse_data(sse_bytes):\n",
    "    if not sse_bytes or len(sse_bytes) == 0:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        text = sse_bytes.decode('utf-8').strip()\n",
    "        if not text or text == '': return None\n",
    "\n",
    "        if text.startswith('data: '):\n",
    "            json_text = text[6:].strip()\n",
    "            if json_text: return json.loads(json_text)\n",
    "        else:\n",
    "            return json.loads(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        # ë””ë²„ê¹…ìš©ìœ¼ë¡œë§Œ ì¶œë ¥\n",
    "        # print(f\"Parse error: {e}\")\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "      \n",
    "\n",
    "agent_arn = launch_result.agent_arn\n",
    "from botocore.config import Config\n",
    "\n",
    "my_config = Config(\n",
    "    connect_timeout=60*100,\n",
    "    read_timeout=60*5,\n",
    ")\n",
    "\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region,\n",
    "    config=my_config,\n",
    ")\n",
    "\n",
    "#agent_arn = \"arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\"\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    #payload=json.dumps({\"prompt\": \"What is the weather now?\"})\n",
    "    payload=json.dumps({\"prompt\": 'ì´ê²ƒì€ ì•„ë§ˆì¡´ ìƒí’ˆíŒë§¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ë¶„ì„ëŒ€ìƒì€ \"./data/Dat-fresh-food-claude.csv\" íŒŒì¼ ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œì„ ìœ„í•œ ë¶„ì„ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¶„ì„ì€ ê¸°ë³¸ì ì¸ ë°ì´í„° ì†ì„± íƒìƒ‰ ë¶€í„°, ìƒí’ˆ íŒë§¤ íŠ¸ë Œë“œ, ë³€ìˆ˜ ê´€ê³„, ë³€ìˆ˜ ì¡°í•© ë“± ë‹¤ì–‘í•œ ë¶„ì„ ê¸°ë²•ì„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”. ë°ì´í„° ë¶„ì„ í›„ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œì— í•„ìš”í•œ ì‚¬í•­ì´ ìˆë‹¤ë©´ ê·¸ë¥¼ ìœ„í•œ ì¶”ê°€ ë¶„ì„ë„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”. ë¶„ì„ ë¦¬í¬íŠ¸ëŠ” ìƒì„¸ ë¶„ì„ê³¼ ê·¸ ê²ƒì„ ë’·ë°›ì¹¨ í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ ë° ì°¨íŠ¸ë¥¼ í•¨ê»˜ ì‚½ì…í•´ ì£¼ì„¸ìš”. ìµœì¢… ë¦¬í¬íŠ¸ëŠ” pdf í˜•íƒœë¡œ ì €ì¥í•´ ì£¼ì„¸ìš”.'})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for event in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        event = parse_sse_data(event)\n",
    "        if event is None:  # None ì²´í¬ ì¶”ê°€\n",
    "            continue\n",
    "        else:\n",
    "            strands_utils.process_event_for_display(event)\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            print (\"6\", event)\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "### Processing invocation results\n",
    "\n",
    "We can now process our invocation results to include it in an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249103-cfb3-47b5-970d-981a977a225a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "response_text = json.loads(invoke_response['response'][0].decode(\"utf-8\"))\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime with boto3\n",
    "\n",
    "Now that your AgentCore Runtime was created you can invoke it with any AWS SDK. For instance, you can use the boto3 `invoke_agent_runtime` method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84e68d-6c04-41b9-bf5b-60edc3fa0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    #payload=json.dumps({\"prompt\": \"What is the weather now?\"})\n",
    "    payload=json.dumps({\"prompt\": \"ì•ˆë…• ë‚˜ëŠ” ì¥ë™ì§„ì´ë¼ê³  í•´. ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ ë‚˜ëŠ” ë°ì´í„°ë¥¼ ì œê³µí•˜ê³  ê·¸ê²ƒìœ¼ë¡œ ë¶€í„° ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì‹¶ì–´.\"})\n",
    "    #agentcore_runtime.invoke({\"prompt\": \"ì•ˆë…• ë‚˜ëŠ” ì¥ë™ì§„ì´ë¼ê³  í•´. ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ ë‚˜ëŠ” ë°ì´í„°ë¥¼ ì œê³µí•˜ê³  ê·¸ê²ƒìœ¼ë¡œ ë¶€í„° ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì‹¶ì–´.\"})\n",
    ")\n",
    "# if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "#     content = []\n",
    "#     for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "#         if line:\n",
    "#             line = line.decode(\"utf-8\")\n",
    "#             if line.startswith(\"data: \"):\n",
    "#                 line = line[6:]\n",
    "#                 logger.info(line)\n",
    "#                 content.append(line)\n",
    "#     display(Markdown(\"\\n\".join(content)))\n",
    "# else:\n",
    "#     try:\n",
    "#         events = []\n",
    "#         for event in boto3_response.get(\"response\", []):\n",
    "#             events.append(event)\n",
    "#     except Exception as e:\n",
    "#         events = [f\"Error reading EventStream: {e}\"]\n",
    "#     display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86824-c775-4ad4-aaee-f18e8cf390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "iam_response = iam_client.delete_role(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-manus-agentcore (UV)",
   "language": "python",
   "name": "bedrock-manus-agentcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}