import copy
import pandas as pd
from typing import List, Tuple, Dict, Any
from opensearchpy import OpenSearch, RequestsHttpConnection
from opensearchpy.helpers import bulk

class opensearch_utils():
    
    @classmethod
    def create_aws_opensearch_client(cls, region: str, host: str, http_auth: Tuple[str, str]) -> OpenSearch:

        client = OpenSearch(
            hosts=[
                {'host': host.replace("https://", ""),
                 'port': 443
                }
            ],
            http_auth=http_auth,
            use_ssl=True,
            verify_certs=True,
            connection_class=RequestsHttpConnection
        )

        return client

    @classmethod
    def create_index(cls, os_client, index_name, index_body):
        '''
        ì¸ë±ìŠ¤ ìƒì„±
        '''
        response = os_client.indices.create(
            index=index_name,  # í‚¤ì›Œë“œ ì¸ìë¡œ ë³€ê²½
            body=index_body
        )
        print('\nCreating index:')
        print(response)

    @classmethod
    def check_if_index_exists(cls, os_client, index_name):
        '''
        ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        '''
        exists = os_client.indices.exists(index=index_name)  # í‚¤ì›Œë“œ ì¸ìë¡œ ë³€ê²½
        print(f"index_name={index_name}, exists={exists}")

        return exists

    @classmethod
    def delete_index_if_exists(cls, os_client, index_name):
        '''
        ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ë©´ ì‚­ì œ
        '''
        if cls.check_if_index_exists(os_client, index_name):
            cls.delete_index(os_client, index_name)
            return True
        return False

    @classmethod
    def add_doc(cls, os_client, index_name, document, id):
        '''
        # Add a document to the index.
        '''
        response = os_client.index(
            index = index_name,
            body = document,
            id = id,
            refresh = True
        )

        print('\nAdding document:')
        print(response)

    @classmethod
    def bulk_index_documents(cls, os_client, documents: List[Dict], index_name: str, 
                           mapping: Dict = None, id_field: str = None, 
                           batch_size: int = 500, create_index: bool = True) -> Dict:
        '''
        ë¬¸ì„œë“¤ì„ ë²Œí¬ë¡œ ì¸ë±ì‹±
        
        Args:
            os_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
            documents: ì¸ë±ì‹±í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
            index_name: ëŒ€ìƒ ì¸ë±ìŠ¤ëª…
            mapping: ì¸ë±ìŠ¤ ë§¤í•‘ (Noneì´ë©´ ê¸°ë³¸ ë§¤í•‘ ì‚¬ìš©)
            id_field: IDë¡œ ì‚¬ìš©í•  í•„ë“œëª… (Noneì´ë©´ ìë™ ìƒì„±)
            batch_size: ë°°ì¹˜ í¬ê¸°
            create_index: ì¸ë±ìŠ¤ ìƒì„± ì—¬ë¶€

            ex) documents = [
                    {"name": "Product A", "price": 100.0, "date": "2024-01-01"},
                    {"name": "Product B", "price": 200.0, "date": "2024-01-02"},
                    {"name": "Product C", "price": 300.0, "date": "2024-01-03"}
                ]
            
        Returns:
            ì¸ë±ì‹± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        '''
        try:
            # ì¸ë±ìŠ¤ ìƒì„± (í•„ìš”í•œ ê²½ìš°)
            if create_index:
                if mapping:
                    cls.delete_index_if_exists(os_client, index_name)
                    # ë§¤í•‘ì„ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë³€í™˜
                    index_body = {"mappings": mapping}
                    cls.create_index(os_client, index_name, index_body)
                else:
                    # ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±ë¨ (dynamic mapping)
                    if not cls.check_if_index_exists(os_client, index_name):
                        print(f'â„¹ï¸  ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìë™ ë§¤í•‘ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤: {index_name}')
            
            def doc_generator():
                for i, doc in enumerate(documents):
                    doc_id = doc.get(id_field) if id_field else i + 1
                    yield {
                        "_index": index_name,
                        "_id": doc_id,
                        "_source": doc
                    }
            
            # ë²Œí¬ ì¸ë±ì‹± ì‹¤í–‰
            success_count, errors = bulk(
                os_client,
                doc_generator(),
                chunk_size=batch_size,
                request_timeout=60
            )
            
            result = {
                "success": True,
                "indexed_count": success_count,
                "errors": errors,
                "total_documents": len(documents)
            }
            
            print(f'âœ… ë²Œí¬ ì¸ë±ì‹± ì™„ë£Œ: {index_name} ({success_count}/{len(documents)}ê°œ ë¬¸ì„œ)')
            
            if errors:
                print(f'âš ï¸  {len(errors)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì‹¤íŒ¨')
                
            return result
            
        except Exception as e:
            print(f'âŒ ë²Œí¬ ì¸ë±ì‹± ì‹¤íŒ¨ {index_name}: {e}')
            return {
                "success": False,
                "error": str(e),
                "indexed_count": 0,
                "total_documents": len(documents)
            }

    @classmethod
    def bulk_index_from_csv(cls, os_client, csv_path: str, index_name: str, 
                          mapping: Dict = None, id_field: str = None, 
                          batch_size: int = 500) -> Dict:
        '''
        CSV íŒŒì¼ì—ì„œ ì§ì ‘ ë²Œí¬ ì¸ë±ì‹±
        
        Args:
            os_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
            csv_path: CSV íŒŒì¼ ê²½ë¡œ
            index_name: ëŒ€ìƒ ì¸ë±ìŠ¤ëª…
            mapping: ì¸ë±ìŠ¤ ë§¤í•‘ (Noneì´ë©´ ì¸ë±ìŠ¤ ìƒì„± ì•ˆí•¨)
            id_field: IDë¡œ ì‚¬ìš©í•  í•„ë“œëª…
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            ì¸ë±ì‹± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        '''
        try:
            # CSV íŒŒì¼ ì½ê¸°
            df = pd.read_csv(csv_path)
            print(f'ğŸ“„ CSV ë¡œë“œ: {csv_path} ({len(df)}í–‰)')
            
            # ì¸ë±ìŠ¤ ìƒì„± (ë§¤í•‘ì´ ì œê³µëœ ê²½ìš°)
            if mapping:
                cls.delete_index_if_exists(os_client, index_name)
                index_body = {"mappings": mapping}
                cls.create_index(os_client, index_name, index_body)
            
            # DataFrameì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            documents = cls.prepare_documents_from_dataframe(df)
            
            # ë²Œí¬ ì¸ë±ì‹± ì‹¤í–‰
            result = cls.bulk_index_documents(
                os_client, documents, index_name, None, id_field, batch_size, False
            )
            
            return result
            
        except Exception as e:
            print(f'âŒ CSV ë²Œí¬ ì¸ë±ì‹± ì‹¤íŒ¨ {csv_path}: {e}')
            return {
                "success": False,
                "error": str(e),
                "indexed_count": 0
            }

    @classmethod
    def prepare_documents_from_dataframe(cls, df: pd.DataFrame) -> List[Dict]:
        '''
        DataFrameì„ OpenSearch ë¬¸ì„œ í˜•íƒœë¡œ ë³€í™˜
        '''
        documents = df.to_dict('records')
        
        # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜
        for doc in documents:
            for key, value in doc.items():
                if pd.isna(value):
                    doc[key] = None
        
        return documents

    @classmethod
    def bulk_update_documents(cls, os_client, updates: List[Dict], index_name: str, 
                            batch_size: int = 500) -> Dict:
        '''
        ë¬¸ì„œë“¤ì„ ë²Œí¬ë¡œ ì—…ë°ì´íŠ¸
        
        Args:
            updates: [{"_id": "doc_id", "doc": {"field": "new_value"}}] í˜•íƒœ
        '''
        def update_generator():
            for update in updates:
                yield {
                    "_op_type": "update",
                    "_index": index_name,
                    "_id": update["_id"],
                    "doc": update["doc"]
                }
        
        try:
            success_count, errors = bulk(
                os_client,
                update_generator(),
                chunk_size=batch_size,
                request_timeout=60
            )
            
            result = {
                "success": True,
                "updated_count": success_count,
                "errors": errors,
                "total_updates": len(updates)
            }
            
            print(f'âœ… ë²Œí¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {index_name} ({success_count}/{len(updates)}ê°œ ë¬¸ì„œ)')
            return result
            
        except Exception as e:
            print(f'âŒ ë²Œí¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ {index_name}: {e}')
            return {"success": False, "error": str(e)}

    @classmethod
    def bulk_delete_documents(cls, os_client, doc_ids: List[str], index_name: str, 
                            batch_size: int = 500) -> Dict:
        '''
        ë¬¸ì„œë“¤ì„ ë²Œí¬ë¡œ ì‚­ì œ
        '''
        def delete_generator():
            for doc_id in doc_ids:
                yield {
                    "_op_type": "delete",
                    "_index": index_name,
                    "_id": doc_id
                }
        
        try:
            success_count, errors = bulk(
                os_client,
                delete_generator(),
                chunk_size=batch_size,
                request_timeout=60
            )
            
            result = {
                "success": True,
                "deleted_count": success_count,
                "errors": errors,
                "total_deletes": len(doc_ids)
            }
            
            print(f'âœ… ë²Œí¬ ì‚­ì œ ì™„ë£Œ: {index_name} ({success_count}/{len(doc_ids)}ê°œ ë¬¸ì„œ)')
            return result
            
        except Exception as e:
            print(f'âŒ ë²Œí¬ ì‚­ì œ ì‹¤íŒ¨ {index_name}: {e}')
            return {"success": False, "error": str(e)}

    @classmethod
    def search_document(cls, os_client, query, index_name):
        response = os_client.search(
            body=query,
            index=index_name
        )
        #print('\nKeyword Search results:')
        return response

    @classmethod
    def delete_index(cls, os_client, index_name):
        response = os_client.indices.delete(
            index=index_name  # í‚¤ì›Œë“œ ì¸ìë¡œ ë³€ê²½
        )

        print('\nDeleting index:')
        print(response)

    @classmethod
    def get_index_stats(cls, os_client, index_name: str) -> Dict:
        '''
        ì¸ë±ìŠ¤ í†µê³„ ì •ë³´ ì¡°íšŒ
        '''
        try:
            # ë¬¸ì„œ ìˆ˜ ì¡°íšŒ
            count_response = os_client.count(index=index_name)
            doc_count = count_response['count']
            
            # ì¸ë±ìŠ¤ ì‚¬ì´ì¦ˆ ì¡°íšŒ
            stats_response = os_client.indices.stats(index=index_name)
            index_size = stats_response['indices'][index_name]['total']['store']['size_in_bytes']
            
            # ë§¤í•‘ ì •ë³´ ì¡°íšŒ
            mapping_response = os_client.indices.get_mapping(index=index_name)
            
            return {
                "document_count": doc_count,
                "size_bytes": index_size,
                "size_mb": round(index_size / 1024 / 1024, 2),
                "mappings": mapping_response[index_name]['mappings']
            }
            
        except Exception as e:
            print(f'âŒ ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ {index_name}: {e}')
            return {}

    @classmethod
    def parse_keyword_response(cls, response, show_size=3):
        '''
        í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ì—¬ ì¤Œ.
        '''
        length = len(response['hits']['hits'])
        if length >= 1:
            print("# of searched docs: ", length)
            print(f"# of display: {show_size}")        
            print("---------------------")        
            for idx, doc in enumerate(response['hits']['hits']):
                print("_id in index: " , doc['_id'])
                print(doc['_score'])
                print(doc['_source']['text'])
                print(doc['_source']['metadata'])
                print("---------------------")
                if idx == show_size-1:
                    break
        else:
            print("There is no response")

    @classmethod
    def opensearch_pretty_print_documents(cls, response):
        '''
        OpenSearch ê²°ê³¼ì¸ LIST ë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
        '''
        for doc, score in response:
            print(f'\nScore: {score}')
            print(f'Document Number: {doc.metadata["row"]}')

            # Split the page content into lines
            lines = doc.page_content.split("\n")

            # Extract and print each piece of information if it exists
            for line in lines:
                split_line = line.split(": ")
                if len(split_line) > 1:
                    print(f'{split_line[0]}: {split_line[1]}')

            print("Metadata:")
            print(f'Type: {doc.metadata["type"]}')
            print(f'Source: {doc.metadata["source"]}')        

            print('-' * 50)

    @classmethod
    def get_document(cls, os_client, doc_id, index_name):
        response = os_client.get(
            id= doc_id,
            index=index_name
        )

        return response

    @classmethod
    def get_count(cls, os_client, index_name):
        response = os_client.count(
            index=index_name
        )

        return response

    @classmethod
    def get_query(cls, **kwargs):

        # Reference:
        # OpenSearcj boolean query:
        #  - https://opensearch.org/docs/latest/query-dsl/compound/bool/
        # OpenSearch match qeury:
        #  - https://opensearch.org/docs/latest/query-dsl/full-text/index/#match-boolean-prefix
        # OpenSearch Query Description (í•œê¸€)
        #  - https://esbook.kimjmin.net/05-search)

        search_type = kwargs.get("search_type", "lexical")

        if search_type == "lexical":

            min_shoud_match = 0
            if "minimum_should_match" in kwargs:
                min_shoud_match = kwargs["minimum_should_match"]

            QUERY_TEMPLATE = {
                "query": {
                    "bool": {
                        "must": [
                            {
                                "match": {
                                    "text": {
                                        "query": f'{kwargs["query"]}',
                                        "minimum_should_match": f'{min_shoud_match}%',
                                        "operator":  "or",
                                        # "fuzziness": "AUTO",
                                        # "fuzzy_transpositions": True,
                                        # "zero_terms_query": "none",
                                        # "lenient": False,
                                        # "prefix_length": 0,
                                        # "max_expansions": 50,
                                        # "boost": 1
                                    }
                                }
                            },
                        ],
                        "filter": [
                        ]
                    }
                }
            }

            if "filter" in kwargs:
                QUERY_TEMPLATE["query"]["bool"]["filter"].extend(kwargs["filter"])

        elif search_type == "semantic":

            QUERY_TEMPLATE = {
            "query": {
                    "bool": {
                        "must": [
                            {
                                "knn": {
                                    kwargs["vector_field"]: {
                                        "vector": kwargs["vector"],
                                        "k": kwargs["k"],
                                    }
                                }
                            },
                        ],
                        "filter": [
                        ]
                    }
                }
            }

            if "filter" in kwargs:
                QUERY_TEMPLATE["query"]["bool"]["filter"].extend(kwargs["filter"])

        return QUERY_TEMPLATE

    @classmethod
    def get_filter(cls, **kwargs):

        BOOL_FILTER_TEMPLATE = {
            "bool": {
                "filter": [
                ]
            }
        }

        if "filter" in kwargs:
            BOOL_FILTER_TEMPLATE["bool"]["filter"].extend(kwargs["filter"])

        return BOOL_FILTER_TEMPLATE

    @staticmethod
    def get_documents_by_ids(os_client, ids, index_name):

        response = os_client.mget(
            body={"ids": ids},
            index=index_name
        )

        return response

    @staticmethod
    def opensearch_pretty_print_documents_with_score(response):
        '''
        OpenSearch ê²°ê³¼ì¸ LIST ë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
        '''
        responses = copy.deepcopy(response)
        for doc, score in responses:
            print(f'\nScore: {score}')
            # print(f'Document Number: {doc.metadata["row"]}')
            # Split the page content into lines
            lines = doc.page_content.split("\n")
            metadata = doc.metadata
            if "image_base64" in metadata: metadata["image_base64"] = ""
            if "orig_elements" in metadata: metadata["orig_elements"] = ""
            
            print(lines)
            print(metadata)


# ==================== í¸ì˜ í•¨ìˆ˜ë“¤ ====================

def create_simple_mapping(field_types: Dict[str, str]) -> Dict:
    """
    ê°„ë‹¨í•œ í•„ë“œ íƒ€ì… ë”•ì…”ë„ˆë¦¬ë¡œ ë§¤í•‘ ìƒì„±
    
    Args:
        field_types: {"field_name": "field_type"} í˜•íƒœ
    """
    properties = {}
    for field_name, field_type in field_types.items():
        properties[field_name] = {"type": field_type}
    
    return {
        "mappings": {
            "properties": properties
        }
    }

def quick_csv_to_opensearch(csv_path: str, index_name: str, field_types: Dict[str, str], 
                          host: str = "localhost", port: int = 9200, 
                          username: str = None, password: str = None) -> Dict:
    """
    CSV íŒŒì¼ì„ OpenSearchì— ë¹ ë¥´ê²Œ ì¸ë±ì‹±
    
    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        index_name: ì¸ë±ìŠ¤ëª…
        field_types: í•„ë“œ íƒ€ì… ë”•ì…”ë„ˆë¦¬
        host, port: OpenSearch ì„œë²„ ì •ë³´
        username, password: ì¸ì¦ ì •ë³´ (ì„ íƒì‚¬í•­)
    
    Returns:
        ì¸ë±ì‹± ê²°ê³¼
    """
    # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = opensearch_utils.create_local_opensearch_client(host, port, username, password)
    
    # ë§¤í•‘ ìƒì„±
    mapping = create_simple_mapping(field_types)
    
    # CSV ì¸ë±ì‹±
    result = opensearch_utils.bulk_index_from_csv(
        client, csv_path, index_name, mapping
    )
    
    # ê²°ê³¼ í™•ì¸
    if result['success']:
        stats = opensearch_utils.get_index_stats(client, index_name)
        print(f"ğŸ“Š ì¸ë±ìŠ¤ í†µê³„: {stats['document_count']}ê°œ ë¬¸ì„œ, {stats['size_mb']}MB")
    
    return result