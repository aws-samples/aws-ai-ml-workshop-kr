"""
SCM file utility functions for managing artifacts and previous results.
Provides standardized methods for reading and writing analysis results.
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Optional, Any


def ensure_artifacts_folder() -> str:
    """
    Ensure artifacts folder exists and return its path.
    
    Returns:
        str: Path to artifacts folder
    """
    artifacts_path = "./artifacts/"
    if not os.path.exists(artifacts_path):
        os.makedirs(artifacts_path)
    return artifacts_path


def save_analysis_result(
    content: str, 
    step_number: int, 
    agent_name: str, 
    filename_override: Optional[str] = None
) -> str:
    """
    Save analysis result to artifacts folder with standardized naming.
    
    Args:
        content: Content to save
        step_number: Step number in workflow (01, 02, etc.)
        agent_name: Name of the agent
        filename_override: Optional custom filename
        
    Returns:
        str: Path to saved file
    """
    artifacts_path = ensure_artifacts_folder()
    
    if filename_override:
        filename = filename_override
    else:
        filename = f"{step_number:02d}_{agent_name}_results.txt"
    
    filepath = os.path.join(artifacts_path, filename)
    
    # Add metadata header
    timestamp = datetime.now().isoformat()
    formatted_content = f"""=== {agent_name.upper()} ANALYSIS RESULTS ===
Generated: {timestamp}
Step: {step_number:02d}
Agent: {agent_name}

{content}
"""
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(formatted_content)
    
    return filepath


def read_previous_results(max_step: Optional[int] = None) -> Dict[str, str]:
    """
    Read all previous analysis results from artifacts folder.
    
    Args:
        max_step: Maximum step number to read (None for all)
        
    Returns:
        Dict[str, str]: Dictionary mapping filename to content
    """
    artifacts_path = ensure_artifacts_folder()
    results = {}
    
    # Standard filenames to look for
    standard_files = [
        "01_research_results.txt",
        "02_business_insights.txt", 
        "03_analysis_plan.txt",
        "04_impact_analysis.txt",
        "05_correlation_analysis.txt",
        "06_mitigation_plan.txt",
        "07_final_report.txt"
    ]
    
    for filename in standard_files:
        if max_step:
            step_num = int(filename[:2])
            if step_num > max_step:
                continue
                
        filepath = os.path.join(artifacts_path, filename)
        if os.path.exists(filepath):
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    results[filename] = f.read()
            except Exception as e:
                results[filename] = f"Error reading file: {str(e)}"
    
    return results


def generate_file_reading_code(
    files_to_read: List[str],
    print_separator: bool = True,
    include_error_handling: bool = True
) -> str:
    """
    Generate Python code for reading previous result files with print statements.
    
    Args:
        files_to_read: List of filenames to read
        print_separator: Whether to include separator lines
        include_error_handling: Whether to include try/catch blocks
        
    Returns:
        str: Python code for reading files
    """
    code_lines = [
        "# Read previous analysis results",
        "import os",
        "print('=== ì´ì „ ê²°ê³¼ íŒŒì¼ë“¤ í™•ì¸ ===')",
        ""
    ]
    
    for filename in files_to_read:
        file_label = {
            "01_research_results.txt": "ðŸ“‹ ì—°êµ¬ ê²°ê³¼",
            "02_business_insights.txt": "ðŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸", 
            "03_analysis_plan.txt": "ðŸ“Š ë¶„ì„ ê³„íš",
            "04_impact_analysis.txt": "ðŸ“ˆ ì˜í–¥ ë¶„ì„",
            "05_correlation_analysis.txt": "ðŸ”— ìƒê´€ê´€ê³„ ë¶„ì„",
            "06_mitigation_plan.txt": "ðŸ›¡ï¸ ëŒ€ì‘ ë°©ì•ˆ",
            "07_final_report.txt": "ðŸ“„ ìµœì¢… ë³´ê³ ì„œ"
        }.get(filename, f"ðŸ“ {filename}")
        
        if include_error_handling:
            code_lines.extend([
                "try:",
                f"    with open('./artifacts/{filename}', 'r', encoding='utf-8') as f:",
                f"        {filename.replace('.txt', '_data').replace('-', '_')} = f.read()",
                f"    print('{file_label}:')",
                f"    print({filename.replace('.txt', '_data').replace('-', '_')})",
                f"except FileNotFoundError:",
                f"    print('âš ï¸ {filename} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')"
            ])
        else:
            code_lines.extend([
                f"with open('./artifacts/{filename}', 'r', encoding='utf-8') as f:",
                f"    {filename.replace('.txt', '_data').replace('-', '_')} = f.read()",
                f"print('{file_label}:')",
                f"print({filename.replace('.txt', '_data').replace('-', '_')})"
            ])
        
        if print_separator:
            code_lines.append("print('\\n' + '='*50 + '\\n')")
        
        code_lines.append("")
    
    return "\n".join(code_lines)


def get_scm_workflow_files() -> List[str]:
    """
    Get the standard list of SCM workflow files in order.
    
    Returns:
        List[str]: Ordered list of workflow filenames
    """
    return [
        "01_research_results.txt",
        "02_business_insights.txt", 
        "03_analysis_plan.txt",
        "04_impact_analysis.txt",
        "05_correlation_analysis.txt",
        "06_mitigation_plan.txt",
        "07_final_report.txt"
    ]


def create_opensearch_mcp_code() -> str:
    """
    Generate standard OpenSearch MCP connection code.
    
    Returns:
        str: Python code for OpenSearch MCP setup
    """
    return """
# OpenSearch MCP ì—°ê²° ì„¤ì •
import os
import boto3
from strands import Agent
from strands.tools.mcp import MCPClient
from mcp import stdio_client, StdioServerParameters
from utils.ssm import parameter_store

print("=== OpenSearch MCP ì—°ê²° ì‹œìž‘ ===")

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
region = boto3.Session().region_name
pm = parameter_store(region)

os.environ["OPENSEARCH_URL"] = pm.get_params(key="opensearch_domain_endpoint", enc=False)
os.environ["OPENSEARCH_USERNAME"] = pm.get_params(key="opensearch_user_id", enc=False)
os.environ["OPENSEARCH_PASSWORD"] = pm.get_params(key="opensearch_user_password", enc=True)

# MCP í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
env_vars = os.environ.copy()
opensearch_mcp_client = MCPClient(
    lambda: stdio_client(StdioServerParameters(
        command="python",
        args=["-m", "mcp_server_opensearch"],
        env=env_vars
    ))
)

print("âœ… OpenSearch MCP í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì™„ë£Œ")
"""


def create_analysis_template(
    agent_name: str,
    step_number: int,
    previous_files: List[str],
    analysis_instructions: str,
    save_filename: str
) -> str:
    """
    Create a standardized analysis code template.
    
    Args:
        agent_name: Name of the agent
        step_number: Step number in workflow
        previous_files: List of previous files to read
        analysis_instructions: Specific analysis instructions
        save_filename: Filename to save results to
        
    Returns:
        str: Complete analysis code template
    """
    file_reading_code = generate_file_reading_code(previous_files)
    opensearch_code = create_opensearch_mcp_code()
    
    template = f"""
ë‹¹ì‹ ì€ {agent_name} ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ì´ì „ ë¶„ì„ ê²°ê³¼ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìž‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

ë¨¼ì € ì´ì „ ê²°ê³¼ë“¤ì„ ëª¨ë‘ í™•ì¸í•˜ì„¸ìš”:

```python
{file_reading_code}
```

{analysis_instructions}

{opensearch_code if 'mcp' in analysis_instructions.lower() or 'opensearch' in analysis_instructions.lower() else ''}

ë¶„ì„ ê²°ê³¼ë¥¼ ./artifacts/{save_filename}ë¡œ ì €ìž¥í•˜ì„¸ìš”:

```python
# ë¶„ì„ ê²°ê³¼ ì €ìž¥
from datetime import datetime

analysis_result = '''
=== {agent_name.upper()} ë¶„ì„ ê²°ê³¼ ===
ìƒì„± ì‹œê°„: {{datetime.now().isoformat()}}
ë‹¨ê³„: {step_number:02d}

[ì—¬ê¸°ì— ë¶„ì„ ê²°ê³¼ ìž‘ì„±]
'''

with open('./artifacts/{save_filename}', 'w', encoding='utf-8') as f:
    f.write(analysis_result)

print(f"âœ… ë¶„ì„ ê²°ê³¼ê°€ ./artifacts/{save_filename}ì— ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```
"""
    
    return template


def cleanup_artifacts_folder() -> None:
    """Remove all files from artifacts folder."""
    artifacts_path = ensure_artifacts_folder()
    
    for filename in os.listdir(artifacts_path):
        filepath = os.path.join(artifacts_path, filename)
        if os.path.isfile(filepath):
            os.remove(filepath)


def get_artifacts_summary() -> Dict[str, Any]:
    """
    Get summary of all artifacts in the folder.
    
    Returns:
        Dict containing file info and statistics
    """
    artifacts_path = ensure_artifacts_folder()
    
    summary = {
        "folder_path": artifacts_path,
        "files": [],
        "total_files": 0,
        "total_size_bytes": 0,
        "last_modified": None
    }
    
    if not os.path.exists(artifacts_path):
        return summary
    
    latest_time = 0
    
    for filename in os.listdir(artifacts_path):
        filepath = os.path.join(artifacts_path, filename)
        if os.path.isfile(filepath):
            stat = os.stat(filepath)
            file_info = {
                "filename": filename,
                "size_bytes": stat.st_size,
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "step_number": None
            }
            
            # Extract step number if follows naming convention
            if filename[:2].isdigit():
                file_info["step_number"] = int(filename[:2])
            
            summary["files"].append(file_info)
            summary["total_size_bytes"] += stat.st_size
            
            if stat.st_mtime > latest_time:
                latest_time = stat.st_mtime
                summary["last_modified"] = file_info["modified"]
    
    summary["total_files"] = len(summary["files"])
    summary["files"].sort(key=lambda x: x.get("step_number", 999))
    
    return summary