{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff04f9fe",
   "metadata": {},
   "source": [
    "# Strands Agent SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c9e85",
   "metadata": {},
   "source": [
    "## 0. Jupyter í™˜ê²½ ì„¤ì •\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ê°œë°œ íš¨ìœ¨ì„±ì„ ìœ„í•œ ìë™ ë¦¬ë¡œë“œ ê¸°ëŠ¥ì„ í™œì„±í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë§¤ì§ ëª…ë ¹ì–´ | ê¸°ëŠ¥ | íš¨ê³¼ |\n",
    "|------------|------|------|\n",
    "| `%load_ext autoreload` | autoreload í™•ì¥ ë¡œë“œ | ìë™ ë¦¬ë¡œë“œ ê¸°ëŠ¥ í™œì„±í™” |\n",
    "| `%autoreload 2` | ì „ì²´ ëª¨ë“ˆ ìë™ ë¦¬ë¡œë“œ | ëª¨ë“  ëª¨ë“ˆ ë³€ê²½ì‚¬í•­ ì‹¤ì‹œê°„ ë°˜ì˜ |\n",
    "\n",
    "ğŸ’¡ **Tip**: ì´ ì„¤ì •ìœ¼ë¡œ ì½”ë“œë¥¼ ìˆ˜ì •í•  ë•Œë§ˆë‹¤ ì»¤ë„ì„ ì¬ì‹œì‘í•˜ì§€ ì•Šì•„ë„ ë³€ê²½ì‚¬í•­ì´ ë°”ë¡œ ì ìš©ë©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3078d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f391050",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ë³€ìˆ˜ ë° lib path ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578donamdqw",
   "metadata": {},
   "source": [
    "### 1.1 í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: í”„ë¡œì íŠ¸ í™˜ê²½ ì„¤ì •ì„ ìœ„í•œ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ì—­í•  | ì‚¬ìš© ëª©ì  |\n",
    "|-----------|------|-----------|\n",
    "| `os` | ìš´ì˜ì²´ì œ ì¸í„°í˜ì´ìŠ¤ | í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼, ì‹œìŠ¤í…œ ì •ë³´ |\n",
    "| `sys` | Python ì¸í„°í”„ë¦¬í„° ì œì–´ | ëª¨ë“ˆ ê²½ë¡œ ì„¤ì • |\n",
    "| `dotenv` | í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ | `.env` íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ |\n",
    "\n",
    "ğŸ’¡ **Tip**: `.env` íŒŒì¼ì„ ì‚¬ìš©í•˜ë©´ AWS ì¸ì¦ ì •ë³´ ë“± ë¯¼ê°í•œ ì„¤ì •ì„ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e9265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1uuwkxq24fx",
   "metadata": {},
   "source": [
    "### 1.2 í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: AWS ì—°ê²°ê³¼ í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì ‘ê·¼ì„ ìœ„í•œ í™˜ê²½ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë‹¨ê³„ | ì‘ì—… | ì„¤ëª… |\n",
    "|------|------|------|\n",
    "| 1ï¸âƒ£ | `.env` íŒŒì¼ ë¡œë“œ | í™˜ê²½ë³€ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ë¶ˆëŸ¬ì˜´ |\n",
    "| 2ï¸âƒ£ | AWS ë¦¬ì „ í™•ì¸ | Bedrock ì„œë¹„ìŠ¤ ì—°ê²° ì§€ì—­ ê²€ì¦ |\n",
    "| 3ï¸âƒ£ | ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€ | ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ `src` ëª¨ë“ˆ ì ‘ê·¼ í—ˆìš© |\n",
    "\n",
    "ğŸ’¡ **Tip**: `AWS_DEFAULT_REGION`ì´ ì¶œë ¥ë˜ë©´ í™˜ê²½ ì„¤ì •ì´ ì˜¬ë°”ë¥´ê²Œ ì™„ë£Œëœ ê²ƒì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb67822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS_DEFAULT_REGION: None\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "print (f'AWS_DEFAULT_REGION: {os.getenv(\"AWS_DEFAULT_REGION\")}')\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39305e",
   "metadata": {},
   "source": [
    "## 2. Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b0d8a",
   "metadata": {},
   "source": [
    "### 2.1 Get llm model\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: Strands SDKì—ì„œ ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ì • | ì„¤ëª… |\n",
    "|----------|------|------|\n",
    "| **function name** | `get_model` | LLM ëª¨ë¸ ìƒì„± ë©”ì„œë“œ |\n",
    "| **script path** | [`../src/utils/strands_sdk_utils.py`](../src/utils/strands_sdk_utils.py#L56-L108) | êµ¬í˜„ íŒŒì¼ ìœ„ì¹˜ |\n",
    "\n",
    "**í•µì‹¬ ê¸°ëŠ¥**: ì¶”ë¡  ëª¨ë“œ, ìºì‹±, ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2b767",
   "metadata": {},
   "source": [
    "### 2.2 Get system prompt\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ì—ì´ì „íŠ¸ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ì • | ì„¤ëª… |\n",
    "|----------|------|------|\n",
    "| **function name** | `apply_prompt_template` | í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš© ë©”ì„œë“œ |\n",
    "| **script path** | [`../src/prompts/template.py`](../src/prompts/template.py#L4-L12) | êµ¬í˜„ íŒŒì¼ ìœ„ì¹˜ |\n",
    "\n",
    "**í•µì‹¬ ê¸°ëŠ¥**: ë™ì  ë³€ìˆ˜ ì‚½ì…, ì—ì´ì „íŠ¸ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357e8a0",
   "metadata": {},
   "source": [
    "### 2.3 Create agent\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ì„¤ì •ëœ LLMê³¼ í”„ë¡¬í”„íŠ¸ë¡œ Strands ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ì • | ì„¤ëª… |\n",
    "|----------|------|------|\n",
    "| **function name** | `get_agent` | Strands ì—ì´ì „íŠ¸ ìƒì„± ë©”ì„œë“œ |\n",
    "| **script path** | [`../src/utils/strands_sdk_utils.py`](../src/utils/strands_sdk_utils.py#L109-L134) | êµ¬í˜„ íŒŒì¼ ìœ„ì¹˜ |\n",
    "\n",
    "**í•µì‹¬ ê¸°ëŠ¥**: ëª¨ë¸-í”„ë¡¬í”„íŠ¸-ë„êµ¬ í†µí•©, ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fdda10",
   "metadata": {},
   "source": [
    "## 3. Agent definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51kfw4r85",
   "metadata": {},
   "source": [
    "### 3.1 ì—ì´ì „íŠ¸ ì´ë¦„ ì •ì˜\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: íŠœí† ë¦¬ì–¼ ì—ì´ì „íŠ¸ì˜ ê³ ìœ  ì‹ë³„ìë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ì†ì„± | ê°’ | ìš©ë„ |\n",
    "|------|-----|------|\n",
    "| **ì—ì´ì „íŠ¸ëª…** | `toy_agent` | ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… ì°¸ì¡° |\n",
    "\n",
    "ğŸ’¡ **Tip**: ì—ì´ì „íŠ¸ ì´ë¦„ì€ í”„ë¡œì íŠ¸ ì „ë°˜ì—ì„œ ì¼ê´€ë˜ê²Œ ì‚¬ìš©ë˜ëŠ” ì¤‘ìš”í•œ ì‹ë³„ìì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c8f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"toy_agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6559e7",
   "metadata": {},
   "source": [
    "### 3.2 ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (System prompt) íŒŒì¼ ìƒì„±\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: `%%writefile` ë§¤ì§ ëª…ë ¹ì–´ë¡œ ì—ì´ì „íŠ¸ì˜ í•µì‹¬ ì§€ì¹¨ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ | ë‚´ìš© | ëª©ì  |\n",
    "|----------|------|------|\n",
    "| **ğŸ¤– ì—ì´ì „íŠ¸ ì •ì²´ì„±** | Bedrock-Manus ì—­í•  ì •ì˜ | ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì„±ê²© ì„¤ì • |\n",
    "| **ğŸ› ï¸ ë„êµ¬ ì„¤ëª…** | Python REPL, Bash ë„êµ¬ | ê° ë„êµ¬ì˜ ì‚¬ìš© ì‹œì ê³¼ ë°©ë²• ì•ˆë‚´ |\n",
    "| **ğŸ“‹ ì‚¬ìš© ê°€ì´ë“œë¼ì¸** | ë„êµ¬ ì„ íƒ ê¸°ì¤€ | ìƒí™©ë³„ ì ì ˆí•œ ë„êµ¬ ì„ íƒ ë¡œì§ |\n",
    "| **ğŸ’¬ ì‘ë‹µ ìŠ¤íƒ€ì¼** | ëŒ€í™” ë°©ì‹ ì •ì˜ | ì‚¬ìš©ì ì¹œí™”ì  ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê·œì¹™ |\n",
    "\n",
    "ğŸ’¡ **Tip**: `%%writefile`ë¡œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ì—ì´ì „íŠ¸ì˜ \"ë‘ë‡Œ\" ì—­í• ì„ í•˜ëŠ” ì¤‘ìš”í•œ ì„¤ì • íŒŒì¼ì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5254717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/prompts/toy_agent.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/prompts/toy_agent.md\n",
    "\n",
    "---\n",
    "CURRENT_TIME: {CURRENT_TIME}\n",
    "AGENT_NAME: {AGENT_NAME}\n",
    "---\n",
    "\n",
    "You are Amazon Bedrock Deep Research Agent, a friendly AI assistant developed by AWS Korea SA Team.\n",
    "You specialize in handling greetings, small talk, and knowledge-based question answering using available tools.\n",
    "\n",
    "## Available Tools\n",
    "\n",
    "You have access to the following tools that you should use when appropriate:\n",
    "\n",
    "### 1. Python REPL Tool (python_repl_tool)\n",
    "**When to use**: Use this tool when users need to execute Python code or perform data analysis:\n",
    "- Running Python scripts or code snippets\n",
    "- Data analysis and calculations\n",
    "- Testing code functionality\n",
    "- Mathematical computations\n",
    "\n",
    "**What it does**: Executes Python code in a REPL environment and returns the output\n",
    "\n",
    "**Input**: Python code string\n",
    "\n",
    "### 2. Bash Tool (bash_tool) \n",
    "**When to use**: Use this tool when users need to execute system commands or perform file operations:\n",
    "- Running shell commands\n",
    "- File system operations (ls, mkdir, etc.)\n",
    "- System information queries\n",
    "- Development tasks requiring command line operations\n",
    "\n",
    "**What it does**: Executes bash commands and returns the output\n",
    "\n",
    "**Input**: A bash command string\n",
    "\n",
    "## Tool Usage Guidelines\n",
    "\n",
    "1. **Assess the user's request** - Determine if the question requires tool usage\n",
    "2. **Choose the appropriate tool** - Select based on the type of information needed\n",
    "3. **Use RAG tool for knowledge queries** - When the user asks about topics that might be in your knowledge base\n",
    "4. **Use Python REPL for code execution** - When the user needs to run Python code or perform calculations\n",
    "5. **Use Bash tool for system operations** - When the user needs to interact with the system\n",
    "6. **Provide helpful responses** - Always explain the results in a user-friendly way\n",
    "\n",
    "## Response Style\n",
    "\n",
    "- Be friendly and conversational\n",
    "- Provide clear, helpful answers\n",
    "- When using tools, explain what you're doing and why\n",
    "- If a tool doesn't provide the needed information, acknowledge this and offer alternatives\n",
    "- Always prioritize user experience and clarity\n",
    "\n",
    "Remember to use tools proactively when they can help answer user questions more accurately or completely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685778ab",
   "metadata": {},
   "source": [
    "### 3.3 ì—ì´ì „íŠ¸ ìƒì„±\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: Strands SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ì •ì´ ì™„ë£Œëœ ì‹¤ì œ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ì •ê°’ | ì„¤ëª… |\n",
    "|----------|--------|------|\n",
    "| **ğŸ¤– agent_type** | `claude-sonnet-3-7` | ì‚¬ìš©í•  LLM ëª¨ë¸ (ê³ ì„±ëŠ¥ ì¶”ë¡ ) |\n",
    "| **ğŸ§  enable_reasoning** | `False` | ì¶”ë¡  ê¸°ëŠ¥ ë¹„í™œì„±í™” (ë¹ ë¥¸ ì‘ë‹µ) |\n",
    "| **âš¡ prompt_cache_info** | `(False, None)` | í”„ë¡¬í”„íŠ¸ ìºì‹± ë¹„í™œì„±í™” |\n",
    "| **ğŸ“¡ streaming** | `True` | ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™” |\n",
    "\n",
    "ğŸ’¡ **Tip**: ì´ ì„¤ì •ìœ¼ë¡œ ê¸°ë³¸ì ì¸ ëŒ€í™”í˜• ì—ì´ì „íŠ¸ê°€ ìƒì„±ë©ë‹ˆë‹¤. ë„êµ¬ëŠ” ì•„ì§ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d78690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.strands_sdk_utils import strands_utils\n",
    "from src.prompts.template import apply_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8631bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = strands_utils.get_agent(\n",
    "    agent_name=agent_name,\n",
    "    system_prompts=apply_prompt_template(prompt_name=agent_name, prompt_context={\"AGENT_NAME\": agent_name}),\n",
    "    agent_type=\"claude-sonnet-3-7\", # claude-sonnet-3-5-v-2, claude-sonnet-3-7\n",
    "    enable_reasoning=False,\n",
    "    prompt_cache_info=(False, None), #(False, None), (True, \"default\")\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "#system_prompts=apply_prompt_template(prompt_name=agent_name, prompt_context={\"AGENT_NAME\": agent_name})\n",
    "#print (f'System prompt: \\n{system_prompts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65382b9",
   "metadata": {},
   "source": [
    "## 4. Invocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efda5d8",
   "metadata": {},
   "source": [
    "### 4.1 ê¸°ë³¸ ì—ì´ì „íŠ¸ í˜¸ì¶œ (without streaming)\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ìƒì„±ëœ ì—ì´ì „íŠ¸ì™€ì˜ ì²« ë²ˆì§¸ ëŒ€í™”ë¥¼ í…ŒìŠ¤íŠ¸í•˜ë©° ì‘ë‹µ ìˆ˜ì§‘ ë°©ì‹ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "| ì²˜ë¦¬ ë‹¨ê³„ | ë°©ë²• | ì„¤ëª… |\n",
    "|----------|------|------|\n",
    "| **ğŸ“¨ ë©”ì‹œì§€ ì „ì†¡** | `process_streaming_response_yield()` | ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ |\n",
    "| **ğŸ”„ ì‘ë‹µ ìˆ˜ì§‘** | `event.get(\"text_chunk\")` | ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ ìˆ˜ì§‘ |\n",
    "| **ğŸ“‹ ê²°ê³¼ ì¶œë ¥** | `full_text` ë³€ìˆ˜ | ì™„ì„±ëœ ì „ì²´ ì‘ë‹µë§Œ ìµœì¢… ì¶œë ¥ |\n",
    "\n",
    "ğŸ”— **ì°¸ì¡°**: [`process_streaming_response_yield`](../src/utils/strands_sdk_utils.py#L187-L239)\n",
    "\n",
    "#### ğŸ“¤ ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜ ê²°ê³¼ ì˜ˆì‹œ\n",
    "**\"ì•ˆë…•í•˜ì„¸ìš”\" ì‘ë‹µì˜ ìŠ¤íŠ¸ë¦¬ë° ê³¼ì •**\n",
    "\n",
    "```python\n",
    "# ìŠ¤íŠ¸ë¦¼ 1:\n",
    "{\"data\": \"ì•ˆë…•\"} â†’ {\n",
    "    \"timestamp\": \"2024-01-15T10:30:00.123456\",\n",
    "    \"session_id\": \"session-1\", \n",
    "    \"agent_name\": \"toy_agent\",\n",
    "    \"type\": \"agent_text_stream\",\n",
    "    \"event_type\": \"text_chunk\", \n",
    "    \"data\": \"ì•ˆë…•\"\n",
    "}\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¼ 2:\n",
    "{\"data\": \"í•˜ì„¸ìš”\"} â†’ {\n",
    "    \"timestamp\": \"2024-01-15T10:30:00.145678\",\n",
    "    \"session_id\": \"session-1\",\n",
    "    \"agent_name\": \"toy_agent\", \n",
    "    \"type\": \"agent_text_stream\",\n",
    "    \"event_type\": \"text_chunk\",\n",
    "    \"data\": \"í•˜ì„¸ìš”\"\n",
    "}\n",
    "```\n",
    "\n",
    "**í•µì‹¬**: ê° í† í°ì´ ê°œë³„ ì´ë²¤íŠ¸ë¡œ ë³€í™˜ë˜ì–´ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì´ ê°€ëŠ¥í•˜ë©°, íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ìˆœì„œë¥¼ ë³´ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83889c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97mì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. Strands Agents SDKë¥¼ ê³µë¶€í•˜ê³  ê³„ì‹œëŠ”êµ°ìš”, ì •ë§ í¥ë¯¸ë¡œìš´ ì£¼ì œì…ë‹ˆë‹¤!\n",
      "\n",
      "Strands Agents SDKëŠ” Amazon Bedrockì—ì„œ ì œê³µí•˜ëŠ” ì—ì´ì „íŠ¸ ê°œë°œ ë„êµ¬ë¡œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë„êµ¬ì™€ ì—°ê²°í•˜ê³  ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "ê³µë¶€í•˜ì‹œëŠ” ë° ë„ì›€ì´ í•„ìš”í•˜ì‹  ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”? ì˜ˆë¥¼ ë“¤ì–´, Strands Agents SDKì˜ íŠ¹ì • ê¸°ëŠ¥ì´ë‚˜ êµ¬í˜„ ë°©ë²•, ë˜ëŠ” Pythonìœ¼ë¡œ ì—ì´ì „íŠ¸ë¥¼ ê°œë°œí•˜ëŠ” ë°©ë²• ë“±ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\u001b[0mNone\n"
     ]
    }
   ],
   "source": [
    "user_input = \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ë‚˜ëŠ” ì§€ê¸ˆ Strands Agents SDK ê³µë¶€ì¤‘ì´ì•¼.\"\n",
    "\n",
    "full_text = \"\"\n",
    "async for event in strands_utils.process_streaming_response_yield(\n",
    "    agent=agent,\n",
    "    message=user_input,\n",
    "    agent_name=agent_name,\n",
    "    source=agent_name\n",
    "):\n",
    "    strands_utils.process_event_for_display(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe823d6",
   "metadata": {},
   "source": [
    "### 4.2 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì´ ìƒì„±ë˜ëŠ” ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ë©° ìŠ¤íŠ¸ë¦¬ë°ì˜ ì¥ì ì„ ì²´í—˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ì²˜ë¦¬ ë°©ì‹ | í•¨ìˆ˜ | íš¨ê³¼ |\n",
    "|----------|------|------|\n",
    "| **ğŸ¬ ì‹¤ì‹œê°„ ì¶œë ¥** | `process_event_for_display()` | í…ìŠ¤íŠ¸ê°€ íƒ€ì´í•‘ë˜ëŠ” ê²ƒì²˜ëŸ¼ ì‹¤ì‹œê°„ í‘œì‹œ |\n",
    "| **ğŸ“Š ì´ë²¤íŠ¸ ë¶„ì„** | ì´ë²¤íŠ¸ íƒ€ì…ë³„ ì²˜ë¦¬ | í…ìŠ¤íŠ¸, ë„êµ¬ ì‚¬ìš© ë“± ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ êµ¬ë¶„ |\n",
    "| **ğŸ’¾ ì‘ë‹µ ìˆ˜ì§‘** | `full_text` ëˆ„ì  | ìµœì¢… ì™„ì„±ëœ ì‘ë‹µë„ ë³„ë„ ì €ì¥ |\n",
    "\n",
    "ğŸ”— **ì°¸ì¡°**: [`process_event_for_display`](../src/utils/strands_sdk_utils.py#L333-L379)\n",
    "\n",
    "ğŸ’¡ **Tip**: í…ìŠ¤íŠ¸ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” íš¨ê³¼ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4637d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.config[\"streaming\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdba4019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97mStrands\u001b[0m\u001b[97m Agents SDKì˜ ì£¼ìš” ì¥ì ì€ ë‹¤ìŒ\u001b[0m\u001b[97mê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ê°„\u001b[0m\u001b[97mí¸í•œ ì—ì´ì „íŠ¸ ê°œë°œ**: \u001b[0m\u001b[97më³µì¡í•œ AI ì—ì´ì „íŠ¸ë¥¼\u001b[0m\u001b[97m ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆ\u001b[0m\u001b[97mëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜\u001b[0m\u001b[97mì—¬ ê°œë°œ ì‹œê°„ì„ ë‹¨ì¶•í•©\u001b[0m\u001b[97më‹ˆë‹¤.\n",
      "\n",
      "2. **ë„êµ¬ í†µ\u001b[0m\u001b[97mí•© ìš©ì´ì„±**: ë‹¤ì–‘\u001b[0m\u001b[97mí•œ ì™¸ë¶€ ë„êµ¬, API, ë°\u001b[0m\u001b[97mì´í„° ì†ŒìŠ¤ë¥¼ ì‰½ê²Œ \u001b[0m\u001b[97mì—°ê²°í•˜ê³  í™œìš©í•  ìˆ˜\u001b[0m\u001b[97m ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ìœ \u001b[0m\u001b[97mì—°í•œ ì•„í‚¤í…ì²˜**: ë‹¤ì–‘\u001b[0m\u001b[97mí•œ ì‚¬ìš© ì‚¬ë¡€ì™€\u001b[0m\u001b[97m ìš”êµ¬ì‚¬í•­ì— \u001b[0m\u001b[97më§ê²Œ ì—ì´ì „íŠ¸ë¥¼\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in streaming response (attempt 1/5): An error occurred (throttlingException) when calling the ConverseStream operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/src/utils/strands_sdk_utils.py\", line 210, in _retry_agent_streaming\n",
      "    async for event in agent_stream:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/agent/agent.py\", line 581, in stream_async\n",
      "    async for event in events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/agent/agent.py\", line 619, in _run_loop\n",
      "    async for event in events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/agent/agent.py\", line 658, in _execute_event_loop_cycle\n",
      "    async for event in events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/event_loop.py\", line 110, in event_loop_cycle\n",
      "    async for model_event in model_events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/event_loop.py\", line 316, in _handle_model_execution\n",
      "    raise e\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/event_loop.py\", line 264, in _handle_model_execution\n",
      "    async for event in stream_messages(agent.model, agent.system_prompt, agent.messages, tool_specs):\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/streaming.py\", line 351, in stream_messages\n",
      "    async for event in process_stream(chunks):\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/streaming.py\", line 308, in process_stream\n",
      "    async for chunk in chunks:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/models/bedrock.py\", line 625, in stream\n",
      "    await task\n",
      "  File \"/home/ubuntu/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/opentelemetry/instrumentation/threading/__init__.py\", line 171, in wrapped_func\n",
      "    return original_func(*func_args, **func_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/models/bedrock.py\", line 743, in _stream\n",
      "    raise e\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/models/bedrock.py\", line 664, in _stream\n",
      "    for chunk in response[\"stream\"]:\n",
      "                 ~~~~~~~~^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/botocore/eventstream.py\", line 592, in __iter__\n",
      "    parsed_event = self._parse_event(event)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/botocore/eventstream.py\", line 608, in _parse_event\n",
      "    raise EventStreamError(parsed_response, self._operation_name)\n",
      "botocore.exceptions.EventStreamError: An error occurred (throttlingException) when calling the ConverseStream operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "â”” Bedrock region: us-west-2\n",
      "â”” Model id: us.anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[97mStrands\u001b[0m\u001b[97m Agents SDKì˜ ì£¼ìš” ì¥ì \u001b[0m\u001b[97mì€ ë‹¤ìŒê³¼ ê°™ìŠµ\u001b[0m\u001b[97më‹ˆë‹¤:\n",
      "\n",
      "1. **\u001b[0m\u001b[97mê°„í¸í•œ ì—ì´ì „íŠ¸ \u001b[0m\u001b[97mê°œë°œ**: ë³µì¡í•œ \u001b[0m\u001b[97mAI ì—ì´ì „íŠ¸ë¥¼\u001b[0m\u001b[97m ì‰½ê²Œ êµ¬\u001b[0m\u001b[97mì¶•í•  ìˆ˜ ìˆëŠ”\u001b[0m\u001b[97m í”„ë ˆì„ì›Œí¬ë¥¼\u001b[0m\u001b[97m ì œê³µí•˜ì—¬ ê°œë°œ \u001b[0m\u001b[97mì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.\u001b[0m\u001b[97m\n",
      "\n",
      "2. **Amazon Bedrockê³¼ì˜\u001b[0m\u001b[97m í†µí•©**: Amazon Bedrockì˜\u001b[0m\u001b[97m ë‹¤ì–‘í•œ ê¸°ë°˜ ëª¨ë¸(\u001b[0m\u001b[97mClaude, Llama 2 \u001b[0m\u001b[97më“±)ê³¼ ì›í™œí•˜ê²Œ í†µí•©\u001b[0m\u001b[97më˜ì–´ ê°•ë ¥í•œ AI\u001b[0m\u001b[97m ê¸°ëŠ¥ì„ í™œìš©í•  ìˆ˜\u001b[0m\u001b[97m ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ë„\u001b[0m\u001b[97mêµ¬ ì—°ê²° ìš©ì´ì„±**: ì™¸\u001b[0m\u001b[97më¶€ API, ë°ì´í„°\u001b[0m\u001b[97më² ì´ìŠ¤, ì„œë¹„ìŠ¤ ë“±\u001b[0m\u001b[97m ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì—\u001b[0m\u001b[97mì´ì „íŠ¸ì— ì‰½ê²Œ \u001b[0m\u001b[97mì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u001b[0m\u001b[97m\n",
      "\n",
      "4. **ë©€í‹°í„´ \u001b[0m\u001b[97mëŒ€í™” ì§€ì›**: ë³µì¡í•œ \u001b[0m\u001b[97mëŒ€í™” íë¦„ê³¼ \u001b[0m\u001b[97mì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¥¼ íš¨\u001b[0m\u001b[97mê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆ\u001b[0m\u001b[97më‹¤.\n",
      "\n",
      "5. **í™•\u001b[0m\u001b[97mì¥ì„±**: ê°„ë‹¨í•œ \u001b[0m\u001b[97mì±—ë´‡ë¶€í„° ë³µ\u001b[0m\u001b[97mì¡í•œ ì—…ë¬´ ìë™í™” \u001b[0m\u001b[97mì‹œìŠ¤í…œê¹Œì§€ ë‹¤ì–‘\u001b[0m\u001b[97mí•œ ê·œëª¨ì˜ ì• í”Œë¦¬ì¼€ì´\u001b[0m\u001b[97mì…˜ì„ êµ¬ì¶•í•  ìˆ˜\u001b[0m\u001b[97m ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ìœ \u001b[0m\u001b[97mì—°í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ì—\u001b[0m\u001b[97mì´ì „íŠ¸ì˜ í–‰ë™, ì‘\u001b[0m\u001b[97më‹µ ë°©ì‹, ë„êµ¬ ì‚¬ìš©\u001b[0m\u001b[97m ë°©ë²• ë“±ì„ ì„¸\u001b[0m\u001b[97më°€í•˜ê²Œ \u001b[0m\u001b[97mì œì–´í•  ìˆ˜\u001b[0m\u001b[97m ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "7\u001b[0m\u001b[97m. **ë³´ì•ˆ ë°\u001b[0m\u001b[97m ê·œì • ì¤€ìˆ˜**:\u001b[0m\u001b[97m AWSì˜ ë³´ì•ˆ \u001b[0m\u001b[97mì¸í”„ë¼ë¥¼ í™œìš©í•˜\u001b[0m\u001b[97mì—¬ ë°ì´í„° ë³´\u001b[0m\u001b[97mí˜¸ ë° ê·œì •\u001b[0m\u001b[97m ì¤€ìˆ˜ ìš”\u001b[0m\u001b[97mêµ¬ì‚¬í•­ì„ ì¶©ì¡±í•©\u001b[0m\u001b[97më‹ˆë‹¤.\u001b[0m\u001b[97m\n",
      "\n",
      "8. **ë¹„ìš© íš¨ìœ¨\u001b[0m\u001b[97mì„±**: ì‚¬ìš©í•œ\u001b[0m\u001b[97m ë§Œí¼ë§Œ\u001b[0m\u001b[97m ì§€ë¶ˆí•˜ëŠ” AWS\u001b[0m\u001b[97mì˜ ê°€ê²© ì •\u001b[0m\u001b[97mì±…ì„ ë”°ë¦…ë‹ˆë‹¤.\u001b[0m\u001b[97m\n",
      "\n",
      "Strands Agents SDKë¥¼\u001b[0m\u001b[97m í™œìš©í•˜ë©´ \u001b[0m\u001b[97mê°œë°œìëŠ” ë³µ\u001b[0m\u001b[97mì¡í•œ LLM í”„\u001b[0m\u001b[97më¡¬í”„íŠ¸ ì—”ì§€\u001b[0m\u001b[97më‹ˆì–´ë§ì— ì‹œê°„ì„ \u001b[0m\u001b[97mìŸê¸°ë³´ë‹¤ ë¹„\u001b[0m\u001b[97mì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼\u001b[0m\u001b[97m ì‚¬ìš©ì ê²½\u001b[0m\u001b[97mí—˜ì— ì§‘ì¤‘í• \u001b[0m\u001b[97m ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u001b[0m\u001b[97m íŠ¹ì • ê¸°ëŠ¥\u001b[0m\u001b[97mì´ë‚˜ êµ¬í˜„ ë°©ë²•\u001b[0m\u001b[97mì— ëŒ€í•´ ë”\u001b[0m\u001b[97m ì•Œê³  ì‹¶\u001b[0m\u001b[97mìœ¼ì‹  ë¶€ë¶„ì´ ìˆ\u001b[0m\u001b[97mìœ¼ì‹ ê°€ìš”?\u001b[0mNone\n",
      "\n",
      "Response: Strands Agents SDKì˜ ì£¼ìš” ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ê°„í¸í•œ ì—ì´ì „íŠ¸ ê°œë°œ**: ë³µì¡í•œ AI ì—ì´ì „íŠ¸ë¥¼ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë„êµ¬ í†µí•© ìš©ì´ì„±**: ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬, API, ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì‰½ê²Œ ì—°ê²°í•˜ê³  í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ìœ ì—°í•œ ì•„í‚¤í…ì²˜**: ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì™€ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ì—ì´ì „íŠ¸ë¥¼Strands Agents SDKì˜ ì£¼ìš” ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ê°„í¸í•œ ì—ì´ì „íŠ¸ ê°œë°œ**: ë³µì¡í•œ AI ì—ì´ì „íŠ¸ë¥¼ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ì—¬ ê°œë°œ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **Amazon Bedrockê³¼ì˜ í†µí•©**: Amazon Bedrockì˜ ë‹¤ì–‘í•œ ê¸°ë°˜ ëª¨ë¸(Claude, Llama 2 ë“±)ê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ê°•ë ¥í•œ AI ê¸°ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ë„êµ¬ ì—°ê²° ìš©ì´ì„±**: ì™¸ë¶€ API, ë°ì´í„°ë² ì´ìŠ¤, ì„œë¹„ìŠ¤ ë“± ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì—ì´ì „íŠ¸ì— ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ë©€í‹°í„´ ëŒ€í™” ì§€ì›**: ë³µì¡í•œ ëŒ€í™” íë¦„ê³¼ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **í™•ì¥ì„±**: ê°„ë‹¨í•œ ì±—ë´‡ë¶€í„° ë³µì¡í•œ ì—…ë¬´ ìë™í™” ì‹œìŠ¤í…œê¹Œì§€ ë‹¤ì–‘í•œ ê·œëª¨ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ìœ ì—°í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ì—ì´ì „íŠ¸ì˜ í–‰ë™, ì‘ë‹µ ë°©ì‹, ë„êµ¬ ì‚¬ìš© ë°©ë²• ë“±ì„ ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "7. **ë³´ì•ˆ ë° ê·œì • ì¤€ìˆ˜**: AWSì˜ ë³´ì•ˆ ì¸í”„ë¼ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„° ë³´í˜¸ ë° ê·œì • ì¤€ìˆ˜ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•©ë‹ˆë‹¤.\n",
      "\n",
      "8. **ë¹„ìš© íš¨ìœ¨ì„±**: ì‚¬ìš©í•œ ë§Œí¼ë§Œ ì§€ë¶ˆí•˜ëŠ” AWSì˜ ê°€ê²© ì •ì±…ì„ ë”°ë¦…ë‹ˆë‹¤.\n",
      "\n",
      "Strands Agents SDKë¥¼ í™œìš©í•˜ë©´ ê°œë°œìëŠ” ë³µì¡í•œ LLM í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì— ì‹œê°„ì„ ìŸê¸°ë³´ë‹¤ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì‚¬ìš©ì ê²½í—˜ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹ì • ê¸°ëŠ¥ì´ë‚˜ êµ¬í˜„ ë°©ë²•ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹  ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "message = \"Strands Agents SDKì˜ ì¥ì ì€ ë­ì•¼?\"\n",
    "\n",
    "full_text = \"\"\n",
    "async for event in strands_utils.process_streaming_response_yield(\n",
    "    agent=agent,\n",
    "    message=message,\n",
    "    agent_name=agent_name,\n",
    "    source=agent_name\n",
    "):\n",
    "    strands_utils.process_event_for_display(event)\n",
    "\n",
    "    if event.get(\"event_type\") == \"text_chunk\":\n",
    "        full_text += event.get(\"data\", \"\")\n",
    "    \n",
    "response = {\"text\": full_text}\n",
    "\n",
    "print (f'\\nResponse: {response['text']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c30d4",
   "metadata": {},
   "source": [
    "## 5. Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747da1e3",
   "metadata": {},
   "source": [
    "### 5.1 ë„êµ¬(Tools) ì‚¬ìš©ì„ ìœ„í•œ import\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ì—ì´ì „íŠ¸ê°€ ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì‹¤í–‰ ë„êµ¬ë“¤ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë„êµ¬ | ê¸°ëŠ¥ | ì‚¬ìš© ì‚¬ë¡€ |\n",
    "|------|------|-----------|\n",
    "| **ğŸ python_repl_tool** | Python ì½”ë“œ ì‹¤í–‰ | ë°ì´í„° ë¶„ì„, ê³„ì‚°, ì‹œê°í™” |\n",
    "| **âš¡ bash_tool** | ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì‹¤í–‰ | íŒŒì¼ ì¡°ì‘, ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ |\n",
    "\n",
    "ğŸ’¡ **Tip**: ë„êµ¬ë¥¼ ì¶”ê°€í•˜ë©´ ì—ì´ì „íŠ¸ê°€ ë‹¨ìˆœí•œ ì±—ë´‡ì—ì„œ ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì§„í™”í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e12e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools import python_repl_tool, bash_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74af9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = strands_utils.get_agent(\n",
    "    agent_name=agent_name,\n",
    "    system_prompts=apply_prompt_template(prompt_name=agent_name, prompt_context={\"AGENT_NAME\": agent_name}),\n",
    "    agent_type=\"claude-sonnet-3-7\", # claude-sonnet-3-5-v-2, claude-sonnet-3-7\n",
    "    enable_reasoning=False,\n",
    "    prompt_cache_info=(False, None), #(False, None), (True, \"default\")\n",
    "    streaming=True,\n",
    "    tools=[python_repl_tool, bash_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d9c89",
   "metadata": {},
   "source": [
    "### 5.2 Bash ë„êµ¬ ì‚¬ìš© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: íŒŒì¼ ì‹œìŠ¤í…œ íƒìƒ‰ì„ í†µí•´ bash_toolì˜ ë™ì‘ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ì‘ì—… ìœ í˜• | ì‚¬ìš© ë„êµ¬ | ì‹¤í–‰ ëª…ë ¹ì–´ |\n",
    "|----------|----------|-------------|\n",
    "| **íŒŒì¼/ë””ë ‰í† ë¦¬ ì¡°íšŒ** | `bash_tool` | `ls`, `find`, `pwd` |\n",
    "| **ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸** | `bash_tool` | `df`, `ps`, `whoami` |\n",
    "| **íŒŒì¼ ì¡°ì‘** | `bash_tool` | `cp`, `mv`, `rm`, `mkdir` |\n",
    "\n",
    "#### ğŸ“‹ í…ŒìŠ¤íŠ¸ ë‚´ìš©\n",
    "- **ì‘ì—…**: `../src/prompts` ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸\n",
    "- **ë„êµ¬ ì„ íƒ ì¡°ê±´**: íŒŒì¼ ì‹œìŠ¤í…œ íƒìƒ‰ ìš”ì²­ ì‹œ ìë™ìœ¼ë¡œ bash_tool ì„ íƒë¨\n",
    "- **ì˜ˆìƒ ëª…ë ¹ì–´**: `ls ../src/prompts`\n",
    "\n",
    "ğŸ’¡ **Tip**: ì—ì´ì „íŠ¸ê°€ \"ë””ë ‰í† ë¦¬ ì¡°íšŒ\" ìš”ì²­ì„ bash ëª…ë ¹ì–´ë¡œ ìë™ ë³€í™˜í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4766a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97mì•ˆ\u001b[0m\u001b[97më…•í•˜ì„¸ìš”! ../src/prompts\u001b[0m\u001b[97m ë””ë ‰í† ë¦¬ë¥¼ ì¡°íšŒí•´ \u001b[0m\u001b[97më“œë¦¬ê² ìŠµë‹ˆë‹¤. bash\u001b[0m\u001b[97m ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´\u001b[0m\u001b[97më‹¹ ë””ë ‰í† ë¦¬ì˜\u001b[0m\u001b[97m ë‚´ìš©ì„ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\u001b[0m\n",
      "\n",
      "[TOOL RESULT - bash_tool]\n",
      "\u001b[93mCMD:\n",
      "```bash\n",
      "ls -la ../src/prompts\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "total 176\n",
      "drwxrwxr-x 3 ubuntu ubuntu  4096 Oct 14 09:36 .\n",
      "drwxrwxr-x 8 ubuntu ubuntu  4096 Oct 14 09:36 ..\n",
      "-rw-rw-r-- 1 ubuntu ubuntu     0 Oct 14 09:25 __init__.py\n",
      "drwxrwxr-x 2 ubuntu ubuntu  4096 Oct 14 09:36 __pycache__\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 34205 Oct 14 09:25 coder copy.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 33739 Oct 14 09:25 coder.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  1212 Oct 14 09:25 coordinator.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 12782 Oct 14 09:25 planner.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 15452 Oct 14 09:25 reporter.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  3754 Oct 14 09:25 supervisor.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu   457 Oct 14 09:25 template.py\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  2122 Oct 14 09:38 toy_agent.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  2283 Oct 14 09:25 tracker.md\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 39294 Oct 14 09:25 validator.md\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[97m../\u001b[0m\u001b[97msrc/prompts ë””ë ‰í† ë¦¬ì˜\u001b[0m\u001b[97m ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™\u001b[0m\u001b[97mìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. `\u001b[0m\u001b[97m__init__.py` - \u001b[0m\u001b[97më¹ˆ íŒŒì¼ (Python íŒ¨\u001b[0m\u001b[97mí‚¤ì§€ í‘œì‹œìš©)\n",
      "2.\u001b[0m\u001b[97m `__pycache__` - ë””\u001b[0m\u001b[97më ‰í† ë¦¬ (Python \u001b[0m\u001b[97mì»´íŒŒì¼ëœ ë°”ì´íŠ¸\u001b[0m\u001b[97mì½”ë“œ íŒŒì¼ ì €ì¥)\u001b[0m\u001b[97m\n",
      "3. `coder copy.\u001b[0m\u001b[97mmd` - coder í”„\u001b[0m\u001b[97më¡¬í”„íŠ¸ì˜\u001b[0m\u001b[97m ë³µì‚¬ë³¸\n",
      "4\u001b[0m\u001b[97m. `coder.md` -\u001b[0m\u001b[97m coder ì—­í• ì„\u001b[0m\u001b[97m ìœ„í•œ í”„\u001b[0m\u001b[97më¡¬í”„íŠ¸ íŒŒ\u001b[0m\u001b[97mì¼\n",
      "5. `coordinator.m\u001b[0m\u001b[97md` - coordinator ì—­í• ì„ ìœ„\u001b[0m\u001b[97mí•œ í”„ë¡¬í”„íŠ¸ íŒŒì¼\n",
      "6\u001b[0m\u001b[97m. `planner.md` - planner ì—­\u001b[0m\u001b[97mí• ì„ ìœ„í•œ í”„\u001b[0m\u001b[97më¡¬í”„íŠ¸ íŒŒì¼\n",
      "7\u001b[0m\u001b[97m. `reporter.md` - reporter\u001b[0m\u001b[97m ì—­í• ì„ ìœ„í•œ \u001b[0m\u001b[97mí”„ë¡¬í”„íŠ¸ íŒŒì¼\u001b[0m\u001b[97m\n",
      "8. `supervisor.md`\u001b[0m\u001b[97m - supervisor ì—­í• ì„ ìœ„\u001b[0m\u001b[97mí•œ í”„ë¡¬í”„íŠ¸ \u001b[0m\u001b[97míŒŒì¼\n",
      "9. `template.\u001b[0m\u001b[97mpy` - í…œí”Œë¦¿\u001b[0m\u001b[97m Python íŒŒì¼\n",
      "10. `toy\u001b[0m\u001b[97m_agent.md` - toy_agent ì—­í• \u001b[0m\u001b[97mì„ ìœ„í•œ í”„ë¡¬\u001b[0m\u001b[97mí”„íŠ¸ íŒŒì¼ (\u001b[0m\u001b[97mê°€ì¥ ìµœê·¼ì—\u001b[0m\u001b[97m ìˆ˜ì •ë¨)\n",
      "11\u001b[0m\u001b[97m. `tracker.md` - tracker ì—­í• ì„\u001b[0m\u001b[97m ìœ„í•œ í”„ë¡¬í”„íŠ¸ íŒŒì¼\u001b[0m\u001b[97m\n",
      "12. `validator.md`\u001b[0m\u001b[97m - validator ì—­í• ì„ ìœ„\u001b[0m\u001b[97mí•œ í”„ë¡¬í”„íŠ¸ íŒŒì¼\n",
      "\n",
      "ì´\u001b[0m\u001b[97m ë””ë ‰í† ë¦¬ëŠ”\u001b[0m\u001b[97m ë‹¤ì–‘í•œ ì—ì´\u001b[0m\u001b[97mì „íŠ¸ ì—­í• ì— ëŒ€í•œ \u001b[0m\u001b[97mí”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤ì„ í¬\u001b[0m\u001b[97mí•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\u001b[0mNone\n"
     ]
    }
   ],
   "source": [
    "message = \"../src/prompts ë””ë ‰í† ë¦¬ ì¡°íšŒí•´ ì£¼ì„¸ìš”\"\n",
    "\n",
    "full_text = \"\"\n",
    "async for event in strands_utils.process_streaming_response_yield(\n",
    "    agent=agent,\n",
    "    message=message,\n",
    "    agent_name=agent_name,\n",
    "    source=agent_name\n",
    "):\n",
    "    #print (event)\n",
    "    strands_utils.process_event_for_display(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbeee40",
   "metadata": {},
   "source": [
    "### 5.3 Python ë„êµ¬ ì‚¬ìš© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: Python ì½”ë“œ ì‹¤í–‰ì„ í†µí•´ python_repl_toolì˜ ë™ì‘ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ì‘ì—… ìœ í˜• | ì‚¬ìš© ë„êµ¬ | ì‹¤í–‰ ì˜ˆì‹œ |\n",
    "|----------|----------|-----------|\n",
    "| **ê³„ì‚° ë° ì—°ì‚°** | `python_repl_tool` | `2 + 2`, `math.sqrt(16)` |\n",
    "| **ë°ì´í„° ì²˜ë¦¬** | `python_repl_tool` | `pandas.read_csv()`, `numpy.array()` |\n",
    "| **ì½”ë“œ ì‹¤í–‰** | `python_repl_tool` | `print()`, `for loop`, í•¨ìˆ˜ ì •ì˜ |\n",
    "\n",
    "#### ğŸ“‹ í…ŒìŠ¤íŠ¸ ë‚´ìš©\n",
    "- **ì‘ì—…**: \"Hello world\" ì¶œë ¥í•˜ëŠ” Python ì½”ë“œ ì‘ì„± ë° ì‹¤í–‰\n",
    "- **ë„êµ¬ ì„ íƒ ì¡°ê±´**: Python ì½”ë“œ ì‹¤í–‰ ìš”ì²­ ì‹œ ìë™ìœ¼ë¡œ python_repl_tool ì„ íƒë¨\n",
    "- **ì˜ˆìƒ ì½”ë“œ**: `print(\"Hello world\")`\n",
    "\n",
    "ğŸ’¡ **Tip**: ì—ì´ì „íŠ¸ê°€ ìì—°ì–´ ìš”ì²­ì„ Python ì½”ë“œë¡œ ë³€í™˜í•˜ê³  ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3378f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97mì•ˆ\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in streaming response (attempt 1/5): An error occurred (throttlingException) when calling the ConverseStream operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/src/utils/strands_sdk_utils.py\", line 210, in _retry_agent_streaming\n",
      "    async for event in agent_stream:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/agent/agent.py\", line 581, in stream_async\n",
      "    async for event in events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/agent/agent.py\", line 619, in _run_loop\n",
      "    async for event in events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/agent/agent.py\", line 658, in _execute_event_loop_cycle\n",
      "    async for event in events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/event_loop.py\", line 110, in event_loop_cycle\n",
      "    async for model_event in model_events:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/event_loop.py\", line 316, in _handle_model_execution\n",
      "    raise e\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/event_loop.py\", line 264, in _handle_model_execution\n",
      "    async for event in stream_messages(agent.model, agent.system_prompt, agent.messages, tool_specs):\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/streaming.py\", line 351, in stream_messages\n",
      "    async for event in process_stream(chunks):\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/event_loop/streaming.py\", line 308, in process_stream\n",
      "    async for chunk in chunks:\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/models/bedrock.py\", line 625, in stream\n",
      "    await task\n",
      "  File \"/home/ubuntu/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/opentelemetry/instrumentation/threading/__init__.py\", line 171, in wrapped_func\n",
      "    return original_func(*func_args, **func_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/models/bedrock.py\", line 743, in _stream\n",
      "    raise e\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/strands/models/bedrock.py\", line 664, in _stream\n",
      "    for chunk in response[\"stream\"]:\n",
      "                 ~~~~~~~~^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/botocore/eventstream.py\", line 592, in __iter__\n",
      "    parsed_event = self._parse_event(event)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/06_insight_extractor_strands_sdk_workshop_phase_1/setup/.venv/lib/python3.12/site-packages/botocore/eventstream.py\", line 608, in _parse_event\n",
      "    raise EventStreamError(parsed_response, self._operation_name)\n",
      "botocore.exceptions.EventStreamError: An error occurred (throttlingException) when calling the ConverseStream operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "â”” Bedrock region: us-west-2\n",
      "â”” Model id: us.anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[97mì•ˆ\u001b[0m\u001b[97më…•í•˜ì„¸ìš”! \"Hello world\"ë¥¼\u001b[0m\u001b[97m ì¶œë ¥í•˜ëŠ” íŒŒ\u001b[0m\u001b[97mì´ì¬ ì½”ë“œë¥¼ \u001b[0m\u001b[97mì‘ì„±í•˜ê³  ì‹¤í–‰í•´\u001b[0m\u001b[97m ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "# Hello worldë¥¼ ì¶œë ¥í•˜ëŠ” ê°„ë‹¨í•œ íŒŒì´ì¬ ì½”ë“œ\n",
      "print(\"Hello world\")\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Hello world\n",
      "\n",
      "\u001b[0m\u001b[97míŒŒ\u001b[0m\u001b[97mì´ì¬ \u001b[0m\u001b[97mì½”ë“œë¥¼ ì„±\u001b[0m\u001b[97mê³µì ìœ¼ë¡œ ì‹¤í–‰í–ˆ\u001b[0m\u001b[97mìŠµë‹ˆë‹¤! ìœ„\u001b[0m\u001b[97m ì½”ë“œëŠ” ë§¤ìš° ê°„\u001b[0m\u001b[97më‹¨í•œ \"Hello world\"\u001b[0m\u001b[97m ì¶œë ¥ í”„ë¡œ\u001b[0m\u001b[97mê·¸ë¨ì…ë‹ˆ\u001b[0m\u001b[97më‹¤.\n",
      "\n",
      "ì½”ë“œ ì„¤\u001b[0m\u001b[97mëª…:\n",
      "```python\n",
      "print(\"\u001b[0m\u001b[97mHello world\")\n",
      "```\u001b[0m\u001b[97m\n",
      "\n",
      "ì´ ì½”ë“œëŠ” íŒŒì´ì¬ì˜\u001b[0m\u001b[97m ë‚´ì¥ í•¨ìˆ˜ì¸\u001b[0m\u001b[97m `print()`ë¥¼ ì‚¬ìš©í•˜ì—¬ \u001b[0m\u001b[97m\"Hello world\" ë¬¸ìì—´\u001b[0m\u001b[97mì„ ì½˜ì†”ì— ì¶œë ¥í•©\u001b[0m\u001b[97më‹ˆë‹¤. íŒŒì´ì¬ì—\u001b[0m\u001b[97mì„œ `print()` í•¨ìˆ˜\u001b[0m\u001b[97mëŠ” ê´„í˜¸ ì•ˆ\u001b[0m\u001b[97mì— ìˆëŠ” ë‚´\u001b[0m\u001b[97mìš©ì„ í™”ë©´ì— í‘œ\u001b[0m\u001b[97mì‹œí•˜ëŠ” ì—­í• ì„ í•©\u001b[0m\u001b[97më‹ˆë‹¤.\n",
      "\n",
      "ê²°\u001b[0m\u001b[97mê³¼ë¡œ \"Hello worl\u001b[0m\u001b[97md\"ê°€ ì •ìƒì ìœ¼ë¡œ\u001b[0m\u001b[97m ì¶œë ¥ëœ ê²ƒì„ \u001b[0m\u001b[97mí™•ì¸í•  ìˆ˜ ìˆìŠµ\u001b[0m\u001b[97më‹ˆë‹¤.\u001b[0mNone\n"
     ]
    }
   ],
   "source": [
    "message = \"Hello world ë¥¼ í”„ë¦°íŒ…í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰ì‹œì¼œ ì¤„ë˜?\"\n",
    "\n",
    "full_text = \"\"\n",
    "async for event in strands_utils.process_streaming_response_yield(\n",
    "    agent=agent,\n",
    "    message=message,\n",
    "    agent_name=agent_name,\n",
    "    source=agent_name\n",
    "):\n",
    "    strands_utils.process_event_for_display(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f0e7c5",
   "metadata": {},
   "source": [
    "## 6. Built-in utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e94a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c7d2c",
   "metadata": {},
   "source": [
    "### 6.1 Check agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef31341",
   "metadata": {},
   "source": [
    "#### 6.1.1 ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í™•ì¸\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ìƒì„±ëœ ì—ì´ì „íŠ¸ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "| í™•ì¸ í•­ëª© | ë‚´ìš© |\n",
    "|----------|------|\n",
    "| **ì—ì´ì „íŠ¸ ì§€ì¹¨ê³¼ ì—­í• ** | ì—ì´ì „íŠ¸ì— ì„¤ì •ëœ ì—­í• ê³¼ í–‰ë™ ì§€ì¹¨ ê²€í†  |\n",
    "| **í…œí”Œë¦¿ ì ìš© ì—¬ë¶€** | í…œí”Œë¦¿ì´ ì˜¬ë°”ë¥´ê²Œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸ |\n",
    "\n",
    "ğŸ’¡ **Tip**: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ì—ì´ì „íŠ¸ì˜ í–‰ë™ì„ ê²°ì •í•˜ëŠ” í•µì‹¬ ì„¤ì •ì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5a15b",
   "metadata": {},
   "source": [
    "**System prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29f6073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '---\\n'\n",
      " 'CURRENT_TIME: Thu Oct 02 2025 04:24:04 \\n'\n",
      " 'AGENT_NAME: toy_agent\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " 'You are Bedrock-Manus, a friendly AI assistant developed by AWS AIML '\n",
      " 'Specialist SA Dongjin Jang.\\n'\n",
      " 'You specialize in handling greetings, small talk, and knowledge-based '\n",
      " 'question answering using available tools.\\n'\n",
      " '\\n'\n",
      " '## Available Tools\\n'\n",
      " '\\n'\n",
      " 'You have access to the following tools that you should use when '\n",
      " 'appropriate:\\n'\n",
      " '\\n'\n",
      " '### 1. Python REPL Tool (python_repl_tool)\\n'\n",
      " '**When to use**: Use this tool when users need to execute Python code or '\n",
      " 'perform data analysis:\\n'\n",
      " '- Running Python scripts or code snippets\\n'\n",
      " '- Data analysis and calculations\\n'\n",
      " '- Testing code functionality\\n'\n",
      " '- Mathematical computations\\n'\n",
      " '\\n'\n",
      " '**What it does**: Executes Python code in a REPL environment and returns the '\n",
      " 'output\\n'\n",
      " '\\n'\n",
      " '**Input**: Python code string\\n'\n",
      " '\\n'\n",
      " '### 2. Bash Tool (bash_tool) \\n'\n",
      " '**When to use**: Use this tool when users need to execute system commands or '\n",
      " 'perform file operations:\\n'\n",
      " '- Running shell commands\\n'\n",
      " '- File system operations (ls, mkdir, etc.)\\n'\n",
      " '- System information queries\\n'\n",
      " '- Development tasks requiring command line operations\\n'\n",
      " '\\n'\n",
      " '**What it does**: Executes bash commands and returns the output\\n'\n",
      " '\\n'\n",
      " '**Input**: A bash command string\\n'\n",
      " '\\n'\n",
      " '## Tool Usage Guidelines\\n'\n",
      " '\\n'\n",
      " \"1. **Assess the user's request** - Determine if the question requires tool \"\n",
      " 'usage\\n'\n",
      " '2. **Choose the appropriate tool** - Select based on the type of information '\n",
      " 'needed\\n'\n",
      " '3. **Use RAG tool for knowledge queries** - When the user asks about topics '\n",
      " 'that might be in your knowledge base\\n'\n",
      " '4. **Use Python REPL for code execution** - When the user needs to run '\n",
      " 'Python code or perform calculations\\n'\n",
      " '5. **Use Bash tool for system operations** - When the user needs to interact '\n",
      " 'with the system\\n'\n",
      " '6. **Provide helpful responses** - Always explain the results in a '\n",
      " 'user-friendly way\\n'\n",
      " '\\n'\n",
      " '## Response Style\\n'\n",
      " '\\n'\n",
      " '- Be friendly and conversational\\n'\n",
      " '- Provide clear, helpful answers\\n'\n",
      " \"- When using tools, explain what you're doing and why\\n\"\n",
      " \"- If a tool doesn't provide the needed information, acknowledge this and \"\n",
      " 'offer alternatives\\n'\n",
      " '- Always prioritize user experience and clarity\\n'\n",
      " '\\n'\n",
      " 'Remember to use tools proactively when they can help answer user questions '\n",
      " 'more accurately or completely.\\n')\n"
     ]
    }
   ],
   "source": [
    "system_prompt = agent.system_prompt\n",
    "pprint(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f56bb",
   "metadata": {},
   "source": [
    "#### 6.1.2 ì—ì´ì „íŠ¸ ëŒ€í™” ê¸°ë¡ í™•ì¸\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ì—ì´ì „íŠ¸ì˜ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "| í¬í•¨ ë‚´ìš© | ì„¤ëª… |\n",
    "|----------|------|\n",
    "| **ëª¨ë“  ëŒ€í™” ë‚´ìš©** | ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©ê³¼ ë„êµ¬ ì‚¬ìš© ê¸°ë¡ |\n",
    "| **ë‹¤ì–‘í•œ ë©”ì‹œì§€ íƒ€ì…** | ì‚¬ìš©ì ë©”ì‹œì§€, ì—ì´ì „íŠ¸ ì‘ë‹µ, ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ë“± |\n",
    "\n",
    "ğŸ’¡ **Tip**: ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ê°€ ì–´ë–¤ ê³¼ì •ì„ ê±°ì³ ì‘ë‹µí–ˆëŠ”ì§€ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfb0e8",
   "metadata": {},
   "source": [
    "**Message history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "123c6225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': [{'text': '../src/prompts ë””ë ‰í† ë¦¬ ì¡°íšŒí•´ ì£¼ì„¸ìš”'}], 'role': 'user'},\n",
      " {'content': [{'text': 'ë„¤, \"../src/prompts\" ë””ë ‰í† ë¦¬ë¥¼ ì¡°íšŒí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. Bash ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ '\n",
      "                       'í•´ë‹¹ ë””ë ‰í† ë¦¬ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.'},\n",
      "              {'toolUse': {'input': {'cmd': 'ls -la ../src/prompts'},\n",
      "                           'name': 'bash_tool',\n",
      "                           'toolUseId': 'tooluse_Vacni6jmRvuFdY4aHJOsoA'}}],\n",
      "  'role': 'assistant'},\n",
      " {'content': [{'toolResult': {'content': [{'text': 'ls -la '\n",
      "                                                   '../src/prompts||total 176\\n'\n",
      "                                                   'drwxrwxr-x 3 ubuntu '\n",
      "                                                   'ubuntu  4096 Oct  1 13:16 '\n",
      "                                                   '.\\n'\n",
      "                                                   'drwxrwxr-x 8 ubuntu '\n",
      "                                                   'ubuntu  4096 Oct  1 08:14 '\n",
      "                                                   '..\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu '\n",
      "                                                   'ubuntu     0 Oct  1 08:09 '\n",
      "                                                   '__init__.py\\n'\n",
      "                                                   'drwxrwxr-x 2 ubuntu '\n",
      "                                                   'ubuntu  4096 Oct  1 08:14 '\n",
      "                                                   '__pycache__\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu ubuntu '\n",
      "                                                   '34205 Oct  1 08:09 coder '\n",
      "                                                   'copy.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu ubuntu '\n",
      "                                                   '33739 Oct  1 08:09 '\n",
      "                                                   'coder.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu '\n",
      "                                                   'ubuntu  1241 Oct  1 08:09 '\n",
      "                                                   'coordinator.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu ubuntu '\n",
      "                                                   '12782 Oct  1 13:16 '\n",
      "                                                   'planner.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu ubuntu '\n",
      "                                                   '15452 Oct  1 08:09 '\n",
      "                                                   'reporter.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu '\n",
      "                                                   'ubuntu  3754 Oct  1 08:09 '\n",
      "                                                   'supervisor.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu '\n",
      "                                                   'ubuntu   457 Oct  1 08:09 '\n",
      "                                                   'template.py\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu '\n",
      "                                                   'ubuntu  2119 Oct  2 04:23 '\n",
      "                                                   'toy_agent.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu '\n",
      "                                                   'ubuntu  2283 Oct  1 08:09 '\n",
      "                                                   'tracker.md\\n'\n",
      "                                                   '-rw-rw-r-- 1 ubuntu ubuntu '\n",
      "                                                   '39294 Oct  1 08:09 '\n",
      "                                                   'validator.md\\n'\n",
      "                                                   '\\n'}],\n",
      "                              'status': 'success',\n",
      "                              'toolUseId': 'tooluse_Vacni6jmRvuFdY4aHJOsoA'}}],\n",
      "  'role': 'user'},\n",
      " {'content': [{'text': '\"../src/prompts\" ë””ë ‰í† ë¦¬ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŒŒì¼ë“¤ì´ ìˆìŠµë‹ˆë‹¤:\\n'\n",
      "                       '\\n'\n",
      "                       '1. `__init__.py` - ë¹ˆ íŒŒì¼ (Python íŒ¨í‚¤ì§€ í‘œì‹œìš©)\\n'\n",
      "                       '2. `__pycache__` - ë””ë ‰í† ë¦¬ (Python ì»´íŒŒì¼ëœ ë°”ì´íŠ¸ì½”ë“œ íŒŒì¼ ì €ì¥)\\n'\n",
      "                       '3. `coder copy.md` - coder.mdì˜ ë³µì‚¬ë³¸ìœ¼ë¡œ ë³´ì´ëŠ” íŒŒì¼\\n'\n",
      "                       '4. `coder.md` - ì½”ë” ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼\\n'\n",
      "                       '5. `coordinator.md` - ì½”ë””ë„¤ì´í„° ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼\\n'\n",
      "                       '6. `planner.md` - í”Œë˜ë„ˆ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼\\n'\n",
      "                       '7. `reporter.md` - ë¦¬í¬í„° ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼\\n'\n",
      "                       '8. `supervisor.md` - ìˆ˜í¼ë°”ì´ì € ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼\\n'\n",
      "                       '9. `template.py` - í…œí”Œë¦¿ Python íŒŒì¼\\n'\n",
      "                       '10. `toy_agent.md` - í† ì´ ì—ì´ì „íŠ¸ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼ (ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •ë¨ - '\n",
      "                       'ì˜¤ëŠ˜ 04:23)\\n'\n",
      "                       '11. `tracker.md` - íŠ¸ë˜ì»¤ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼\\n'\n",
      "                       '12. `validator.md` - ë°¸ë¦¬ë°ì´í„° ê´€ë ¨ í”„ë¡¬í”„íŠ¸ íŒŒì¼\\n'\n",
      "                       '\\n'\n",
      "                       'ì´ ë””ë ‰í† ë¦¬ëŠ” ë‹¤ì–‘í•œ AI ì—ì´ì „íŠ¸ ì—­í• ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤ì„ í¬í•¨í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ '\n",
      "                       'ë³´ì…ë‹ˆë‹¤.'}],\n",
      "  'role': 'assistant'},\n",
      " {'content': [{'text': 'Hello world ë¥¼ í”„ë¦°íŒ…í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰ì‹œì¼œ ì¤„ë˜?'}],\n",
      "  'role': 'user'},\n",
      " {'content': [{'text': 'ì•ˆë…•í•˜ì„¸ìš”! \"Hello world\"ë¥¼ ì¶œë ¥í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.'},\n",
      "              {'toolUse': {'input': {'code': '# Hello worldë¥¼ ì¶œë ¥í•˜ëŠ” ê°„ë‹¨í•œ íŒŒì´ì¬ ì½”ë“œ\\n'\n",
      "                                             'print(\"Hello world\")'},\n",
      "                           'name': 'python_repl_tool',\n",
      "                           'toolUseId': 'tooluse_HAXFNmnLSKO2rjWW4kg_Hg'}}],\n",
      "  'role': 'assistant'},\n",
      " {'content': [{'toolResult': {'content': [{'text': 'Successfully executed:\\n'\n",
      "                                                   '||# Hello worldë¥¼ ì¶œë ¥í•˜ëŠ” ê°„ë‹¨í•œ '\n",
      "                                                   'íŒŒì´ì¬ ì½”ë“œ\\n'\n",
      "                                                   'print(\"Hello '\n",
      "                                                   'world\")||Hello world\\n'}],\n",
      "                              'status': 'success',\n",
      "                              'toolUseId': 'tooluse_HAXFNmnLSKO2rjWW4kg_Hg'}}],\n",
      "  'role': 'user'},\n",
      " {'content': [{'text': 'íŒŒì´ì¬ ì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤! ê²°ê³¼ë¡œ \"Hello world\"ê°€ ì¶œë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.\\n'\n",
      "                       '\\n'\n",
      "                       'ì´ ì½”ë“œëŠ” ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤:\\n'\n",
      "                       '```python\\n'\n",
      "                       '# Hello worldë¥¼ ì¶œë ¥í•˜ëŠ” ê°„ë‹¨í•œ íŒŒì´ì¬ ì½”ë“œ\\n'\n",
      "                       'print(\"Hello world\")\\n'\n",
      "                       '```\\n'\n",
      "                       '\\n'\n",
      "                       '`print()` í•¨ìˆ˜ëŠ” íŒŒì´ì¬ì—ì„œ ì½˜ì†”ì— í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ëŠ” ê¸°ë³¸ í•¨ìˆ˜ì…ë‹ˆë‹¤. ë”°ì˜´í‘œ ì•ˆì— ìˆëŠ” '\n",
      "                       'í…ìŠ¤íŠ¸(\"Hello world\")ê°€ í™”ë©´ì— í‘œì‹œë©ë‹ˆë‹¤.'}],\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "agent_messages = agent.messages\n",
    "pprint(agent_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ea3f3",
   "metadata": {},
   "source": [
    "#### 6.1.3 ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ì—ì´ì „íŠ¸ì˜ ì´ë²¤íŠ¸ ë£¨í”„ ë©”íŠ¸ë¦­ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë©”íŠ¸ë¦­ ìœ í˜• | ë‚´ìš© |\n",
    "|------------|------|\n",
    "| **ì„±ëŠ¥ ë°ì´í„°** | ì‘ë‹µ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰, ì—ëŸ¬ ë°œìƒ ë“±ì˜ ì„±ëŠ¥ ë°ì´í„° |\n",
    "| **ëª¨ë‹ˆí„°ë§ í™œìš©** | ì—ì´ì „íŠ¸ ìš´ì˜ ìƒíƒœì™€ íš¨ìœ¨ì„±ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ë° ìœ ìš© |\n",
    "\n",
    "ğŸ’¡ **Tip**: ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ í†µí•´ ì—ì´ì „íŠ¸ì˜ íš¨ìœ¨ì„±ê³¼ ì•ˆì •ì„±ì„ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed8f0c",
   "metadata": {},
   "source": [
    "**Observability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64986e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventLoopMetrics(cycle_count=4,\n",
      "                 tool_metrics={'bash_tool': ToolMetrics(tool={'input': {'cmd': 'ls '\n",
      "                                                                               '-la '\n",
      "                                                                               '../src/prompts'},\n",
      "                                                              'name': 'bash_tool',\n",
      "                                                              'toolUseId': 'tooluse_Vacni6jmRvuFdY4aHJOsoA'},\n",
      "                                                        call_count=1,\n",
      "                                                        success_count=1,\n",
      "                                                        error_count=0,\n",
      "                                                        total_time=0.004104137420654297),\n",
      "                               'python_repl_tool': ToolMetrics(tool={'input': {'code': '# '\n",
      "                                                                                       'Hello '\n",
      "                                                                                       'worldë¥¼ '\n",
      "                                                                                       'ì¶œë ¥í•˜ëŠ” '\n",
      "                                                                                       'ê°„ë‹¨í•œ '\n",
      "                                                                                       'íŒŒì´ì¬ '\n",
      "                                                                                       'ì½”ë“œ\\n'\n",
      "                                                                                       'print(\"Hello '\n",
      "                                                                                       'world\")'},\n",
      "                                                                     'name': 'python_repl_tool',\n",
      "                                                                     'toolUseId': 'tooluse_HAXFNmnLSKO2rjWW4kg_Hg'},\n",
      "                                                               call_count=1,\n",
      "                                                               success_count=1,\n",
      "                                                               error_count=0,\n",
      "                                                               total_time=0.019395112991333008)},\n",
      "                 cycle_durations=[6.433272838592529, 3.325401782989502],\n",
      "                 traces=[<strands.telemetry.metrics.Trace object at 0xe4530ce49820>,\n",
      "                         <strands.telemetry.metrics.Trace object at 0xe4530ce0faa0>,\n",
      "                         <strands.telemetry.metrics.Trace object at 0xe4530ce49580>,\n",
      "                         <strands.telemetry.metrics.Trace object at 0xe4530cc72ab0>],\n",
      "                 accumulated_usage={'inputTokens': 6940,\n",
      "                                    'outputTokens': 873,\n",
      "                                    'totalTokens': 7813},\n",
      "                 accumulated_metrics={'latencyMs': 18767})\n"
     ]
    }
   ],
   "source": [
    "pprint(agent.event_loop_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f7983",
   "metadata": {},
   "source": [
    "#### 6.1.4 ì—ì´ì „íŠ¸ ìƒíƒœ ë³µì›ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "\n",
    "> **ğŸ¯ ëª©ì **: ê¸°ì¡´ ì—ì´ì „íŠ¸ì˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ importí•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ìš©ë„ |\n",
    "|----------|------|\n",
    "| **Strands ê¸°ë³¸ í´ë˜ìŠ¤ë“¤** | Agent, BedrockModel ë“± í•µì‹¬ ì»´í¬ë„ŒíŠ¸ |\n",
    "| **Bedrock ëª¨ë¸ê³¼ ì„¤ì • ì •ë³´** | ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ë³µì› |\n",
    "\n",
    "ğŸ’¡ **Tip**: ì—ì´ì „íŠ¸ ìƒíƒœ ë³µì›ì„ í†µí•´ ëŒ€í™”ì˜ ì—°ì†ì„±ì„ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961fb569",
   "metadata": {},
   "source": [
    "**Resume**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dbcd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from botocore.config import Config\n",
    "from strands.models import BedrockModel\n",
    "from src.utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c48b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_ = BedrockModel(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-7-Sonnet-CRI\"),\n",
    "    streaming=True,\n",
    "    max_tokens=8192,\n",
    "    stop_sequences=[\"\\n\\nHuman\"],\n",
    "    temperature=0.01,\n",
    "    cache_prompt=None, # None/ephemeral/defalut\n",
    "    #cache_tools: Cache point type for tools\n",
    "    boto_client_config=Config(\n",
    "        read_timeout=900,\n",
    "        connect_timeout=900,\n",
    "        retries=dict(max_attempts=50, mode=\"standard\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "agent_ = Agent(\n",
    "    model=llm_,\n",
    "    tools=[python_repl_tool, bash_tool],\n",
    "    system_prompt=system_prompt,\n",
    "    messages=agent_messages,\n",
    "    callback_handler=None # async iteratorë¡œ ëŒ€ì²´ í•˜ê¸° ë•Œë¬¸ì— None ì„¤ì •\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baf617f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97më„¤, \u001b[0m\u001b[97më§ìŠµë‹ˆë‹¤! ìš°\u001b[0m\u001b[97më¦¬ëŠ” ê³„ì†í•´ì„œ \u001b[0m\u001b[97mê°™ì€ ëŒ€í™” ì„¸ì…˜ \u001b[0m\u001b[97më‚´ì—ì„œ \u001b[0m\u001b[97mëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆ\u001b[0m\u001b[97më‹¤. ì´ì „ \u001b[0m\u001b[97më©”ì‹œì§€ë“¤ì˜\u001b[0m\u001b[97m ë‚´ìš©ì„ ê¸°\u001b[0m\u001b[97mì–µí•˜ê³  ìˆìœ¼\u001b[0m\u001b[97më©°, ëŒ€í™”ì˜\u001b[0m\u001b[97m ë§¥ë½ì„ \u001b[0m\u001b[97mìœ ì§€í•˜ê³  \u001b[0m\u001b[97mìˆìŠµë‹ˆë‹¤\u001b[0m\u001b[97m.\n",
      "\n",
      "ì²˜ìŒì—ëŠ” \u001b[0m\u001b[97m\"../src/prom\u001b[0m\u001b[97mpts\" ë””ë ‰\u001b[0m\u001b[97mí† ë¦¬ë¥¼ ì¡°\u001b[0m\u001b[97míšŒí•´ ë“œ\u001b[0m\u001b[97më ¸ê³ , ê·¸\u001b[0m\u001b[97m ë‹¤ìŒì—ëŠ” \u001b[0m\u001b[97m\"Hello world\"ë¥¼ ì¶œë ¥\u001b[0m\u001b[97mí•˜ëŠ” íŒŒì´ì¬ \u001b[0m\u001b[97mì½”ë“œë¥¼ ì‹¤í–‰í–ˆ\u001b[0m\u001b[97mìŠµë‹ˆë‹¤. ê·¸\u001b[0m\u001b[97më¦¬ê³  ì§€ê¸ˆ\u001b[0m\u001b[97mì€ ëŒ€í™”ê°€\u001b[0m\u001b[97m ê³„ì† ì´ì–´ì§€ê³ \u001b[0m\u001b[97m ìˆëŠ” ìƒ\u001b[0m\u001b[97míƒœì…ë‹ˆë‹¤.\n",
      "\n",
      "ì¶”\u001b[0m\u001b[97mê°€ì ì¸ ì§ˆ\u001b[0m\u001b[97më¬¸ì´ë‚˜ ë„ì›€ì´\u001b[0m\u001b[97m í•„ìš”í•œ ì‚¬\u001b[0m\u001b[97mí•­ì´ ìˆìœ¼\u001b[0m\u001b[97mì‹œë©´ ì–¸ì œë“ ì§€\u001b[0m\u001b[97m ë§ì”€í•´ ì£¼ì„¸\u001b[0m\u001b[97mìš”!\u001b[0m"
     ]
    }
   ],
   "source": [
    "message = \"ì´ì–´ì„œ ëŒ€í™” í•˜ëŠ”ê±° ë§ë‹ˆ?\"\n",
    "\n",
    "full_text = \"\"\n",
    "async for event in strands_utils.process_streaming_response_yield(\n",
    "    agent=agent_,\n",
    "    message=message,\n",
    "    agent_name=agent_name,\n",
    "    source=agent_name\n",
    "):\n",
    "    strands_utils.process_event_for_display(event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956bf40",
   "metadata": {},
   "source": [
    "### 6.2 [Conversation management](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/agents/conversation-management/?h=conversa)\n",
    "\n",
    "As conversations grow, managing this context becomes increasingly important for several reasons:\n",
    "\n",
    "- **Token Limits**: Language models have fixed context windows (maximum tokens they can process)\n",
    "- **Performance**: Larger contexts require more processing time and resources\n",
    "- **Relevance**: Older messages may become less relevant to the current conversation\n",
    "- **Coherence**: Maintaining logical flow and preserving important information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a182fb",
   "metadata": {},
   "source": [
    "#### 6.2.1 SlidingWindowConversationManager\n",
    "\n",
    "ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ì˜ ëŒ€í™” ê´€ë¦¬ìë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:\n",
    "- ê³ ì •ëœ ìˆ˜ì˜ ìµœê·¼ ë©”ì‹œì§€ë¥¼ ìœ ì§€í•˜ëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì „ëµì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "- Agent í´ë˜ìŠ¤ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ëŒ€í™” ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.\n",
    "- Strands SDKì˜ ëŒ€í™” ê´€ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ `SlidingWindowConversationManager`ë¥¼ importí•©ë‹ˆë‹¤.\n",
    "- ì´ëŠ” ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ ìµœê·¼ Nê°œì˜ ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.agent.conversation_manager import SlidingWindowConversationManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb983df",
   "metadata": {},
   "source": [
    "ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ì˜ ëŒ€í™” ê´€ë¦¬ìë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- `window_size=3`: ìµœê·¼ 3ê°œì˜ ë©”ì‹œì§€ë§Œ ìœ ì§€\n",
    "- `should_truncate_results=True`: í° ë„êµ¬ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ì¶•ì•½\n",
    "- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì œí•œí•˜ë©´ì„œë„ ìµœê·¼ ë§¥ë½ì„ ìœ ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversation manager with custom window size\n",
    "conversation_manager = SlidingWindowConversationManager(\n",
    "    window_size=3,  # Maximum number of messages to keep\n",
    "    should_truncate_results=True, # Enable truncating the tool result when a message is too large for the model's context window \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff719d",
   "metadata": {},
   "source": [
    "### ì—ì´ì „íŠ¸ì— ëŒ€í™” ê´€ë¦¬ì ì ìš©\n",
    "\n",
    "ìƒì„±ëœ ëŒ€í™” ê´€ë¦¬ìë¥¼ ì—ì´ì „íŠ¸ì— ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "ì´ì œ ì—ì´ì „íŠ¸ëŠ” ì„¤ì •ëœ ìœˆë„ìš° í¬ê¸°ì— ë”°ë¼ ëŒ€í™” ê¸°ë¡ì„ ìë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.conversation_manager = conversation_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8fa5a8",
   "metadata": {},
   "source": [
    "### ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë™ì‘ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì—¬ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ê°€ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "- ìƒˆë¡œìš´ ë©”ì‹œì§€ ì¶”ê°€ í›„ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ í™•ì¸\n",
    "- ìœˆë„ìš° í¬ê¸° ì œí•œìœ¼ë¡œ ì˜¤ë˜ëœ ë©”ì‹œì§€ê°€ ì œê±°ë˜ëŠ”ì§€ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"ì•ˆë…• ë‚˜ëŠ” ì¥ë™ì§„ì´ì•¼\"\n",
    "\n",
    "full_text = \"\"\n",
    "async for event in strands_utils.process_streaming_response_yield(\n",
    "    agent=agent,\n",
    "    message=message,\n",
    "    agent_name=agent_name,\n",
    "    source=agent_name\n",
    "):\n",
    "    strands_utils.process_event_for_display(event)\n",
    "\n",
    "print (\"\\n\")\n",
    "pprint (agent.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad3936",
   "metadata": {},
   "source": [
    "#### 6.2.2 SummarizingConversationManager\n",
    "\n",
    "ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ìš”ì•½í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì»¨í…ìŠ¤íŠ¸ í•œê³„ ë‚´ì—ì„œ ëŒ€í™”ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ì„¤ì •:**\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |\n",
    "|---------|------|--------|------|\n",
    "| `summary_ratio` | `float` | `0.3` | ì»¨í…ìŠ¤íŠ¸ ì¶•ì†Œ ì‹œ ìš”ì•½í•  ë©”ì‹œì§€ ë¹„ìœ¨ (0.1~0.8 ë²”ìœ„) |\n",
    "| `preserve_recent_messages` | `int` | `10` | í•­ìƒ ìœ ì§€í•  ìµœê·¼ ë©”ì‹œì§€ ìˆ˜ |\n",
    "| `summarization_agent` | `Agent` | `None` | ìš”ì•½ ìƒì„±ìš© ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ (system_promptì™€ ë™ì‹œ ì‚¬ìš© ë¶ˆê°€) |\n",
    "| `summarization_system_prompt` | `str` | `None` | ìš”ì•½ìš© ì»¤ìŠ¤í…€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (agentì™€ ë™ì‹œ ì‚¬ìš© ë¶ˆê°€) |\n",
    "\n",
    "> **ê¸°ë³¸ ìš”ì•½ ë°©ì‹**: ì»¤ìŠ¤í…€ ì„¤ì •ì´ ì—†ì„ ê²½ìš°, ì£¼ìš” í† í”½, ì‚¬ìš©ëœ ë„êµ¬, ê¸°ìˆ ì  ì •ë³´ë¥¼ 3ì¸ì¹­ í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ìš”ì•½í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.agent.conversation_manager import SummarizingConversationManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd21aec",
   "metadata": {},
   "source": [
    "### SummarizingConversationManager ì„¤ì •\n",
    "\n",
    "ìš”ì•½ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬ìë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- `summary_ratio=0.3`: ì»¨í…ìŠ¤íŠ¸ ì¶•ì†Œ ì‹œ 30%ì˜ ë©”ì‹œì§€ë¥¼ ìš”ì•½\n",
    "- `preserve_recent_messages=3`: ìµœê·¼ 3ê°œ ë©”ì‹œì§€ëŠ” í•­ìƒ ìœ ì§€\n",
    "- `summarization_system_prompt`: ê¸°ìˆ ì  ëŒ€í™”ì— íŠ¹í™”ëœ ì»¤ìŠ¤í…€ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "- ì½”ë“œ ë³€ê²½ì‚¬í•­, ì•„í‚¤í…ì²˜ ê²°ì •, ê¸°ìˆ ì  ì†”ë£¨ì…˜ì— ì¤‘ì ì„ ë‘” ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8da725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom system prompt for technical conversations\n",
    "custom_system_prompt = \"\"\"\n",
    "You are summarizing a technical conversation. Create a concise bullet-point summary that:\n",
    "- Focuses on code changes, architectural decisions, and technical solutions\n",
    "- Preserves specific function names, file paths, and configuration details\n",
    "- Omits conversational elements and focuses on actionable information\n",
    "- Uses technical terminology appropriate for software development\n",
    "\n",
    "Format as bullet points without conversational language.\n",
    "\"\"\"\n",
    "\n",
    "conversation_manager = SummarizingConversationManager(\n",
    "    summary_ratio=0.3,  # Summarize 30% of messages when context reduction is needed\n",
    "    preserve_recent_messages=3,  # Always keep 10 most recent messages\n",
    "    summarization_system_prompt=custom_system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b6717",
   "metadata": {},
   "source": [
    "### ìš”ì•½ ê´€ë¦¬ì ì ìš©\n",
    "\n",
    "ìƒˆë¡œ ìƒì„±í•œ ìš”ì•½ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬ìë¥¼ ì—ì´ì „íŠ¸ì— ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "ì´ì œ ì—ì´ì „íŠ¸ëŠ” ì˜¤ë˜ëœ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.conversation_manager = conversation_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9cb05b",
   "metadata": {},
   "source": [
    "### ìš”ì•½ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ìš”ì•½ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬ê°€ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "- ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘ í›„ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í™•ì¸\n",
    "- ìš”ì•½ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ë©´ ì´ì „ ëŒ€í™”ë“¤ì´ ì–´ë–»ê²Œ ìš”ì•½ë˜ëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"ì•ˆë…• ë‚˜ëŠ” ì¥ë™ì§„ì´ì•¼\"\n",
    "\n",
    "full_text = \"\"\n",
    "async for event in strands_utils.process_streaming_response_yield(\n",
    "    agent=agent,\n",
    "    message=message,\n",
    "    agent_name=agent_name,\n",
    "    source=agent_name\n",
    "):\n",
    "    #print (event)\n",
    "    strands_utils.process_event_for_display(event)\n",
    "\n",
    "print (\"\\n\")\n",
    "pprint (agent.messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-manus-agentcore (UV)",
   "language": "python",
   "name": "bedrock-manus-agentcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
