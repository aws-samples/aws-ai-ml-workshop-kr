{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í†µí•© ìƒëª…ê³¼í•™ ì—°êµ¬ ì—ì´ì „íŠ¸ - Amazon Bedrock AgentCore\n",
    "\n",
    "![AgentCore](images/agentcore_overview.png)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ëª¨ë“  ë…¸íŠ¸ë¶(01~04)ì˜ ë„êµ¬ë“¤ì„ í†µí•©í•œ ì¢…í•©ì ì¸ ìƒëª…ê³¼í•™ ì—°êµ¬ ì—ì´ì „íŠ¸ë¥¼ Amazon Bedrock AgentCore Runtimeìœ¼ë¡œ ë°°í¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "## í†µí•©ë˜ëŠ” ê¸°ëŠ¥\n",
    "- **ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤** (01_external_dbs): Arxiv, ChEMBL, PubMed, ClinicalTrials\n",
    "- **ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤** (02_internal_dbs): PostgreSQL ì„ìƒ/ìœ ì „ì²´ ë°ì´í„°\n",
    "- **í•˜ì´ë¸Œë¦¬ë“œ ë„êµ¬** (03_hybrid_tools): Knowledge Base\n",
    "- **ë‹¨ë°±ì§ˆ ì„¤ê³„** (04_protein_design): AWS HealthOmics ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- ëª¨ë“  ë„êµ¬ë¥¼ í†µí•©í•œ ì¢…í•© Agent êµ¬í˜„\n",
    "- AgentCore Runtimeì— ë°°í¬ ë° ìš´ì˜\n",
    "- ë‹¤ì–‘í•œ ìƒëª…ê³¼í•™ ì—°êµ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "%pip install bedrock-agentcore-starter-toolkit strands-agents strands-agents-tools boto3 \\\n",
    "    mcp arxiv chembl-webresource-client python-dateutil pubmedmcp \\\n",
    "    psycopg2-binary --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:05.334794Z",
     "iopub.status.busy": "2025-09-29T09:20:05.334352Z",
     "iopub.status.idle": "2025-09-29T09:20:06.415212Z",
     "shell.execute_reply": "2025-09-29T09:20:06.414538Z",
     "shell.execute_reply.started": "2025-09-29T09:20:05.334767Z"
    }
   },
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "\n",
    "# AWS SDK\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "\n",
    "# Bedrock AgentCore\n",
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "# Strands Agents\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands_tools import calculator\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í†µí•© Agent êµ¬í˜„\n",
    "\n",
    "ëª¨ë“  ë…¸íŠ¸ë¶ì˜ ë„êµ¬ë“¤ì„ í•˜ë‚˜ì˜ Agentì— í†µí•©í•œ Python ëª¨ë“ˆì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë³€ê²½ í•„ìš” ì‚¬í•­:\n",
    "1. `DB_CONFIG`ì˜ `host`\n",
    "2. `trigger_protein_optimization` í•¨ìˆ˜ì˜ `workflow_id`, `role_arn`, `s3_bucket`\n",
    "3. `query_knowledge_base` í•¨ìˆ˜ì˜ `kb_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:06.431400Z",
     "iopub.status.busy": "2025-09-29T09:20:06.431173Z",
     "iopub.status.idle": "2025-09-29T09:20:06.444836Z",
     "shell.execute_reply": "2025-09-29T09:20:06.444090Z",
     "shell.execute_reply.started": "2025-09-29T09:20:06.431381Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile integrated_research_agent.py\n",
    "\"\"\"\n",
    "í†µí•© ìƒëª…ê³¼í•™ ì—°êµ¬ ì—ì´ì „íŠ¸ for Amazon Bedrock AgentCore\n",
    "ëª¨ë“  ë„êµ¬ í†µí•©: ì™¸ë¶€DB, ë‚´ë¶€DB, í•˜ì´ë¸Œë¦¬ë“œ, ë‹¨ë°±ì§ˆ ì„¤ê³„\n",
    "\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Any, List, Optional\n",
    "from collections import defaultdict\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import arxiv\n",
    "from chembl_webresource_client.new_client import new_client as chembl_client\n",
    "import httpx\n",
    "from defusedxml import ElementTree as ET\n",
    "import psycopg2\n",
    "import boto3\n",
    "\n",
    "import uuid\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# AWS í´ë¼ì´ì–¸íŠ¸\n",
    "omics_client = boto3.client('omics')\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "knowledge_base_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "# =========================\n",
    "# 1. ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def search_arxiv(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Arxivì—ì„œ í•™ìˆ  ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n",
    "    \n",
    "    Returns:\n",
    "        ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = arxiv.Client()\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for paper in client.results(search):\n",
    "            results.append({\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"abstract\": paper.summary[:500],\n",
    "                \"url\": paper.pdf_url,\n",
    "                \"published\": paper.published.isoformat()\n",
    "            })\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Arxiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "@tool\n",
    "def search_compound(compound_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"ChEMBLì—ì„œ í™”í•©ë¬¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        compound_name: í™”í•©ë¬¼ëª…\n",
    "    \n",
    "    Returns:\n",
    "        í™”í•©ë¬¼ ì •ë³´ ë° í™œì„± ë°ì´í„°\n",
    "    \"\"\"\n",
    "    try:\n",
    "        molecule = chembl_client.molecule.filter(\n",
    "            pref_name__iexact=compound_name\n",
    "        ).only(['molecule_chembl_id', 'pref_name', 'max_phase'])\n",
    "        \n",
    "        if molecule:\n",
    "            mol_data = molecule[0]\n",
    "            # IC50 í™œì„± ë°ì´í„°\n",
    "            activity = chembl_client.activity.filter(\n",
    "                molecule_chembl_id=mol_data['molecule_chembl_id']\n",
    "            ).filter(standard_type=\"IC50\").only(\n",
    "                ['pchembl_value', 'assay_description', 'canonical_smiles']\n",
    "            )[:10]\n",
    "            \n",
    "            return {\n",
    "                \"chembl_id\": mol_data['molecule_chembl_id'],\n",
    "                \"name\": mol_data['pref_name'],\n",
    "                \"max_phase\": mol_data.get('max_phase'),\n",
    "                \"activities\": list(activity)\n",
    "            }\n",
    "        return {\"error\": \"Compound not found\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ChEMBL ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@tool\n",
    "def search_pubmed(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"PubMedì—ì„œ ì˜í•™ ë¬¸í—Œì„ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n",
    "    \n",
    "    Returns:\n",
    "        ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
    "        \n",
    "        # ê²€ìƒ‰\n",
    "        search_params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"term\": query,\n",
    "            \"retmax\": max_results,\n",
    "            \"retmode\": \"json\"\n",
    "        }\n",
    "        \n",
    "        search_response = httpx.get(\n",
    "            f\"{base_url}/esearch.fcgi\",\n",
    "            params=search_params\n",
    "        )\n",
    "        search_data = search_response.json()\n",
    "        \n",
    "        id_list = search_data[\"esearchresult\"].get(\"idlist\", [])\n",
    "        if not id_list:\n",
    "            return []\n",
    "        \n",
    "        # ìƒì„¸ ì •ë³´\n",
    "        fetch_params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"id\": \",\".join(id_list),\n",
    "            \"retmode\": \"xml\"\n",
    "        }\n",
    "        \n",
    "        fetch_response = httpx.get(\n",
    "            f\"{base_url}/efetch.fcgi\",\n",
    "            params=fetch_params\n",
    "        )\n",
    "        \n",
    "        # XML íŒŒì‹±\n",
    "        root = ET.fromstring(fetch_response.text)\n",
    "        articles = []\n",
    "        \n",
    "        for article in root.findall(\".//PubmedArticle\"):\n",
    "            title = article.find(\".//ArticleTitle\")\n",
    "            abstract = article.find(\".//AbstractText\")\n",
    "            pmid = article.find(\".//PMID\")\n",
    "            year = article.find(\".//PubDate/Year\")\n",
    "            \n",
    "            articles.append({\n",
    "                \"pmid\": pmid.text if pmid is not None else \"\",\n",
    "                \"title\": title.text if title is not None else \"\",\n",
    "                \"abstract\": abstract.text[:500] if abstract is not None else \"\",\n",
    "                \"year\": year.text if year is not None else \"\"\n",
    "            })\n",
    "        \n",
    "        return articles\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PubMed ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "# =========================\n",
    "# 2. ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬ (PostgreSQL)\n",
    "# =========================\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • - '02_internal_dbs.ipynb' ë…¸íŠ¸ë¶ì˜ ì²«ë²ˆì§¸ cellì˜ ì„¤ì •ìœ¼ë¡œ ë™ì¼í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°\n",
    "DB_CONFIG = {\n",
    "    \"host\": None,\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"agentdb\",\n",
    "    \"user\": \"dbadmin\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"connect_timeout\": 10\n",
    "}\n",
    "\n",
    "@tool\n",
    "def query_clinical_database(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"ë‚´ë¶€ PostgreSQL ì„ìƒ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¿¼ë¦¬í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: SQL ì¿¼ë¦¬ ë˜ëŠ” ìì—°ì–´ ì§ˆë¬¸\n",
    "    \n",
    "    Returns:\n",
    "        ì¿¼ë¦¬ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        with conn.cursor() as cursor:\n",
    "            # SQL ì¿¼ë¦¬ì¸ì§€ í™•ì¸\n",
    "            if query.strip().upper().startswith(('SELECT', 'WITH')):\n",
    "                cursor.execute(query)\n",
    "            else:\n",
    "                # ìì—°ì–´ë¥¼ ê°„ë‹¨í•œ SQLë¡œ ë³€í™˜ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ NLP í•„ìš”)\n",
    "                cursor.execute(\n",
    "                    \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\"\n",
    "                )\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"data\": results[:100],  # ê²°ê³¼ ì œí•œ\n",
    "                \"count\": len(results)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database ì¿¼ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "@tool\n",
    "def get_database_schema() -> Dict[str, Any]:\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "    \n",
    "    Returns:\n",
    "        í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT\n",
    "                    c.relname AS table_name,\n",
    "                    a.attname AS column_name,\n",
    "                    pg_catalog.format_type(a.atttypid, a.atttypmod) AS data_type\n",
    "                FROM pg_catalog.pg_attribute a\n",
    "                JOIN pg_catalog.pg_class c ON a.attrelid = c.oid\n",
    "                JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid\n",
    "                WHERE a.attnum > 0 AND NOT a.attisdropped\n",
    "                    AND n.nspname = 'public'\n",
    "                    AND c.relkind = 'r'\n",
    "                ORDER BY c.relname, a.attnum;\n",
    "            \"\"\")\n",
    "            \n",
    "            rows = cursor.fetchall()\n",
    "            tables = defaultdict(list)\n",
    "            for table_name, column_name, data_type in rows:\n",
    "                tables[table_name].append({\n",
    "                    \"column\": column_name,\n",
    "                    \"type\": data_type\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"schema\": dict(tables)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "# =========================\n",
    "# 3. ë‹¨ë°±ì§ˆ ì„¤ê³„ ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def trigger_protein_optimization(\n",
    "    seed_sequence: str,\n",
    "    runName: Optional[str] = None,\n",
    "    outputUri: Optional[str] = None,\n",
    "    esm_model_files: Optional[str] = None,\n",
    "    onehotcnn_model_files: Optional[str] = None,\n",
    "    output_type: Optional[str] = None,\n",
    "    parallel_chains: Optional[str] = None,\n",
    "    n_steps: Optional[str] = None,\n",
    "    max_mutations: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Trigger the AWS HealthOmics workflow for protein design optimization\n",
    "    \n",
    "    Args:\n",
    "        seed_sequence: The input protein sequence to optimize\n",
    "        runName: Name for the workflow run (optional)\n",
    "        outputUri: S3 URI where the workflow outputs will be stored (optional)\n",
    "        esm_model_files: S3 directory storing ESM pLM model files (optional)\n",
    "        onehotcnn_model_files: S3 directory storing Onehot CNN predictor model files (optional)\n",
    "        output_type: Output type, can be 'best', 'last', or 'all' variants (optional)\n",
    "        parallel_chains: Number of MCMC chains to run in parallel (optional)\n",
    "        n_steps: Number of MCMC steps per chain (optional)\n",
    "        max_mutations: Maximum number of mutations per variant (optional)\n",
    "    \n",
    "    Returns:\n",
    "        String with workflow run information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ê³„ì •ê³¼ ì§€ì—­ ì •ë³´ ì¶”ì¶œ\n",
    "        sts_client = boto3.client('sts')\n",
    "        account_id = sts_client.get_caller_identity()['Account']\n",
    "        region = boto3.Session().region_name\n",
    "        \n",
    "        # ì›Œí¬í”Œë¡œìš° íŒŒë¼ë¯¸í„° ì„¤ì • - '04_protein_design_strands.ipynb' ë…¸íŠ¸ë¶ì˜ 6ë²ˆì§¸ cellì—ì„œ ì¶œë ¥ë˜ëŠ” ì„¤ì •ìœ¼ë¡œ ì…ë ¥\n",
    "        workflow_id = None\n",
    "        role_arn = None\n",
    "        s3_bucket = None\n",
    "        container_image = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/protein-design-evoprotgrad:latest\"\n",
    "\n",
    "        # ì„œì—´ ê²€ì¦\n",
    "        valid_amino_acids = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "        if not all(aa in valid_amino_acids for aa in seed_sequence.upper()):\n",
    "            return {\"error\": \"Invalid amino acid seed_sequence\"}\n",
    "                \n",
    "        run_name = f\"workflow-run-{uuid.uuid4().hex[:8]}\"\n",
    "        \n",
    "        # Use default S3 output location if not provided\n",
    "        output_uri = f\"s3://{s3_bucket}/outputs/{run_name}/\"\n",
    "        \n",
    "        # Get all workflow parameters with defaults\n",
    "        esm_files = f\"s3://{s3_bucket}/models/esm2_t33_650M_UR50D/\"\n",
    "        out_type = output_type or \"all\"\n",
    "        \n",
    "        # Convert numeric parameters\n",
    "        try:\n",
    "            p_chains = int(parallel_chains) if parallel_chains else 10\n",
    "        except (ValueError, TypeError):\n",
    "            p_chains = 10\n",
    "            \n",
    "        try:\n",
    "            steps = int(n_steps) if n_steps else 100\n",
    "        except (ValueError, TypeError):\n",
    "            steps = 100\n",
    "            \n",
    "        try:\n",
    "            mutations = int(max_mutations) if max_mutations else 15\n",
    "        except (ValueError, TypeError):\n",
    "            mutations = 15\n",
    "        \n",
    "        # Prepare workflow parameters\n",
    "        workflow_parameters = {\n",
    "            \"container_image\": container_image,\n",
    "            \"seed_sequence\": seed_sequence.upper(),\n",
    "            \"esm_model_files\": esm_files  # Pass S3 path to workflow\n",
    "        }\n",
    "        \n",
    "        # Add optional parameters\n",
    "        if onehotcnn_model_files:\n",
    "            workflow_parameters[\"onehotcnn_model_files\"] = onehotcnn_model_files\n",
    "            \n",
    "        workflow_parameters[\"output_type\"] = out_type\n",
    "        workflow_parameters[\"parallel_chains\"] = p_chains\n",
    "        workflow_parameters[\"n_steps\"] = steps\n",
    "        workflow_parameters[\"max_mutations\"] = mutations\n",
    "        \n",
    "        # Start the workflow run\n",
    "        response = omics_client.start_run(\n",
    "            workflowId=workflow_id,\n",
    "            name=run_name,\n",
    "            parameters=workflow_parameters,\n",
    "            outputUri=output_uri,\n",
    "            roleArn=role_arn\n",
    "        )\n",
    "        \n",
    "        # Format response\n",
    "        result = f\"\"\"Successfully started protein optimization workflow.\n",
    "\n",
    "Run ID: {response['id']}\n",
    "Status: {response['status']}\n",
    "Output URI: {output_uri}\n",
    "\n",
    "Optimization parameters:\n",
    "- Seed sequence: {seed_sequence[:20]}... ({len(seed_sequence)} amino acids)\n",
    "- Parallel chains: {p_chains}\n",
    "- Steps per chain: {steps}\n",
    "- Max mutations: {mutations}\n",
    "- Output type: {out_type}\n",
    "\n",
    "You can check the status later by asking me to 'monitor workflow run {response['id']}'\"\"\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def monitor_protein_workflow(runId: str,\n",
    "    waitForCompletion: Optional[bool] = None,\n",
    "    pollIntervalSeconds: Optional[int] = None,\n",
    "    maxWaitTimeMinutes: Optional[int] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Monitor the status of a running AWS HealthOmics workflow and retrieve results when complete\n",
    "    \n",
    "    Args:\n",
    "        runId: The ID of the HealthOmics workflow run to monitor\n",
    "        waitForCompletion: Whether to wait for the workflow to complete before returning (optional, defaults to True)\n",
    "        pollIntervalSeconds: Time between status checks in seconds (optional, defaults to 30)\n",
    "        maxWaitTimeMinutes: Maximum time to wait for workflow completion in minutes (optional, defaults to 30)\n",
    "    \n",
    "    Returns:\n",
    "        String with workflow status and results if completed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize clients\n",
    "        omics_client = boto3.client('omics')\n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        if not runId:\n",
    "            return \"Error: runId parameter is required\"\n",
    "        \n",
    "        # Get workflow run status\n",
    "        run_response = omics_client.get_run(id=runId)\n",
    "        status = run_response.get('status')\n",
    "        \n",
    "        # Format response with current status\n",
    "        response_text = f\"Run ID: {runId}\\nCurrent Status: {status}\\n\"\n",
    "        if run_response.get('name'):\n",
    "            response_text += f\"Run Name: {run_response.get('name')}\\n\"\n",
    "        if run_response.get('startTime'):\n",
    "            response_text += f\"Start Time: {run_response.get('startTime').isoformat()}\\n\"\n",
    "        \n",
    "        if status == 'COMPLETED':\n",
    "            # Include results if completed\n",
    "            response_text += _get_run_results(run_response, s3_client)\n",
    "        elif status == 'FAILED':\n",
    "            response_text += f\"Failed with message: {run_response.get('statusMessage')}\\n\"\n",
    "        else:\n",
    "            response_text += \"\\nThe workflow is still running. You can check again later with the same run ID.\\n\"\n",
    "            response_text += f\"To check again, ask me to 'monitor workflow run {runId}'.\"\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error monitoring workflow: {str(e)}\"\n",
    "\n",
    "def _get_run_results(run_response: Dict[str, Any], s3_client) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to retrieve workflow results from S3.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output_text = f\"Completed at: {run_response.get('stopTime').isoformat() if run_response.get('stopTime') else 'Unknown'}\\n\\n\"\n",
    "        \n",
    "        # Get output files\n",
    "        output_uri = run_response.get('outputUri')\n",
    "        if not output_uri:\n",
    "            return output_text + \"No output URI provided.\"\n",
    "            \n",
    "        # Parse the S3 URI\n",
    "        parsed_uri = urlparse(output_uri)\n",
    "        bucket = parsed_uri.netloc\n",
    "        prefix = parsed_uri.path.lstrip('/')\n",
    "        \n",
    "        # List objects in the output location\n",
    "        try:\n",
    "            s3_response = s3_client.list_objects_v2(\n",
    "                Bucket=bucket,\n",
    "                Prefix=prefix\n",
    "            )\n",
    "            \n",
    "            # Add output files to the response\n",
    "            output_files = []\n",
    "            for obj in s3_response.get('Contents', []):\n",
    "                if obj['Key'].endswith('.json') or obj['Key'].endswith('.txt') or obj['Key'].endswith('.csv'):\n",
    "                    file_key = obj['Key']\n",
    "                    file_size = obj['Size']\n",
    "                    \n",
    "                    # For small text files, include the content\n",
    "                    if file_size < 10240 and (file_key.endswith('.json') or file_key.endswith('.txt') or file_key.endswith('.csv')):\n",
    "                        try:\n",
    "                            file_obj = s3_client.get_object(Bucket=bucket, Key=file_key)\n",
    "                            file_content = file_obj['Body'].read().decode('utf-8')\n",
    "                            \n",
    "                            output_files.append({\n",
    "                                'key': file_key,\n",
    "                                'size': file_size,\n",
    "                                'content': file_content\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            output_files.append({\n",
    "                                'key': file_key,\n",
    "                                'size': file_size,\n",
    "                                'error': str(e)\n",
    "                            })\n",
    "                    else:\n",
    "                        output_files.append({\n",
    "                            'key': file_key,\n",
    "                            'size': file_size,\n",
    "                            'url': f\"s3://{bucket}/{file_key}\"\n",
    "                        })\n",
    "            \n",
    "            if output_files:\n",
    "                output_text += \"Output files:\\n\"\n",
    "                for file in output_files:\n",
    "                    output_text += f\"- {file.get('key')} ({file.get('size')} bytes)\\n\"\n",
    "                    if 'content' in file and file.get('key').endswith('de_results.csv'):\n",
    "                        output_text += f\"Results summary:\\n{file.get('content')[:1000]}...\\n\\n\"\n",
    "            else:\n",
    "                output_text += \"No output files found.\"\n",
    "        except Exception as e:\n",
    "            output_text += f\"Error listing S3 objects: {str(e)}\"\n",
    "            \n",
    "        return output_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving results: {str(e)}\"\n",
    "        \n",
    "# =========================\n",
    "# 4. Knowledge Base ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def query_knowledge_base(query: str, kb_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Amazon Bedrock Knowledge Baseë¥¼ ì¿¼ë¦¬í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        kb_id: Knowledge Base ID (ì„ íƒ)\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # KB íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "        kb_id = None\n",
    "        if not kb_id:\n",
    "            return {\"error\": \"Knowledge Base ID not configured\"}\n",
    "        \n",
    "        response = knowledge_base_client.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={'text': query},\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': 5\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for item in response.get('retrievalResults', []):\n",
    "            results.append({\n",
    "                \"content\": item['content']['text'],\n",
    "                \"score\": item.get('score', 0)\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"results\": results\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Knowledge Base ì¿¼ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# =========================\n",
    "# ë©”ì¸ Agent ì„¤ì •\n",
    "# =========================\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì •\n",
    "model_id = \"global.anthropic.claude-sonnet-4-5-20250929-v1:0\"\n",
    "model = BedrockModel(model_id=model_id)\n",
    "\n",
    "# í†µí•© Agent ìƒì„±\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        # ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤\n",
    "        search_arxiv,\n",
    "        search_compound,\n",
    "        search_pubmed,\n",
    "        # ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤\n",
    "        query_clinical_database,\n",
    "        get_database_schema,\n",
    "        # ë‹¨ë°±ì§ˆ ì„¤ê³„\n",
    "        trigger_protein_optimization,\n",
    "        monitor_protein_workflow,\n",
    "        # Knowledge Base\n",
    "        query_knowledge_base\n",
    "    ],\n",
    "    system_prompt=\"\"\"ë‹¹ì‹ ì€ ì¢…í•©ì ì¸ ìƒëª…ê³¼í•™ ì—°êµ¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "    1. **ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: Arxiv, ChEMBL, PubMedë¥¼ í†µí•œ ë¬¸í—Œ ë° í™”í•©ë¬¼ ê²€ìƒ‰\n",
    "    2. **ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL ì„ìƒ/ìœ ì „ì²´ ë°ì´í„° ë¶„ì„\n",
    "    3. **ë‹¨ë°±ì§ˆ ì„¤ê³„**: AWS HealthOmicsë¥¼ í†µí•œ ë‹¨ë°±ì§ˆ ìµœì í™”\n",
    "    4. **Knowledge Base**: ì¡°ì§ ë‚´ë¶€ ì§€ì‹ ê²€ìƒ‰\n",
    "    \n",
    "    ì—°êµ¬ìì˜ ì§ˆë¬¸ì— ëŒ€í•´:\n",
    "    - ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©\n",
    "    - ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í¬ê´„ì ì¸ ë‹µë³€ ì œê³µ\n",
    "    - ê³¼í•™ì  ì •í™•ì„± ìœ ì§€\n",
    "    - í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ë‹µ\"\"\"\n",
    ")\n",
    "\n",
    "# AgentCore ì—”íŠ¸ë¦¬í¬ì¸íŠ¸\n",
    "@app.entrypoint\n",
    "def integrated_research_agent(payload: Dict[str, Any]) -> str:\n",
    "    \"\"\"AgentCore ì—”íŠ¸ë¦¬í¬ì¸íŠ¸\"\"\"\n",
    "    user_input = payload.get(\"prompt\", \"\")\n",
    "    logger.info(f\"Processing request: {user_input}\")\n",
    "    \n",
    "    try:\n",
    "        response = agent(user_input)\n",
    "        return response.message['content'][0]['text']\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        return f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Requirements íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:06.475292Z",
     "iopub.status.busy": "2025-09-29T09:20:06.475007Z",
     "iopub.status.idle": "2025-09-29T09:20:06.480428Z",
     "shell.execute_reply": "2025-09-29T09:20:06.479653Z",
     "shell.execute_reply.started": "2025-09-29T09:20:06.475259Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "strands-agents>=0.5.0\n",
    "strands-agents-tools>=0.1.0\n",
    "boto3>=1.34.0\n",
    "mcp>=0.1.0\n",
    "arxiv>=2.1.0\n",
    "chembl-webresource-client>=0.10.8\n",
    "python-dateutil>=2.8.2\n",
    "python-dotenv>=1.0.0\n",
    "httpx>=0.24.0\n",
    "defusedxml>=0.7.1\n",
    "psycopg2-binary>=2.9.0\n",
    "bedrock-agentcore-starter-toolkit\n",
    "pubmedmcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:07.101802Z",
     "iopub.status.busy": "2025-09-29T09:20:07.101537Z",
     "iopub.status.idle": "2025-09-29T09:20:07.266805Z",
     "shell.execute_reply": "2025-09-29T09:20:07.265803Z",
     "shell.execute_reply.started": "2025-09-29T09:20:07.101781Z"
    }
   },
   "outputs": [],
   "source": [
    "# AWS ì„¸ì…˜ ì„¤ì •\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AgentCore Runtime êµ¬ì„± ë° ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:08.049606Z",
     "iopub.status.busy": "2025-09-29T09:20:08.049338Z",
     "iopub.status.idle": "2025-09-29T09:20:08.152424Z",
     "shell.execute_reply": "2025-09-29T09:20:08.151484Z",
     "shell.execute_reply.started": "2025-09-29T09:20:08.049586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Runtime ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "agentcore_runtime = Runtime()\n",
    "agent_name = \"integrated_lifescience_research_agent\"\n",
    "\n",
    "# Runtime ì„¤ì •\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"integrated_research_agent.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agent ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:09.104620Z",
     "iopub.status.busy": "2025-09-29T09:20:09.104341Z",
     "iopub.status.idle": "2025-09-29T09:20:53.265358Z",
     "shell.execute_reply": "2025-09-29T09:20:53.264700Z",
     "shell.execute_reply.started": "2025-09-29T09:20:09.104599Z"
    }
   },
   "outputs": [],
   "source": [
    "# AgentCore Runtimeì— ë°°í¬\n",
    "print(\"ğŸš€ í†µí•© Agentë¥¼ AgentCore Runtimeì— ë°°í¬ ì¤‘...\")\n",
    "launch_result = agentcore_runtime.launch()\n",
    "\n",
    "print(f\"\\nâœ… ë°°í¬ ì™„ë£Œ!\")\n",
    "print(f\"Agent ARN: {launch_result.agent_arn}\")\n",
    "print(f\"ECR URI: {launch_result.ecr_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. ì •ì±… ë³µì‚¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "paginator = iam.get_paginator('list_roles')\n",
    "\n",
    "role_prefix = 'AmazonBedrockAgentCoreSDKRuntime'\n",
    "\n",
    "# SageMaker Role ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
    "import sagemaker\n",
    "sagemaker_role_arn = sagemaker.get_execution_role()\n",
    "sagemaker_role_name = sagemaker_role_arn.split('/')[-1]\n",
    "\n",
    "for page in paginator.paginate():\n",
    "    for role in page['Roles']:\n",
    "        if role['RoleName'].startswith(role_prefix):\n",
    "            target_role_name = role['RoleName']\n",
    "            # 1. ê´€ë¦¬í˜• ì •ì±… ë³µì‚¬\n",
    "            attached_policies = iam.list_attached_role_policies(RoleName=sagemaker_role_name)\n",
    "            for policy in attached_policies['AttachedPolicies']:\n",
    "                policy_arn = policy['PolicyArn']\n",
    "                print(f\"Attaching managed policy: {policy['PolicyName']}\")\n",
    "                iam.attach_role_policy(\n",
    "                    RoleName=target_role_name,\n",
    "                    PolicyArn=policy_arn\n",
    "                )\n",
    "            \n",
    "            # 2. ì¸ë¼ì¸ ì •ì±… ë³µì‚¬\n",
    "            inline_policies = iam.list_role_policies(RoleName=sagemaker_role_name)\n",
    "            for policy_name in inline_policies['PolicyNames']:\n",
    "                print(f\"Copying inline policy: {policy_name}\")\n",
    "                \n",
    "                # ì •ì±… ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "                policy_doc = iam.get_role_policy(\n",
    "                    RoleName=sagemaker_role_name,\n",
    "                    PolicyName=policy_name\n",
    "                )\n",
    "                \n",
    "                # ëŒ€ìƒ roleì— ì¸ë¼ì¸ ì •ì±… ì¶”ê°€\n",
    "                iam.put_role_policy(\n",
    "                    RoleName=target_role_name,\n",
    "                    PolicyName=policy_name,\n",
    "                    PolicyDocument=json.dumps(policy_doc['PolicyDocument'])\n",
    "                )\n",
    "            \n",
    "            print(\"ëª¨ë“  ì •ì±… ë³µì‚¬ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ë°°í¬ ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:53.266659Z",
     "iopub.status.busy": "2025-09-29T09:20:53.266340Z",
     "iopub.status.idle": "2025-09-29T09:20:53.509219Z",
     "shell.execute_reply": "2025-09-29T09:20:53.508589Z",
     "shell.execute_reply.started": "2025-09-29T09:20:53.266628Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# ë°°í¬ ìƒíƒœ í™•ì¸\n",
    "print(\"â³ Agent ìƒíƒœ í™•ì¸ ì¤‘...\")\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(f\"ìƒíƒœ: {status}\")\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ìƒíƒœ: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í†µí•© Agent í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ í†µí•© Agentë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 1: ë¬¸í—Œ ê²€ìƒ‰ í†µí•©\n",
    "query1 = \"\"\"COVID-19 ë°±ì‹ ê³¼ ê´€ë ¨ëœ ìµœì‹  ì—°êµ¬ë¥¼ ì¡°ì‚¬í•´ì£¼ì„¸ìš”. \n",
    "Arxivì™€ PubMedì—ì„œ ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ê³ , ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"ğŸ“š í…ŒìŠ¤íŠ¸ 1: ë¬¸í—Œ ê²€ìƒ‰ í†µí•©\")\n",
    "print(f\"ì§ˆë¬¸: {query1}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response1 = agentcore_runtime.invoke({\"prompt\": query1})\n",
    "if 'response' in response1:\n",
    "    response_text = response1['response'][0]\n",
    "    if isinstance(response_text, bytes):\n",
    "        response_text = response_text.decode('utf-8', errors='ignore')\n",
    "    print(f\"ì‘ë‹µ:\\n{response_text}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 ë‚´ë¶€ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:21:32.182362Z",
     "iopub.status.busy": "2025-09-29T09:21:32.182083Z",
     "iopub.status.idle": "2025-09-29T09:21:42.248432Z",
     "shell.execute_reply": "2025-09-29T09:21:42.247739Z",
     "shell.execute_reply.started": "2025-09-29T09:21:32.182340Z"
    }
   },
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: í™”í•©ë¬¼ ì •ë³´\n",
    "query2 = \"\"\"ë°ì´í„°ë² ì´ìŠ¤ì— ì–´ë–¤ í…Œì´ë¸”ë“¤ì´ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ 3: ì‚¬ë‚´ ë°ì´í„°ë² ì´ìŠ¤ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(f\"ì§ˆë¬¸: {query2}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response2 = agentcore_runtime.invoke({\"prompt\": query2})\n",
    "if 'response' in response2:\n",
    "    response_text = response2['response'][0]\n",
    "    if isinstance(response_text, bytes):\n",
    "        response_text = response_text.decode('utf-8', errors='ignore')\n",
    "    print(f\"ì‘ë‹µ:\\n{response_text}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 ë‹¨ë°±ì§ˆ ì„¤ê³„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 3: ë‹¨ë°±ì§ˆ ìµœì í™”\n",
    "test_sequence = \"EVQLVETGGGLVQPGGSLRLSCAASGFTLNSYGISWVRQAPGKGPEWVS\"\n",
    "query3 = f\"\"\"ë‹¤ìŒ í•­ì²´ ì„œì—´ì„ ìµœì í™”í•´ì£¼ì„¸ìš”: {test_sequence}\n",
    "ì•ˆì •ì„±ê³¼ ê²°í•© ì¹œí™”ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ìµœì í™”í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"ğŸ§¬ í…ŒìŠ¤íŠ¸ 3: ë‹¨ë°±ì§ˆ ì„¤ê³„\")\n",
    "print(f\"ì§ˆë¬¸: {query3}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response3 = agentcore_runtime.invoke({\"prompt\": query3})\n",
    "if 'response' in response3:\n",
    "  # ë°”ì´íŠ¸ ë¬¸ìì—´ì„ UTF-8ë¡œ ë””ì½”ë”©\n",
    "  response_text = response3['response'][0]\n",
    "  if isinstance(response_text, bytes):\n",
    "      response_text = response_text.decode('utf-8', errors='ignore')\n",
    "  print(f\"ì‘ë‹µ:\\n{response_text}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 ë³µí•© ì—°êµ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 4: ë³µí•© ì—°êµ¬ ì§ˆë¬¸\n",
    "query4 = \"\"\"ì•Œì¸ í•˜ì´ë¨¸ë³‘ ì¹˜ë£Œë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì— ëŒ€í•´ ì¢…í•©ì ìœ¼ë¡œ ì¡°ì‚¬í•´ì£¼ì„¸ìš”:\n",
    "1. ìµœì‹  ì—°êµ¬ ë…¼ë¬¸ (Arxiv, PubMed)\n",
    "2. í˜„ì¬ ì„ìƒì‹œí—˜ ì¤‘ì¸ ì•½ë¬¼ (ChEMBL)\n",
    "3. ìš°ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ê´€ë ¨ í™˜ì ë°ì´í„°\n",
    "4. íƒ€ìš° ë‹¨ë°±ì§ˆ ì‘ì§‘ ì–µì œë¥¼ ìœ„í•œ í©íƒ€ì´ë“œ ì„¤ê³„ ê°€ëŠ¥ì„±\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ”¬ í…ŒìŠ¤íŠ¸ 4: ë³µí•© ì—°êµ¬ ì§ˆë¬¸\")\n",
    "print(f\"ì§ˆë¬¸: {query4}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response4 = agentcore_runtime.invoke({\"prompt\": query4})\n",
    "if 'response' in response4:\n",
    "    response_text = response4['response'][0]\n",
    "    if isinstance(response_text, bytes):\n",
    "        response_text = response_text.decode('utf-8', errors='ignore')\n",
    "    print(f\"ì‘ë‹µ:\\n{response_text}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì •ë¦¬ (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Runtime ì‚­ì œ (í•„ìš”ì‹œì—ë§Œ ì‹¤í–‰)\n",
    "# ì£¼ì˜: ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ ë°°í¬ëœ Agentê°€ ì‚­ì œë©ë‹ˆë‹¤!\n",
    "\n",
    "# cleanup = input(\"ì •ë§ë¡œ Agentë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): \")\n",
    "# if cleanup.lower() == 'yes':\n",
    "#     agentcore_control_client = boto3.client(\n",
    "#         'bedrock-agentcore-control',\n",
    "#         region_name=region\n",
    "#     )\n",
    "#     \n",
    "#     ecr_client = boto3.client('ecr', region_name=region)\n",
    "#     \n",
    "#     try:\n",
    "#         # Runtime ì‚­ì œ\n",
    "#         runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "#             agentRuntimeId=launch_result.agent_id\n",
    "#         )\n",
    "#         \n",
    "#         # ECR ë¦¬í¬ì§€í† ë¦¬ ì‚­ì œ\n",
    "#         ecr_response = ecr_client.delete_repository(\n",
    "#             repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "#             force=True\n",
    "#         )\n",
    "#         \n",
    "#         print(\"âœ… Agent ì •ë¦¬ ì™„ë£Œ\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìš”ì•½\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ëª¨ë“  ìƒëª…ê³¼í•™ ì—°êµ¬ ë„êµ¬ë¥¼ í†µí•©í•œ ì¢…í•© Agentë¥¼ Amazon Bedrock AgentCore Runtimeì— ì„±ê³µì ìœ¼ë¡œ ë°°í¬í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### í†µí•©ëœ ê¸°ëŠ¥:\n",
    "- âœ… **ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: Arxiv, ChEMBL, PubMed ë¬¸í—Œ ë° í™”í•©ë¬¼ ê²€ìƒ‰\n",
    "- âœ… **ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL ì„ìƒ/ìœ ì „ì²´ ë°ì´í„° ë¶„ì„\n",
    "- âœ… **ë‹¨ë°±ì§ˆ ì„¤ê³„**: AWS HealthOmics ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ ìµœì í™”\n",
    "- âœ… **Knowledge Base**: ì¡°ì§ ë‚´ë¶€ ì§€ì‹ ê²€ìƒ‰ ë° í™œìš©\n",
    "\n",
    "### ì£¼ìš” ì„±ê³¼:\n",
    "- ëª¨ë“  ë„êµ¬ë¥¼ í•˜ë‚˜ì˜ Agentë¡œ í†µí•©\n",
    "- ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ ë°°í¬\n",
    "- ì‹¤ì‹œê°„ ì—°êµ¬ ì§ˆë¬¸ ì²˜ë¦¬\n",
    "- ë‹¤ì–‘í•œ ìƒëª…ê³¼í•™ ì—°êµ¬ ì‹œë‚˜ë¦¬ì˜¤ ì§€ì›\n",
    "\n",
    "### í™œìš© ì‹œë‚˜ë¦¬ì˜¤:\n",
    "1. **ì‹ ì•½ ê°œë°œ**: íƒ€ê²Ÿ ë°œêµ´ë¶€í„° ë¦¬ë“œ ìµœì í™”ê¹Œì§€\n",
    "2. **ì •ë°€ ì˜ë£Œ**: í™˜ì ë§ì¶¤í˜• ì¹˜ë£Œ ì „ëµ ìˆ˜ë¦½\n",
    "3. **ë°”ì´ì˜¤ë§ˆì»¤ ë°œêµ´**: ì§„ë‹¨ ë° ì˜ˆí›„ ë§ˆì»¤ ê°œë°œ\n",
    "4. **ë‹¨ë°±ì§ˆ ê³µí•™**: ì¹˜ë£Œìš© í•­ì²´ ë° íš¨ì†Œ ì„¤ê³„\n",
    "5. **ì„ìƒ ì—°êµ¬**: ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì›\n",
    "\n",
    "### í–¥í›„ ë°œì „ ë°©ì•ˆ:\n",
    "1. ì¶”ê°€ ì™¸ë¶€ ë°ì´í„° (KEGG, UniProt ë“±), ë‚´ë¶€ ë°ì´í„° (ë‚´ë¶€ í™”í•©ë¬¼ ì •ë³´), ë„êµ¬ (AlphaFold) ë“± í†µí•© \n",
    "2. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„\n",
    "3. AgentCoreì˜ ë‹¤ë¥¸ ê¸°ëŠ¥ë“¤ (Gateway, Memory, Identity ë“±) ì‚¬ìš©\n",
    "4. ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
