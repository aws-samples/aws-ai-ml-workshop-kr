{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ddaba7-5e6d-4c33-ab5e-8266bedb1129",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint ìƒì„± - KoSimCSE-RoBERTaë¥¼ ì‚¬ìš©í•œ í•œêµ­ì–´ ë¬¸ì¥ ì„ë² ë”©\n",
    "ì´ ì›Œí¬ìƒµì—ì„œëŠ” Hugging Faceì˜ KoSimCSE-RoBERTa ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ ë¬¸ì¥ ì„ë² ë”©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. KoSimCSE-RoBERTaëŠ” í•œêµ­ì–´ ë¬¸ì¥ ì„ë² ë”©ì— íŠ¹í™”ëœ ëª¨ë¸ë¡œ, ë†’ì€ ìˆ˜ì¤€ì˜ ì˜ë¯¸ë¡ ì  í…ìŠ¤íŠ¸ ìœ ì‚¬ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” íŠ¹ì§•:\n",
    "* ì„±ëŠ¥: KoSimCSE-RoBERTaëŠ” ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ì„± í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ìœ ì‚¬ì„± ì§€í‘œì—ì„œ 83% ì´ìƒì˜ ë†’ì€ ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.[1]\n",
    "* ì‚¬ìš© ìš©ì´ì„±: PyTorchì™€ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‰½ê²Œ ë¬¸ì¥ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "* í™œìš© : ì´ ëª¨ë¸ì€ í•œêµ­ì–´ FAQ ë¬¸ì¥ì…‹ì˜ ì„ë² ë”©ì„ ìˆ˜í–‰í•˜ê³ , ìƒì„±í•œ ë¬¸ì¥ ì„ë² ë”© ë²¡í„°ë¥¼ Faiss ì—”ì§„ì„ ì‚¬ìš©í•œ OpenSearchë¥¼ í†µí•´ ê²€ìƒ‰í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•˜ëŠ”ë° ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac560c-2b93-4a2e-9884-3c4ee053ebc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Container: Data Science 3.0 (studio, python 3.10)\n",
    "\n",
    "### Model Ref:\n",
    "- [1]. BM-K/KoSimCSE-roberta\n",
    "    - https://huggingface.co/BM-K/KoSimCSE-roberta\n",
    "Inference Code Ref:    \n",
    "- Huggingface Sagemaker-sdk - Deploy ğŸ¤— Transformers for inference\n",
    "    - https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb\n",
    "- Sentence Embeddings with Hugging Face Transformers, Sentence Transformers and Amazon SageMaker - Custom Inference for creating document embeddings with Hugging Face's Transformers\n",
    "    - https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb6253-d812-4d76-9f01-bfbe5b2d068b",
   "metadata": {},
   "source": [
    "## 1. ë¡œì»¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸: Huggingfaceë¡œë¶€í„° ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”©\n",
    "* ë¡œì»¬ í™˜ê²½ì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°ê³¼ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œí•˜ê¸°\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048655dd-6805-4b83-9d82-e2343fa32f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e521ad9-37e9-428e-9d3e-a92bbca8bc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 01:47:35.757802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 01:47:36.385936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('BM-K/KoSimCSE-roberta')\n",
    "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc640786-1c7a-44c5-98c1-18bc6756f63a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. local test - sentence to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd52f71-0935-40f6-913e-135037dec0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = \"íƒ€ê¸°ê´€OTP ì´ìš©ë“±ë¡ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5919e9-c0ba-4cce-877c-7c33f03f09a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# í…ì„œí”Œë¡œìš°ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í°í™”ëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ê³ , ê·¸ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ê³  ëª¨ë¸ì„ í†µí•´ ì¶œë ¥í•˜ëŠ” ì½”ë“œ\n",
    "#tokenizer() í•¨ìˆ˜ëŠ” í† í°í™”ëœ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ê³  paddingê³¼ truncation ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬. ê·¸ë¦¬ê³  return_tensors ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë°˜í™˜\n",
    "#ëª¨ë¸ì„ í†µí•´ ì…ë ¥ë°›ì€ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ê³  return_dict ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "inputs = tokenizer(sample, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "embeddings, _ = model(**inputs, return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c80d87d-533a-4ca3-b0b6-920a63705156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sentence: \n",
      " íƒ€ê¸°ê´€OTP ì´ìš©ë“±ë¡ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”\n",
      "Size of the Embedding Vector:  768\n",
      "First 10 Elements of the Embedding Vector (Total Elements: 768): \n",
      " tensor([ 0.7232, -1.1831,  0.2413,  0.4354, -0.2338, -0.7395, -0.2876,  0.5807,\n",
      "        -0.1043, -0.3758], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "emb_len = len(embeddings[0][0])\n",
    "print(\"Sample Sentence: \\n\", sample)\n",
    "print(\"Size of the Embedding Vector: \", emb_len)\n",
    "print(f\"First 10 Elements of the Embedding Vector (Total Elements: {emb_len}): \\n\", embeddings[0][0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14efbfb-aced-495e-8fdd-0af2534a4a67",
   "metadata": {},
   "source": [
    "### 2.2 similarity\n",
    "- ì•„ë˜ ì²«ë¬¸ì¥, ë‘ë²ˆì§¸ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•¨\n",
    "- ì•„ë˜ ì²«ë¬¸ì¥, ì„¸ì§¸ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•¨\n",
    "- ìµœì¢…ì ìœ¼ë¡œ ìœ ì‚¬ë„ ìˆ˜ì¹˜ë¥¼ ë¹„êµ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d3f393-468d-4d64-98a1-fd32b0bbcf28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ë‘ ë¬¸ì¥ì˜ ì„ë² ë”© ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ í•¨ìˆ˜\n",
    "#í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ í† í°í™”í•˜ê³  ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ ê³„ì‚°í•œ ë‹¤ìŒ, cal_score í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ë¬¸ì¥ ì‚¬ì´ì˜ ì„ë² ë”© ì ìˆ˜ë¥¼ ê³„ì‚°. \n",
    "#ì¶œë ¥ ê²°ê³¼ëŠ” ë‘ ë¬¸ì¥ ì‚¬ì´ì˜ ì„ë² ë”© ì ìˆ˜\n",
    "# ì²« ê¸°ì¤€ë¬¸ì¥ê³¼ ë‘ë²ˆì§¸, ì„¸ë²ˆì§¸ ë¬¸ì¥ê³¼ì˜ ìœ ì‚¬ë„ \n",
    "def show_embedding_score(tokenizer, model, sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    embeddings, _ = model(**inputs, return_dict=False)\n",
    "\n",
    "    score01 = cal_score(embeddings[0][0], embeddings[1][0])\n",
    "    score02 = cal_score(embeddings[0][0], embeddings[2][0])\n",
    "\n",
    "    print(score01, score02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "444a2499-4757-4b8d-a0c8-fac863e16eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ì´ í•¨ìˆ˜ëŠ” ë‘ ê°œì˜ ë²¡í„° a, bë¥¼ ì…ë ¥ë°›ì•„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "#ë²¡í„° a, bì˜ ì°¨ì›ì´ 1ì´ë¼ë©´ unsqueeze í•¨ìˆ˜ë¥¼ í†µí•´ ì°¨ì›ì„ ëŠ˜ë ¤ì¤ë‹ˆë‹¤.\n",
    "#ê·¸ ë‹¤ìŒ ë²¡í„° a, bë¥¼ ê°ê° ì •ê·œí™”í•˜ê³ , ë‘ ë²¡í„°ì˜ ë‚´ì ì„ êµ¬í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ êµ¬í•¨. \n",
    "def cal_score(a, b):\n",
    "    '''\n",
    "    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ êµ¬í•˜ëŠ” í•¨ìˆ˜\n",
    "    '''\n",
    "    if len(a.shape) == 1: a = a.unsqueeze(0)\n",
    "    if len(b.shape) == 1: b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24d64cf-dae6-4b90-92a7-27f74d8c2c70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[94.3926]], grad_fn=<MulBackward0>) tensor([[14.9692]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [sample,\n",
    "             \"íƒ€ê¸°ê´€OTP ë“±ë¡ë°©ë²• ì•Œë ¤ì¤˜ìš”\",\n",
    "             'ì•ˆë…• ì¹œêµ¬ë“¤!']\n",
    "\n",
    "show_embedding_score(tokenizer, model, sentences1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac699c-5d7c-4b5c-ade7-400ca456de32",
   "metadata": {},
   "source": [
    "## 3. SageMaker Endpointì— embedding model ë°°í¬\n",
    "* ë¡œì»¬ì—ì„œì˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ í›„, ë‹¤ìŒ ë‹¨ê³„ëŠ” Amazon SageMakerë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ëª¨ë¸ì„ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°°í¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "* SageMaker Endpointë¥¼ ìƒì„±í•¨ìœ¼ë¡œì¨, ì–´í”Œë¦¬ì¼€ì´ì…˜ ë˜ëŠ” ì„œë¹„ìŠ¤ì—ì„œ API í˜¸ì¶œì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„ë² ë”©ì„ ìƒì„±í•˜ê±°ë‚˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n",
    "* ì´ ê³¼ì •ì€ ëª¨ë¸ì˜ í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì„ ë†’ì´ë©°, ë” í° ë°ì´í„°ì…‹ì— ëŒ€í•œ ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ë³´ì¥í•©ë‹ˆë‹¤. SageMakerëŠ” ìë™ìœ¼ë¡œ ëª¨ë¸ì„ ë¡œë“œ ë° ì„œë¹™í•˜ê³ , í•„ìš”ì— ë”°ë¼ ìë™ í™•ì¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "* ì´ ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ë©´, ì„ë² ë”© ëª¨ë¸ì€ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75689e58-4a9e-45e2-aa5c-81371a5c58bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from datetime import datetime\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36053feb-7020-48aa-aeb8-c2c0ee3c9d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::143656149352:role/service-role/AmazonSageMaker-ExecutionRole-20220317T150353\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c9180-6821-4ec0-8ea9-31771abd21ad",
   "metadata": {},
   "source": [
    "### Endpoint ìƒì„± ì‹œ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì„ ì§ì ‘ ë¡œë“œí•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2365ba-5ec9-468f-9adb-07a450821acc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "Deployment is in progress in the background...\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from datetime import datetime\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# Hub Model configuration\n",
    "hub = {\n",
    "  'HF_MODEL_ID': 'BM-K/KoSimCSE-roberta',\n",
    "  'HF_TASK': 'feature-extraction'\n",
    "}\n",
    "\n",
    "# Create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub,\n",
    "   role=role,\n",
    "   transformers_version=\"4.26\",\n",
    "   pytorch_version=\"1.13\",\n",
    "   py_version=\"py39\",\n",
    ")\n",
    "\n",
    "# Generate a unique endpoint name\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "endpoint_name = f\"KoSimCSE-roberta-{time_stamp}\"\n",
    "\n",
    "# Function to deploy the model\n",
    "def deploy_model():\n",
    "    predictor = huggingface_model.deploy(\n",
    "       initial_instance_count=1,\n",
    "       endpoint_name=endpoint_name,\n",
    "       instance_type=\"ml.g5.2xlarge\"\n",
    "    )\n",
    "    print(f\"Endpoint created: {endpoint_name}\")\n",
    "\n",
    "# Create a thread to run the deploy function in the background\n",
    "deploy_thread = threading.Thread(target=deploy_model)\n",
    "\n",
    "# Start the thread\n",
    "deploy_thread.start()\n",
    "\n",
    "# Optional: If you want to wait for the thread to complete\n",
    "# deploy_thread.join()\n",
    "\n",
    "print(\"Deployment is in progress in the background...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1dec2d3-47f7-484b-ba78-2478ca644722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b> [SageMaker LLM Serving] <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/KoSimCSE-roberta-2023-09-19-01-47-48\">Check Endpoint Status</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import display, HTML\n",
    "def make_console_link(region, endpoint_name, task='[SageMaker LLM Serving]'):\n",
    "    endpoint_link = f'<b> {task} <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\">Check Endpoint Status</a></b>'   \n",
    "    return endpoint_link\n",
    "\n",
    "def describe_endpoint(endpoint_name):\n",
    "    '''\n",
    "    ì—”ë“œí°ì¸íŠ¸ ìƒì„± ìœ ë¬´ë¥¼ í™•ì¸. ìƒì„± ì¤‘ì´ë©´ ê¸°ë‹¤ë¦¼.\n",
    "    '''\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    while(True):\n",
    "        response = sm_client.describe_endpoint(\n",
    "            EndpointName= endpoint_name\n",
    "        )    \n",
    "        status = response['EndpointStatus']\n",
    "        if status == 'Creating':\n",
    "            print(\"Endpoint is \", status)\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            print(\"Endpoint is \", status)\n",
    "            break\n",
    "\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "\n",
    "endpoint_link = make_console_link(region, endpoint_name)\n",
    "display(HTML(endpoint_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c73a4e-1067-48a0-be0c-50b551a20a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint is  Creating\n",
      "--Endpoint is  Creating\n",
      "--Endpoint is  Creating\n",
      "--Endpoint is  Creating\n",
      "--Endpoint is  Creating\n",
      "--Endpoint is  InService\n",
      "CPU times: user 163 ms, sys: 4.61 ms, total: 168 ms\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "describe_endpoint(endpoint_name)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62559a-4357-4f2e-bde9-bb3ec2fb11fe",
   "metadata": {},
   "source": [
    "# 4. Sagemaker Embedding Model Endpoint ì¶”ë¡  í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657ac8b-75be-4074-871e-286ad26e934a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boto3 invoke_endpoint() ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13fc7a7e-5032-477d-98c1-b43f4f387e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b80e69-b5b2-4b96-a048-793da29b7b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.base_predictor.Predictor at 0x7fb9655bbb20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = Predictor(endpoint_name=endpoint_name)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b353a25-4ddc-4853-abe5-e4f62ffa7769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_endpoint_embedding_with_json_payload(encoded_json, endpoint_name, content_type=\"application/json\"):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=content_type, Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def transform_output(output: bytes) -> str:\n",
    "    response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "    # return response_json\n",
    "    return response_json[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2225426c-02f0-4d41-a092-3d559fb631d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²«ë¬¸ì¥ ì„ë² ë”© ì‚¬ì´ì¦ˆ:  768\n",
      "ë‘ë²ˆì§¸ ë¬¸ì¥ ì„ë² ë”© ì‚¬ì´ì¦ˆ:  768\n"
     ]
    }
   ],
   "source": [
    "sentences2_1 = \"íƒ€ê¸°ê´€OTP ì´ìš©ë“±ë¡ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”\"\n",
    "sentences2_2 = \"ë‹¤ë¥¸ê³³OTP ì‚¬ìš©ë°©ë²• ì•Œë ¤ì¤˜\"\n",
    "\n",
    "payload_2_1 = {\n",
    "    \"inputs\" : sentences2_1\n",
    "}\n",
    "\n",
    "payload_2_2 = {\n",
    "    \"inputs\" : sentences2_2\n",
    "}\n",
    "\n",
    "# ì²«ë²ˆì§¸ ë¬¸ì¥\n",
    "query_response = query_endpoint_embedding_with_json_payload(\n",
    "    json.dumps(payload_2_1).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "emb_1 = transform_output(query_response['Body'])\n",
    "print(\"ì²«ë¬¸ì¥ ì„ë² ë”© ì‚¬ì´ì¦ˆ: \", len(emb_1))\n",
    "\n",
    "# ë‘ë²ˆì§¸ ë¬¸ì¥\n",
    "query_response = query_endpoint_embedding_with_json_payload(\n",
    "    json.dumps(payload_2_2).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    ")\n",
    " \n",
    "emb_2 = transform_output(query_response['Body'])\n",
    "print(\"ë‘ë²ˆì§¸ ë¬¸ì¥ ì„ë² ë”© ì‚¬ì´ì¦ˆ: \", len(emb_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d1264b0-d669-4f90-8ead-0549991eeaf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[74.7897]])\n"
     ]
    }
   ],
   "source": [
    "def show_embedding_score3(emb1, emb2):\n",
    "\n",
    "    embeddings_0 = torch.Tensor(emb1) \n",
    "    embeddings_1 = torch.Tensor(emb2)\n",
    "\n",
    "    score01 = cal_score(embeddings_0, embeddings_1)\n",
    "\n",
    "    print(score01)\n",
    "\n",
    "show_embedding_score3(emb_1, emb_2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53824dd-583d-42d5-ae10-e313be6b92b6",
   "metadata": {},
   "source": [
    "## 5. Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e651cda-de59-44b3-a2b2-c5c40299a68d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Endpoint created: KoSimCSE-roberta-2023-09-19-01-47-48\n"
     ]
    }
   ],
   "source": [
    "class clean_up():\n",
    "    \n",
    "    def __init__(self, ):    \n",
    "        pass\n",
    "    \n",
    "    def delete_endpoint(self, client, endpoint_name ,is_del_model=True):\n",
    "        \n",
    "        response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        EndpointConfigName = response['EndpointConfigName']\n",
    "\n",
    "        response = client.describe_endpoint_config(EndpointConfigName=EndpointConfigName)\n",
    "        model_name = response['ProductionVariants'][0]['ModelName']    \n",
    "\n",
    "        if is_del_model: # ëª¨ë¸ë„ ì‚­ì œ ì—¬ë¶€ ì„.\n",
    "            client.delete_model(ModelName=model_name)    \n",
    "\n",
    "        client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        client.delete_endpoint_config(EndpointConfigName=EndpointConfigName)    \n",
    "\n",
    "        print(f'--- Deleted model: {model_name}')\n",
    "        print(f'--- Deleted endpoint: {endpoint_name}')\n",
    "        print(f'--- Deleted endpoint_config: {EndpointConfigName}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e66f0602-aaca-4f80-9dba-7536df606fed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name_emb' (str)\n"
     ]
    }
   ],
   "source": [
    "endpoint_name_emb = endpoint_name\n",
    "%store endpoint_name_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d3f59d-eae4-48e0-a6df-47ba4ceadc7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean = clean_up()\n",
    "# sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# ## 2.training \n",
    "# clean.delete_endpoint(sm_client, endpoint_name ,is_del_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250590c-0cc2-4121-8383-9eefbc39c462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
