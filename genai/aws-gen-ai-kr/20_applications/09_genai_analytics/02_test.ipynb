{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4eb837-ef78-4b45-9e2c-dbd81c3b763d",
   "metadata": {},
   "source": [
    "# Text2Chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e755fec-095b-43ce-8b2f-e46fd002dc00",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beee5ec9-5112-4eda-88ab-43a0ef1721a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd7fb1d-710f-4345-92a0-b5a794742afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60864ffe-4fe9-4e08-bb49-9b4ecdb8c7db",
   "metadata": {},
   "source": [
    "## 1. Create Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6705c228-f793-47e9-b2da-ade94f209fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197919c-2fbc-4344-a259-4c34dca45a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a986c0-60fe-4e77-875c-338a138460fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Claude-V2-1': 'anthropic.claude-v2:1',\n",
      " 'Claude-V3-5-Sonnet': 'anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
      " 'Claude-V3-Haiku': 'anthropic.claude-3-haiku-20240307-v1:0',\n",
      " 'Claude-V3-Opus': 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
      " 'Claude-V3-Sonnet': 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
      " 'Cohere-Embeddings-En': 'cohere.embed-english-v3',\n",
      " 'Cohere-Embeddings-Multilingual': 'cohere.embed-multilingual-v3',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Command-Light': 'cohere.command-light-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-Embeddings-V2': 'amazon.titan-embed-text-v2:0',\n",
      " 'Titan-Text-G1': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Express': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Light': 'amazon.titan-text-lite-v1',\n",
      " 'Titan-Text-G1-Premier': 'amazon.titan-text-premier-v1:0'}\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e2368-e195-47e4-b981-80f7e6dc4421",
   "metadata": {},
   "source": [
    "## 2. LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b094dc1-26f9-4dcc-b51a-178edadb407e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.bedrock import bedrock_model\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd05a4a4-0ffc-4e29-b1db-0f28ce6374d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_sonnet = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-Sonnet\"),\n",
    "    bedrock_client=boto3_bedrock,\n",
    "    stream=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    inference_config={\n",
    "        'maxTokens': 1024,\n",
    "        'stopSequences': [\"\\n\\nHuman\"],\n",
    "        'temperature': 0.01,\n",
    "        #'topP': ...,\n",
    "    }\n",
    "    #additional_model_request_fields={\"top_k\": 200}\n",
    ")\n",
    "\n",
    "llm_haiku = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-Haiku\"),\n",
    "    bedrock_client=boto3_bedrock,\n",
    "    stream=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    inference_config={\n",
    "        'maxTokens': 1024,\n",
    "        'stopSequences': [\"\\n\\nHuman\"],\n",
    "        'temperature': 0.01,\n",
    "        #'topP': ...,\n",
    "    }\n",
    "    #additional_model_request_fields={\"top_k\": 200}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bfe3f-bcdb-4b76-bcfe-df9273733e7a",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da51dd14-0656-4515-a162-69496260fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pprint\n",
    "import base64\n",
    "import traceback\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from textwrap import dedent\n",
    "from utils.bedrock import bedrock_utils\n",
    "from typing import TypedDict\n",
    "from src.genai_anaysis import llm_call\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c6f67-b19f-49f6-b809-9afa3633784b",
   "metadata": {},
   "source": [
    "### 3.1 Agent state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b04f8af-ec22-4a11-a468-231dd6c1ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    ask: list[str]\n",
    "    action: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b42e1ca9-7ce8-4e89-bcd4-952be419506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class genai_analyzer():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.llm_sonnet=kwargs[\"llm_sonnet\"]\n",
    "        self.llm_haiku=kwargs[\"llm_haiku\"]\n",
    "        self.df = kwargs[\"df\"]\n",
    "        self.column_info = kwargs[\"column_info\"]\n",
    "        self.state = GraphState\n",
    "\n",
    "        self.llm_caller = llm_call(\n",
    "            llm_sonnet=self.llm_sonnet,\n",
    "            llm_haiku=self.llm_haiku,\n",
    "            verbose=False\n",
    "        ) \n",
    "\n",
    "        self._graph_definition()\n",
    "        self.messages = []\n",
    "        self.img_bytes = \"\"\n",
    "\n",
    "    def _get_string_from_message(self, message):\n",
    "        return message[\"content\"][0][\"text\"]\n",
    "\n",
    "    def _get_message_from_string(self, role, string, img=None):\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": [{\"text\": dedent(string)}]\n",
    "        }\n",
    "        \n",
    "        if img is not None:\n",
    "            img_message = {\n",
    "                \"image\": {\n",
    "                    \"format\": 'png',\n",
    "                    \"source\": {\"bytes\": img}\n",
    "                }\n",
    "            }\n",
    "            message[\"content\"].append(img_message)\n",
    "\n",
    "        return message\n",
    "\n",
    "    def _png_to_bytes(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as image_file:\n",
    "                # 파일을 바이너리 모드로 읽기\n",
    "                binary_data = image_file.read()\n",
    "                \n",
    "                # 바이너리 데이터를 base64로 인코딩\n",
    "                base64_encoded = base64.b64encode(binary_data)\n",
    "                \n",
    "                # bytes 타입을 문자열로 디코딩\n",
    "                base64_string = base64_encoded.decode('utf-8')\n",
    "                \n",
    "                return binary_data, base64_string\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def show_image(base64_string):\n",
    "        try:\n",
    "            # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "            image_data = base64.b64decode(base64_string)\n",
    "            \n",
    "            # 바이너리 데이터를 이미지로 변환\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            \n",
    "            # matplotlib을 사용하여 이미지 표시\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # 축 제거\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")\n",
    "\n",
    "    def get_messages(self, ):\n",
    "        return self.messages\n",
    "        \n",
    "    def _graph_definition(self, **kwargs):\n",
    "\n",
    "        def agent(state):\n",
    "\n",
    "            print(\"---CALL AGENT---\")\n",
    "            ask = state[\"ask\"]\n",
    "\n",
    "            \"\"\"\n",
    "            현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                state (messages): 현재 상태 메시지에 에이전트 응답이 추가된 업데이트된 상태\n",
    "            \"\"\"\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                사용자 메시지를 분석하여 다음 수행 액션을 선택하는 역할\n",
    "                </task>\n",
    "\n",
    "                다음 액션 후보군은 아래와 같음\n",
    "                <action_candidates>\n",
    "                [\"CALL_API\", \"TABLE_QUERY\", \"END\"]\n",
    "                </action_candidates>\n",
    "\n",
    "                각 액션에 대한 설명은 아래와 같음\n",
    "                <action_description>\n",
    "                 - \"CALL_API\": 특정 병원에 대한 정보를 가져 올 수 있는 API\n",
    "                 - \"TABLE_QUERY\": 성형 전 후 이미지에 대한 정보를 가져 오는 경우\n",
    "                 - \"END\": 사용자의 요청이 \"\"CALL_API\" 또는 \"TABLE_QUERY\"로 해결할 수 없는 경우\n",
    "                </action_description>\n",
    "                \n",
    "                <instruction>\n",
    "                1. 수행 액션은 반드시 액션 후보군(action_candidates)중에서 선택하세요.\n",
    "                </instruction>\n",
    "                \n",
    "                <output_format>\n",
    "                JSON 형식으로 다음 형태로 응답하세요. JSON 포멧 외 텍스트는 절대 넣지 마세요.:\n",
    "                {{\n",
    "                  \"target_action\": [\"추출된 앱 이름\"],\n",
    "                  \"desc\": \"action이 선택된 이유\"\n",
    "                }}\n",
    "                </output_format>\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                This is the ask: <ask>{ask}</ask>\n",
    "                '''\n",
    "            )\n",
    "\n",
    "            ## 텍스트로 만들어 놓은 유저 프롬프트에다가 사용자가 입력한 것을 넣어주는 방법입니다.\n",
    "            ## 위 유저 프롬프트를 보면 스크립트를 보면 <ask>{ask}</ask> 되어 있습니다. xml형태는 claude가 그냥 잘 알아먹으라고 한것이고 중요한 것은 {}입니다.\n",
    "            ## python에서 str에 {}를 사용하여 {} 사이에 특정한 string을 넣을 수 있습니다. user_prompts.format({ask=\"요청\"}) 요런 형태로요. \n",
    "            ## context가 dict니까 user_prompts.format(**context) 이렇게 간단하게 쓸 수 있습니다.\n",
    "            ## 이런식으로 json으로 출력된 것을 다음 프롬프트에 입력할 수 있습니다!!\n",
    "            context = {\"ask\": ask}\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "\n",
    "            \n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "            self.messages = messages_updated\n",
    "\n",
    "            results = eval(resp['text']) ## LLM 출력은 JSON 형태를 띈 str 포멧입니다. 따라서 JSON 포멧으로 변경할 필요가 있습니다.\n",
    "            \n",
    "            action = results[\"target_action\"] ## JSON 포멧으로 변경하면 key로 값에 접근 가능합니다.\n",
    "            action = results[\"target_action\"] ## JSON 포멧으로 변경하면 key로 값에 접근 가능합니다.\n",
    "\n",
    "            print (\"\\n JOSN 출력입니다\")\n",
    "            print (results) ## json\n",
    "            print (action)\n",
    "            \n",
    "            return self.state(ask=ask, action=action, prev_node=\"AGENT\") ## JSON 형태의 출력값을 state로 저장해서, 다음 노드에서 꺼내서 사용할 수 있습니.\n",
    "\n",
    "        # langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "        workflow = StateGraph(self.state)\n",
    "\n",
    "        # Todo 를 작성합니다.\n",
    "        workflow.add_node(\"agent\", agent)  # 에이전트 노드를 추가합니다.\n",
    "        workflow.add_edge(\"agent\", END)\n",
    "\n",
    "        # 시작점을 설정합니다.\n",
    "        workflow.set_entry_point(\"agent\")\n",
    "\n",
    "        # 기록을 위한 메모리 저장소를 설정합니다.\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        # 그래프를 컴파일합니다.\n",
    "        self.app = workflow.compile(checkpointer=memory)        \n",
    "        self.config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"Text2Chart\"})\n",
    "\n",
    "    def invoke(self, **kwargs):\n",
    "        \n",
    "        inputs = self.state(ask=kwargs[\"ask\"])\n",
    "        # app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "        for output in self.app.stream(inputs, self.config):\n",
    "            # 출력된 결과에서 키와 값을 순회합니다.\n",
    "            for key, value in output.items():\n",
    "                # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "                pprint.pprint(f\"\\nOutput from node '{key}':\")\n",
    "                pprint.pprint(\"---\")\n",
    "                # 출력 값을 예쁘게 출력합니다.\n",
    "                pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "            # 각 출력 사이에 구분선을 추가합니다.\n",
    "            pprint.pprint(\"\\n---\\n\")\n",
    "    \n",
    "    def show_graph(self, ):\n",
    "        \n",
    "        from IPython.display import Image, display\n",
    "\n",
    "        try:\n",
    "            display(\n",
    "                Image(self.app.get_graph(xray=True).draw_mermaid_png())\n",
    "            )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. \n",
    "            # xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "        except:\n",
    "            # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "            pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b35c6aca-a29e-4272-9130-b01d1d350227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38c901cc-ce6a-48aa-bf66-cf2cdde0a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/app_power_consumption.csv\")\n",
    "column_info = pd.read_csv(\"dataset/column_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24713621-3cb2-4640-b345-4fdf35c9a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm_sonnet=llm_sonnet,\n",
    "    llm_haiku=llm_haiku,\n",
    "    df=df,\n",
    "    column_info=column_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87c2ec8e-81f7-4603-9fd4-5aaade4fe8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyzer.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6efed19-b6de-464c-8932-cb9bb8ceb9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "{\n",
      "  \"target_action\": [\"CALL_API\"],\n",
      "  \"desc\": \"사용자가 가장 손님이 많은 병원에 대해 물어보고 있습니다. 이는 특정 병원에 대한 정보를 요구하는 질문이므로, CALL_API 액션을 통해 병원 정보를 가져오는 것이 적절합니다.\"\n",
      "}\n",
      " JOSN 출력입니다\n",
      "{'target_action': ['CALL_API'], 'desc': '사용자가 가장 손님이 많은 병원에 대해 물어보고 있습니다. 이는 특정 병원에 대한 정보를 요구하는 질문이므로, CALL_API 액션을 통해 병원 정보를 가져오는 것이 적절합니다.'}\n",
      "['CALL_API']\n",
      "\"\\nOutput from node 'agent':\"\n",
      "'---'\n",
      "{'action': ['CALL_API'], 'ask': '가장 손님이 많은 병원이 어디야?'}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"가장 손님이 많은 병원이 어디야?\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
