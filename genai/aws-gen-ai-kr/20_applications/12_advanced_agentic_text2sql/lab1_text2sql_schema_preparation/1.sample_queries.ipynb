{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da7eaba-0251-48d7-87cd-d9980104b836",
   "metadata": {},
   "source": [
    "# Lab. 1-1 Schema Preparation-1\n",
    "\n",
    "이 노트북에서는 아래 그림의 1 / 3 과정을 수행합니다. (2는 불필요하여 생략합니다)\n",
    "\n",
    "복잡한 데이터베이스에서 Text2SQL의 가장 어려운 작업은 쿼리 생성에 필요한 스키마를 선별하는 과정, 즉 Schema Linking 입니다.\n",
    "\n",
    "현실의 기업 환경에서는 테이블/컬럼 이름이 의미를 축약하고 있어서 LLM이 이를 파악하기 힘들거나, 테이블/컬럼이 너무 많아서 모든 목록을 프롬프트에 담아 전달하는 것이 불가능한 경우가 많습니다.\n",
    "\n",
    "이를 해결하기 위해, 우리 DB에 맞춰 스키마 설명 문서를 정제하고, LLM에 필요한 컨텍스트를 선별하여 제공하는 작업이 필요합니다. 이 노트북에서는 스키마 준비 과정을 시뮬레이션 하기 위해, Chinook DB 설명 문서를 활용하겠습니다. 전체 작업 흐름은 아래와 같이 이어갈 예정입니다.\n",
    "\n",
    "![Intro](../images/text2sql/schema-prep-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa1a10-2fa1-4383-8838-3186b39815e8",
   "metadata": {},
   "source": [
    "## Step 0: OpenSearch 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "801cb0f5-8055-442d-814b-9a0cea8b9020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-aws in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.2.6)\n",
      "Requirement already satisfied: boto3>=1.34.131 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (1.35.46)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (0.3.15)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (2.9.2)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.46 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.34.131->langchain-aws) (1.35.46)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.34.131->langchain-aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.34.131->langchain-aws) (0.10.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=2->langchain-aws) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=2->langchain-aws) (2.23.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.46->boto3>=1.34.131->langchain-aws) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.46->boto3>=1.34.131->langchain-aws) (2.2.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-aws) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.0.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (4.6.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.46->boto3>=1.34.131->langchain-aws) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (3.3.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.2.2)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.6 (from langchain-community)\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-community) (0.3.15)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-community) (0.1.139)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-community) (9.0.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.6->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
      "Downloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m150.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Installing collected packages: SQLAlchemy, python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, async-timeout, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.36\n",
      "    Uninstalling SQLAlchemy-2.0.36:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.36\n",
      "Successfully installed SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.5.0 httpx-sse-0.4.0 langchain-0.3.7 langchain-community-0.3.5 langchain-text-splitters-0.3.2 marshmallow-3.23.1 multidict-6.1.0 mypy-extensions-1.0.0 propcache-0.2.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0 yarl-1.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q opensearch-py\n",
    "!pip install langchain-aws\n",
    "!pip install langchain-community\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab1c499-18e0-4fd7-a2d8-e89bb9b4e012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search-chatbot-kevmyung-text2sql-puqfcoozcsspfabblsx3lzh7fe.us-west-2.es.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from libs.ssm import parameter_store\n",
    "\n",
    "pm = parameter_store('us-west-2')\n",
    "domain_endpoint = pm.get_params(key=\"chatbot-opensearch_domain_endpoint\", enc=False)\n",
    "opensearch_domain_endpoint = f\"https://{domain_endpoint}\"\n",
    "opensearch_user_id = pm.get_params(key=\"chatbot-opensearch_user_id\", enc=False)\n",
    "opensearch_user_password = pm.get_params(key=\"chatbot-opensearch_user_password\", enc=True)\n",
    "print(opensearch_domain_endpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385871de-60f4-4930-9ebb-a42f43985283",
   "metadata": {},
   "source": [
    "## Step 1: Schema Description 문서 로드 (위 그림의 `1. Schema Loader`)\n",
    "\n",
    "각 기업에는 Excel / CSV 등으로 스키마 설명 문서가 정의되어 있을 수 있습니다. 이를 Parsing하여 아래의 Schema Description 포맷으로 변경한다고 가정하겠습니다.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"table_name\": {\n",
    "        \"table_desc\": \"Description of the table\",\n",
    "        \"cols\": [\n",
    "            {\n",
    "                \"col\": \"Column Name 1\",\n",
    "                \"col_desc\": \"Description of the column including PK info\"\n",
    "            },\n",
    "            {\n",
    "                \"col\": \"Column Name 2\",\n",
    "                \"col_desc\": \"Description of the column\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "초기 설명 문서에는 테이블의 이름과 테이블에 대한 기본 설명, 컬럼 이름과 컬럼에 대한 설명이 포함되어야 합니다. 기업에 잘 정리된 스키마 설명 문서가 없다면, 아주 기본적인 정보만 제공하고 LLM이 이를 증강하여 초기 설명문서 자체를 생성하도록 할 수도 있습니다. 이를 위한 LLM 호출 스크립트는 다음 [링크](https://github.com/kevmyung/db-schema-loader/blob/main/schema_loader.py)를 참고합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835783d0-5bc3-4bbd-bd16-9cf672270fbf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Album\": {\n",
      "            \"table_desc\": \"Stores album data with unique ID, title, and links to artist via artist ID.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"AlbumId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the album.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Title\",\n",
      "                    \"col_desc\": \"Title of the album.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"ArtistId\",\n",
      "                    \"col_desc\": \"Foreign key that references the artist of the album.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"Artist\": {\n",
      "            \"table_desc\": \"Holds artist information with an ID and name.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"ArtistId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the artist.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Name\",\n",
      "                    \"col_desc\": \"Name of the artist.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"Customer\": {\n",
      "            \"table_desc\": \"Contains customer details and links to their support representative.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"CustomerId\",\n",
      "                    \"col_desc\": \"Primary key, unique customer identifier.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"FirstName\",\n",
      "                    \"col_desc\": \"First name of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"LastName\",\n",
      "                    \"col_desc\": \"Last name of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Company\",\n",
      "                    \"col_desc\": \"Company of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Address\",\n",
      "                    \"col_desc\": \"Address of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"City\",\n",
      "                    \"col_desc\": \"City of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"State\",\n",
      "                    \"col_desc\": \"State of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Country\",\n",
      "                    \"col_desc\": \"Country of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"PostalCode\",\n",
      "                    \"col_desc\": \"Postal code of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Phone\",\n",
      "                    \"col_desc\": \"Phone number of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Fax\",\n",
      "                    \"col_desc\": \"Fax number of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Email\",\n",
      "                    \"col_desc\": \"Email address of the customer.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"SupportRepId\",\n",
      "                    \"col_desc\": \"Foreign key that references the employee who supports this customer.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"Employee\": {\n",
      "            \"table_desc\": \"Stores employee details, including their supervisory chain.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"EmployeeId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"LastName\",\n",
      "                    \"col_desc\": \"Last name of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"FirstName\",\n",
      "                    \"col_desc\": \"First name of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Title\",\n",
      "                    \"col_desc\": \"Job title of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"ReportsTo\",\n",
      "                    \"col_desc\": \"Foreign key that references the supervisor of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"BirthDate\",\n",
      "                    \"col_desc\": \"Birth date of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"HireDate\",\n",
      "                    \"col_desc\": \"Hire date of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Address\",\n",
      "                    \"col_desc\": \"Address of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"City\",\n",
      "                    \"col_desc\": \"City of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"State\",\n",
      "                    \"col_desc\": \"State of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Country\",\n",
      "                    \"col_desc\": \"Country of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"PostalCode\",\n",
      "                    \"col_desc\": \"Postal code of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Phone\",\n",
      "                    \"col_desc\": \"Phone number of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Fax\",\n",
      "                    \"col_desc\": \"Fax number of the employee.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Email\",\n",
      "                    \"col_desc\": \"Email address of the employee.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"Genre\": {\n",
      "            \"table_desc\": \"Catalogs music genres with a unique identifier and name.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"GenreId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the genre.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Name\",\n",
      "                    \"col_desc\": \"Name of the genre.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"Invoice\": {\n",
      "            \"table_desc\": \"Records details of transactions, linked to customers.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"InvoiceId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"CustomerId\",\n",
      "                    \"col_desc\": \"Foreign key that references the customer associated with this invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"InvoiceDate\",\n",
      "                    \"col_desc\": \"Date when the invoice was issued.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"BillingAddress\",\n",
      "                    \"col_desc\": \"Billing address on the invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"BillingCity\",\n",
      "                    \"col_desc\": \"Billing city on the invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"BillingState\",\n",
      "                    \"col_desc\": \"Billing state on the invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"BillingCountry\",\n",
      "                    \"col_desc\": \"Billing country on the invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"BillingPostalCode\",\n",
      "                    \"col_desc\": \"Billing postal code on the invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Total\",\n",
      "                    \"col_desc\": \"Total amount of the invoice.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"InvoiceLine\": {\n",
      "            \"table_desc\": \"Details each line item on an invoice, linked to tracks and invoices.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"InvoiceLineId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the invoice line.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"InvoiceId\",\n",
      "                    \"col_desc\": \"Foreign key that references the associated invoice.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"TrackId\",\n",
      "                    \"col_desc\": \"Foreign key that references the track sold in this invoice line.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"UnitPrice\",\n",
      "                    \"col_desc\": \"Price per unit of the track.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Quantity\",\n",
      "                    \"col_desc\": \"Quantity of the track sold in this invoice line.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"MediaType\": {\n",
      "            \"table_desc\": \"Defines types of media for tracks.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"MediaTypeId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the media type.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Name\",\n",
      "                    \"col_desc\": \"Name of the media type.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"Playlist\": {\n",
      "            \"table_desc\": \"Organizes tracks into playlists.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"PlaylistId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the playlist.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Name\",\n",
      "                    \"col_desc\": \"Name of the playlist.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"PlaylistTrack\": {\n",
      "            \"table_desc\": \"Links tracks to playlists.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"PlaylistId\",\n",
      "                    \"col_desc\": \"Foreign key that identifies the playlist.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"TrackId\",\n",
      "                    \"col_desc\": \"Foreign key that identifies the track on the playlist.\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"Track\": {\n",
      "            \"table_desc\": \"Stores detailed information about music tracks, linked to albums, genres, and media types.\",\n",
      "            \"cols\": [\n",
      "                {\n",
      "                    \"col\": \"TrackId\",\n",
      "                    \"col_desc\": \"Primary key, unique identifier for the track.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Name\",\n",
      "                    \"col_desc\": \"Name of the track.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"AlbumId\",\n",
      "                    \"col_desc\": \"Foreign key that references the album containing this track.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"MediaTypeId\",\n",
      "                    \"col_desc\": \"Foreign key that references the type of media for this track.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"GenreId\",\n",
      "                    \"col_desc\": \"Optional foreign key that references the genre of this track.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Composer\",\n",
      "                    \"col_desc\": \"Composer of the track.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Milliseconds\",\n",
      "                    \"col_desc\": \"Duration of the track in milliseconds.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"Bytes\",\n",
      "                    \"col_desc\": \"Size of the track file in bytes.\"\n",
      "                },\n",
      "                {\n",
      "                    \"col\": \"UnitPrice\",\n",
      "                    \"col_desc\": \"Price per unit of this track.\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = './chinook_schema.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    schema_description = json.load(file)\n",
    "\n",
    "print(json.dumps(schema_description, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197834e-7ee3-4eb4-9398-d2e0d5789d53",
   "metadata": {},
   "source": [
    "### 이제 Schema Description 문서를 활용해 후속 작업을 이어가겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca849b4-8126-4c9d-bafa-af3e7543fa44",
   "metadata": {},
   "source": [
    "## Step 2: SQL2Text 샘플 쿼리 변환 (위 그림의 `3. Query Translator`)\n",
    "\n",
    "Lab 1 / Lab 2에서 언급했듯이, 좋은 샘플 쿼리를 LLM에게 제공하는 것은 쿼리 작성 뿐만 아니라 Schema Linking에도 도움이 됩니다.\n",
    "\n",
    "그러나, 대부분의 기업 환경에서 자주 사용되는 쿼리를 로그로 관리하고 있는 반면, (기존에 Text2SQL을 사용하지 않았기 때문에) 쿼리에 매칭되는 자연어 질문은 없습니다. \n",
    "\n",
    "Step 2에서는 자주 사용하는 쿼리들을 자연어 질문으로 변환하는 SQL2Text 과정을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e40dcac-1073-4a4f-9c68-46944c2ce5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1:\n",
      "SELECT * FROM Artist\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 2:\n",
      "SELECT * FROM Album WHERE ArtistId = (SELECT ArtistId FROM Artist WHERE Name = 'AC/DC')\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 3:\n",
      "SELECT * FROM Track WHERE GenreId = (SELECT GenreId FROM Genre WHERE Name = 'Rock')\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 4:\n",
      "SELECT SUM(Milliseconds) FROM Track\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 5:\n",
      "SELECT * FROM Customer WHERE Country = 'Canada'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 6:\n",
      "SELECT COUNT(*) FROM Track WHERE AlbumId = 5\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 7:\n",
      "SELECT COUNT(*) FROM Invoice\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 8:\n",
      "SELECT * FROM Track WHERE Milliseconds > 300000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 9:\n",
      "SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query 10:\n",
      "SELECT COUNT(*) FROM Employee\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_file = './chinook_sample_queries.sql'\n",
    "\n",
    "with open(sql_file, 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "queries = [query.strip() for query in data.split(';') if query.strip()]\n",
    "\n",
    "for i, query in enumerate(queries, start=1):\n",
    "    print(f\"Query {i}:\\n{query}\\n{'-'*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e58b4f-0b52-4eb1-9d8b-6121cf561aca",
   "metadata": {},
   "source": [
    "쿼리를 해석하기 위해, 각 쿼리에 사용된 테이블/컬럼의 의미를 파악해야 합니다.\n",
    "따라서, 각 쿼리에 사용된 테이블/컬럼 정보를 아래와 같이 추출합니다.\n",
    "```\n",
    "{\n",
    "  \"table\": [\"table1\", \"table2\", ...],\n",
    "  \"column\": [\"col1\", \"col2\", ...]\n",
    "}\n",
    "```\n",
    "다음은 SQL 쿼리에 활용된 스키마 목록을 추출하는 LLM 요청 구문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c44c68a7-3c2c-402f-8a57-657d1e160251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT_TEMPLATE1 = \"\"\" \n",
    "You are an expert in extracting table names and column names from SQL queries. \n",
    "From the provided SQL query, extract all table names and column names used for SELECT, WHERE, and JOIN clauses, excluding asterisks (\"*\"). \n",
    "Ensure that the response is in a valid JSON format that can be used directly with json.load(). \n",
    "Skip the preamble and only provide the answer in a JSON document:\n",
    "\n",
    "{\n",
    "  \"table\": [\"table1\", \"table2\", ...],\n",
    "  \"column\": [\"col1\", \"col2\", ...]\n",
    "}\n",
    "\n",
    "<example>\n",
    "SQL:\n",
    "SELECT * from LOGIS_ADMIN.IAWD_TB_DCBSCD_BASISLC_M \n",
    "where basis_lclsf_cd_nm like '%예약구분%'\n",
    "LIMIT 200;\n",
    "\n",
    "{\n",
    "  \"table\": [\"IAWD_TB_DCBSCD_BASISLC_M\"],\n",
    "  \"column\": [\"basis_lclsf_cd_nm\"]\n",
    "}\n",
    "</example>\n",
    "\"\"\"\n",
    "\n",
    "USR_PROMPT_TEMPLATE1=\"\"\"\n",
    "SQL: {sql}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c230b58-f709-4a7f-a5d9-78c6f7685021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436d16f5-4d08-4f02-843f-dc487c620384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs =  { \n",
    "    \"max_tokens\": 200000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "466e905d-67be-44ec-85e0-0adce0a082a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs[\"system\"] = SYS_PROMPT_TEMPLATE1\n",
    "model1 = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", region_name='us-west-2', model_kwargs=model_kwargs)\n",
    "prompt1 = ChatPromptTemplate.from_template(USR_PROMPT_TEMPLATE1)\n",
    "\n",
    "chain1 = prompt1 | model1 | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592db742-3638-4e33-93ea-2a9c31612142",
   "metadata": {},
   "source": [
    "예를 들어 아래 쿼리에 사용된 스키마를 추출해보겠습니다.\n",
    "\n",
    "```SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e114e6-c10e-48a7-a85d-c073df3d39c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table': ['Invoice'], 'column': ['CustomerId', 'Total']}\n"
     ]
    }
   ],
   "source": [
    "sql = queries[8].strip()\n",
    "response = chain1.invoke({\"sql\": sql})\n",
    "used_schema = json.loads(response)\n",
    "print(used_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d2a722-bba8-4043-b627-8b48c0a45cfd",
   "metadata": {},
   "source": [
    "#### 이제 이 쿼리에 사용된 스키마 설명을 조회합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17816589-1b10-4200-844e-6d76f932c244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_descriptions(table_info, tables, columns):\n",
    "    tables_lower = {table.lower() for table in tables}\n",
    "    columns_lower = {column.lower() for column in columns}\n",
    "    \n",
    "    description = {\n",
    "        \"table\": {},\n",
    "        \"column\": {}\n",
    "    }\n",
    "    \n",
    "    for table_schema in table_info:\n",
    "        for table_name, table_info in table_schema.items():\n",
    "            if table_name.lower() in tables_lower:\n",
    "                description[\"table\"][table_name] = table_info[\"table_desc\"]\n",
    "                for col in table_info[\"cols\"]:\n",
    "                    col_name = col[\"col\"]\n",
    "                    if col_name.lower() in columns_lower:\n",
    "                        description[\"column\"][col_name] = col[\"col_desc\"]\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "052c9d03-949a-45b7-9b0d-3de07601961c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table': {'Invoice': 'Records details of transactions, linked to customers.'}, 'column': {'CustomerId': 'Foreign key that references the customer associated with this invoice.', 'Total': 'Total amount of the invoice.'}}\n"
     ]
    }
   ],
   "source": [
    "extracted_description = extract_descriptions(schema_description, used_schema['table'], used_schema['column'])\n",
    "print(extracted_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35df41-ac97-4ba0-961e-39e76e611549",
   "metadata": {},
   "source": [
    "#### 이제 쿼리에 대한 자연어 변환을 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9311aae-7d37-46f7-846b-8389369adbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYS_PROMPT_TEMPLATE2 = \"\"\" \n",
    "You are an SQL expert who can understand the intent behind a given SQL query. \n",
    "Translate the SQL query into a natural language request in Korean that a real user might make. \n",
    "\n",
    "- Keep your translation concise and conversational, mimicking how an actual user would ask for the information sought by the query. \n",
    "- Do not reference the <description> section directly and do not use a question form. \n",
    "- Ensure to include all conditions specified in the SQL query in the request.\n",
    "- Write possible business and functional purposes of the query.\n",
    "- Write very detailed purposes and motives of the query in detail.\n",
    "- Skip the preamble and phrase only the natural language request using a concise and straightforward tone without a verb ending. \n",
    "\"\"\"\n",
    "\n",
    "USR_PROMPT_TEMPLATE2=\"\"\"\n",
    "<description>\n",
    "{description}\n",
    "</description>\n",
    "\n",
    "SQL: {sql}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b733a116-4d58-4543-86fe-d34858c8199f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs[\"system\"] = SYS_PROMPT_TEMPLATE2\n",
    "model2 = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", region_name='us-west-2', model_kwargs=model_kwargs)\n",
    "prompt2 = ChatPromptTemplate.from_template(USR_PROMPT_TEMPLATE2)\n",
    "chain2 = prompt2 | model2 | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d725d-dcda-4be5-8ffe-130ad299bb7c",
   "metadata": {},
   "source": [
    "#### 자연어 질문을 생성하는 프롬프트는 아래 형식으로 LLM에 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3e377fc-8258-4125-9511-900e9056cfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "You are an SQL expert who can understand the intent behind a given SQL query. \n",
      "Translate the SQL query into a natural language request in Korean that a real user might make. \n",
      "\n",
      "- Keep your translation concise and conversational, mimicking how an actual user would ask for the information sought by the query. \n",
      "- Do not reference the <description> section directly and do not use a question form. \n",
      "- Ensure to include all conditions specified in the SQL query in the request.\n",
      "- Write possible business and functional purposes of the query.\n",
      "- Write very detailed purposes and motives of the query in detail.\n",
      "- Skip the preamble and phrase only the natural language request using a concise and straightforward tone without a verb ending. \n",
      "\n",
      "Human: \n",
      "<description>\n",
      "{'table': {'Invoice': 'Records details of transactions, linked to customers.'}, 'column': {'CustomerId': 'Foreign key that references the customer associated with this invoice.', 'Total': 'Total amount of the invoice.'}}\n",
      "</description>\n",
      "\n",
      "SQL: SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(SYS_PROMPT_TEMPLATE2)\n",
    "print(prompt2.format(description=extracted_description, sql=queries[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a598413-330e-43b6-8bc6-7f8cb643436c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고객별 총 구매액 상위 5명의 고객 ID와 총 구매액 조회\n",
      "\n",
      "상세 목적 및 동기:\n",
      "- 고객 구매 패턴 분석을 통해 주요 고객 파악 및 마케팅 전략 수립\n",
      "- 최상위 고객에 대한 특별 혜택 제공 또는 맞춤형 프로모션 진행\n",
      "- 고객 충성도 제고 및 재구매 유도를 위한 전략 수립\n",
      "- 매출 기여도가 높은 고객 관리 강화\n"
     ]
    }
   ],
   "source": [
    "response = chain2.invoke({\"sql\": queries[8], \"description\": extracted_description})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a2d45-ecaa-402d-8afd-e0c6ca616d28",
   "metadata": {},
   "source": [
    "#### 다음 쿼리에 대한 자연어 설명은 LLM에 의해 위와 같이 정의되었습니다.\n",
    "\n",
    "```SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5```\n",
    "\n",
    "#### 아래는 위 과정을 모든 SQL 쿼리에 대해 반복하는 스크립트입니다. (약 1~2분 소요됩니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57c7a078-d993-4afd-b460-45a0806dcf11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FILE_PATH_1 = './example_queries_temp.jsonl'\n",
    "def query_translation(table_info, queries, chain1, chain2):\n",
    "    if os.path.exists(FILE_PATH_1):\n",
    "        os.remove(FILE_PATH_1)\n",
    "\n",
    "    with open(FILE_PATH_1, 'a') as output_file:\n",
    "        for query in queries:\n",
    "            sql = query.strip()\n",
    "            \n",
    "            try:\n",
    "                response = chain1.invoke({\"sql\": sql})\n",
    "                schema = json.loads(response)\n",
    "            except json.JSONDecodeError:\n",
    "                print(response)\n",
    "                time.sleep(1)  \n",
    "\n",
    "            description = extract_descriptions(table_info, schema[\"table\"], schema[\"column\"])\n",
    "            \n",
    "            input = chain2.invoke({\"sql\": sql, \"description\": description})\n",
    "            # Write input and query to the file in JSON format\n",
    "            data = {\"input\": input, \"query\": sql}\n",
    "            output_file.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "query_translation(schema_description, queries, chain1, chain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaef577-90ef-41e9-89ad-49c4835a2685",
   "metadata": {},
   "source": [
    "#### 쿼리 변환이 완료된 결과는 `./lab3_text2sql_schema_preparation/example_queries_temp.jsonl` 파일에 저장되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "661cc2ab-3114-444c-bbec-b0f8fcc6fc75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '모든 아티스트의 ID와 이름 정보 조회. 신규 아티스트 데이터베이스 구축, 아티스트 목록 생성, 아티스트 프로필 관리 등의 업무에 활용될 수 있습니다.', 'query': 'SELECT * FROM Artist'}\n",
      "{'input': \"앨범 데이터에서 아티스트 이름이 'AC/DC'인 아티스트의 앨범 정보 조회. 아티스트 테이블에서 'AC/DC'라는 이름을 가진 아티스트의 ArtistId를 찾아 Album 테이블에서 해당 ArtistId와 연결된 모든 앨범 정보를 가져오는 요청. 아티스트 이름으로 특정 아티스트의 앨범 목록을 확인하고자 하는 목적으로 보임.\", 'query': \"SELECT * FROM Album WHERE ArtistId = (SELECT ArtistId FROM Artist WHERE Name = 'AC/DC')\"}\n",
      "{'input': '모든 락 장르 음악 트랙 정보 요청. 락 장르에 속한 모든 트랙의 상세 정보가 필요할 때 사용할 수 있는 쿼리. 새 음반 제작을 위해 기존 락 장르 트랙들을 분석하거나, 락 장르 음원 서비스를 준비하는 등의 업무에 활용 가능.', 'query': \"SELECT * FROM Track WHERE GenreId = (SELECT GenreId FROM Genre WHERE Name = 'Rock')\"}\n",
      "{'input': '전체 트랙의 총 재생시간 확인 요청. 음원 서비스 운영을 위해 전체 콘텐츠의 총 길이를 파악하여 스토리지 용량 산정 및 스트리밍 대역폭 예측에 활용할 수 있음.', 'query': 'SELECT SUM(Milliseconds) FROM Track'}\n",
      "{'input': '캐나다에 거주하는 고객 정보 조회. 국가별 고객 데이터 분석 및 마케팅 전략 수립을 위한 데이터 추출이 목적일 수 있습니다. 캐나다 시장 진출 계획 수립 시 현지 고객 기반을 파악하고 타겟 고객층을 정의하는 데 활용될 수 있습니다.', 'query': \"SELECT * FROM Customer WHERE Country = 'Canada'\"}\n",
      "{'input': '앨범 ID가 5인 트랙 수 확인\\n\\n이 쿼리는 특정 앨범에 포함된 트랙의 총 개수를 파악하기 위한 목적으로 사용될 수 있습니다. 예를 들어 앨범별 트랙 수를 비교하거나, 앨범 제작 시 예상 재생 시간을 산출하는 데 활용할 수 있습니다. 또한 특정 앨범의 인기도나 판매량을 간접적으로 가늠하는 지표로도 사용 가능합니다.', 'query': 'SELECT COUNT(*) FROM Track WHERE AlbumId = 5'}\n",
      "{'input': '모든 송장 건수 확인. 회사의 총 거래 규모와 고객 수를 파악하기 위한 목적일 수 있습니다. 매출 추이 분석, 재고 관리, 영업 실적 평가 등 다양한 비즈니스 의사결정에 기초 데이터로 활용될 수 있습니다.', 'query': 'SELECT COUNT(*) FROM Invoice'}\n",
      "{'input': '5분 이상 재생 시간을 가진 모든 음악 트랙 정보 조회. 장시간 재생되는 트랙을 별도로 분류하거나 관리할 필요가 있을 수 있음. 예를 들어 긴 트랙은 스트리밍 서비스에서 데이터 요금 부담이 클 수 있으므로 사용자에게 미리 알려줄 필요가 있을 수 있음.', 'query': 'SELECT * FROM Track WHERE Milliseconds > 300000'}\n",
      "{'input': '고객별 총 구매액 상위 5명의 고객 ID와 총 구매액 조회\\n\\n상세 목적 및 동기:\\n- 고객 구매 패턴 분석을 통해 주요 고객 파악 및 마케팅 전략 수립\\n- 최상위 고객에 대한 특별 혜택 제공 또는 맞춤형 프로모션 진행\\n- 고객 충성도 제고 및 재구매 유도를 위한 전략 수립\\n- 매출 기여도가 높은 고객 관리 강화', 'query': 'SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5'}\n",
      "{'input': '전체 직원 수 확인. 인력 관리 및 인사 계획 수립을 위해 현재 고용된 직원의 총 인원 수를 파악할 필요가 있습니다.', 'query': 'SELECT COUNT(*) FROM Employee'}\n"
     ]
    }
   ],
   "source": [
    "with open(FILE_PATH_1, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc567324-1948-4c8d-ad41-d48a07473a8a",
   "metadata": {},
   "source": [
    "## Step 3: 샘플 쿼리 벡터 임베딩 및 OpenSearch 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac40c19-7081-454f-8087-a364b66ee828",
   "metadata": {},
   "source": [
    "이제 <자연어 질문 & SQL 쿼리> 조합의 자연어 질문을 벡터로 임베딩하여, 사용자 질문과 유사한 SQL 쿼리를 찾아내기 용이하도록 저장해야 합니다.\n",
    "\n",
    "아래 구문은 OpenSearch 환경을 초기화합니다. (연결 생성 및 Index 초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b82ea722-2763-4ab1-b2f1-a90e1e7b371e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index does not exist, Create one.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "INDEX_NAME = \"example_queries\"\n",
    "\n",
    "def load_opensearch_config():\n",
    "    with open(\"./libs/opensearch.yml\", 'r', encoding='utf-8') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def init_opensearch(config):\n",
    "    mapping = {\"settings\": config['settings'], \"mappings\": config['mappings-sql']}\n",
    "    endpoint = opensearch_domain_endpoint\n",
    "    http_auth = (opensearch_user_id, opensearch_user_password)\n",
    "\n",
    "    os_client = OpenSearch(\n",
    "            hosts=[{'host': endpoint.replace(\"https://\", \"\"),'port': 443}],\n",
    "            http_auth=http_auth, \n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            timeout=300,\n",
    "            connection_class=RequestsHttpConnection\n",
    "    )\n",
    "\n",
    "    create_os_index(os_client, mapping)\n",
    "    return os_client\n",
    "\n",
    "def create_os_index(os_client, mapping):\n",
    "    exists = os_client.indices.exists(INDEX_NAME)\n",
    "\n",
    "    if exists:\n",
    "        os_client.indices.delete(index=INDEX_NAME)\n",
    "        print(\"Existing index has been deleted. Create new one.\")\n",
    "    else:\n",
    "        print(\"Index does not exist, Create one.\")\n",
    "\n",
    "    os_client.indices.create(INDEX_NAME, body=mapping)\n",
    "\n",
    "config = load_opensearch_config()\n",
    "os_client = init_opensearch(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea2db1-648b-4fd5-9186-9fc8abc6a20e",
   "metadata": {},
   "source": [
    "이제 앞에 만들었던 <자연어 질문 & SQL 쿼리>를 벡터 임베딩으로 변환하고, OpenSearch에 bulk indexing 할 수 있는 Data-Action 포맷으로 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01cd7dd3-ad79-4953-ada5-bcc0e1c46026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "FILE_PATH_2 = './example_queries.jsonl'\n",
    "emb_model = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", region_name='us-west-2', model_kwargs={\"dimensions\":1024}) \n",
    "\n",
    "def input_embedding(emb_model):\n",
    "    num = 0\n",
    "    if os.path.exists(FILE_PATH_2):\n",
    "        os.remove(FILE_PATH_2)\n",
    "\n",
    "    with open(FILE_PATH_1, 'r') as input_file, open(FILE_PATH_2, 'a') as output_file:\n",
    "        for line in input_file:\n",
    "            data = json.loads(line)\n",
    "            input = data['input']\n",
    "            query = data['query']\n",
    "            \n",
    "            # Data part\n",
    "            body = { \"input\": input, \"query\": query, \"input_v\": emb_model.embed_query(input) }\n",
    "\n",
    "            # Action part\n",
    "            action = { \"index\": { \"_index\": INDEX_NAME, \"_id\": str(num) } }\n",
    "\n",
    "            # Write action and body to the file in correct bulk format\n",
    "            output_file.write(json.dumps(action, ensure_ascii=False) + \"\\n\")\n",
    "            output_file.write(json.dumps(body, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            num += 1    \n",
    "\n",
    "input_embedding(emb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda2f81-7c57-4333-a095-3304ad1dabe9",
   "metadata": {},
   "source": [
    "#### 위 코드를 실행한 뒤 `./lab3_text2sql_schema_preparation/example_queries.jsonl` 파일을 열어보면, 변환된 임베딩을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d151126f-16f1-45f5-9b11-ade378977981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk-inserted all items successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(FILE_PATH_2, 'r') as file:\n",
    "    bulk_data = file.read()\n",
    "        \n",
    "response = os_client.bulk(body=bulk_data)\n",
    "if response[\"errors\"]:\n",
    "    print(\"There were errors during bulk indexing:\")\n",
    "    for item in response[\"items\"]:\n",
    "        if 'index' in item and item['index']['status'] >= 400:\n",
    "            print(f\"Error: {item['index']['error']['reason']}\")\n",
    "else:\n",
    "    print(\"Bulk-inserted all items successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b51586-09a7-4e02-8cb1-aae1ae0d9f96",
   "metadata": {},
   "source": [
    "#### 이제 OpenSearch에 저장을 완료했습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
