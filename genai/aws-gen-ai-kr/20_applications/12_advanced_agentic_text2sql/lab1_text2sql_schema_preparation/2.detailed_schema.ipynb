{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde141b9-c4c6-44b0-b939-2a8dca3b27fb",
   "metadata": {},
   "source": [
    "# Lab. 3-1 Schema Preparation-2\n",
    "\n",
    "이 노트북에서는 아래 그림의 `4. Table Summarizer` 과정을 수행합니다. \n",
    "\n",
    "일반적인 Schema Linking 과정이 테이블 선택 -> 컬럼 선택으로 나눠 진행되는데, 테이블 선택이 잘못되면 후속 과정은 무의미하기 때문에 각 테이블에 대한 충분한 설명을 갖추는 것이 중요합니다.\n",
    "\n",
    "이 노트북에서는 LLM을 활용해 테이블에 대한 자세한 설명 문서를 갖추는 과정을 시뮬레이션 합니다.\n",
    "\n",
    "![Intro](../images/text2sql/schema-prep-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d4222-ceff-47ea-b491-8adac0f315d8",
   "metadata": {},
   "source": [
    "## Step 0: OpenSearch 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c70963-24c8-4a71-8529-37ed362b5f58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search-chatbot-kevmyung-text2sql-puqfcoozcsspfabblsx3lzh7fe.us-west-2.es.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from libs.ssm import parameter_store\n",
    "\n",
    "pm = parameter_store('us-west-2')\n",
    "domain_endpoint = pm.get_params(key=\"chatbot-opensearch_domain_endpoint\", enc=False)\n",
    "opensearch_domain_endpoint = f\"https://{domain_endpoint}\"\n",
    "opensearch_user_id = pm.get_params(key=\"chatbot-opensearch_user_id\", enc=False)\n",
    "opensearch_user_password = pm.get_params(key=\"chatbot-opensearch_user_password\", enc=True)\n",
    "print(opensearch_domain_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed1666-159c-42f4-9664-84161e1fdbd9",
   "metadata": {},
   "source": [
    "## Step 1: Schema Description 및 Example Queries 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6749a59-1105-49ce-9601-1bdb91d7fe50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './example_queries_temp.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m queries\n\u001b[1;32m     15\u001b[0m schema \u001b[38;5;241m=\u001b[39m load_schema(SCHEMA_FILE_PATH)\n\u001b[0;32m---> 16\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[43mload_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAMPLE_QUERY_FILE_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m, in \u001b[0;36mload_queries\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_queries\u001b[39m(file_path):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     12\u001b[0m         queries \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m queries\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './example_queries_temp.jsonl'"
     ]
    }
   ],
   "source": [
    "import json \n",
    "SCHEMA_FILE_PATH = \"./chinook_schema.json\"\n",
    "SAMPLE_QUERY_FILE_PATH = \"./example_queries_temp.jsonl\"\n",
    "\n",
    "def load_schema(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        schema = json.load(file)\n",
    "    return schema\n",
    "\n",
    "def load_queries(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        queries = file.readlines()\n",
    "    return queries\n",
    "\n",
    "schema = load_schema(SCHEMA_FILE_PATH)\n",
    "queries = load_queries(SAMPLE_QUERY_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a650d-2612-440c-835a-ebd1dbab66a4",
   "metadata": {},
   "source": [
    "## Step 2: 테이블 요약 문서 생성\n",
    "\n",
    "다양한 정보들을 테이블 요약 문서 생성에 활용합니다. \n",
    "\n",
    "기본 Schema Description 문서와 Sample Query 등을 모두 활용해서 테이블 요약을 생성합니다. \n",
    "\n",
    "아래는 이 정보를 반영하기 위한 LLM 프롬프트 템플릿입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd9b880-aba2-4708-8f83-1287771a3aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "SYS_PROMPT = \"\"\"\n",
    "You are a data analyst that can help summarize SQL tables.\n",
    "Summarize the provided table by the given context.\n",
    "\n",
    "<instruction>\n",
    "- You shall write the summary based only on the provided information, and make it as detailed as possible.\n",
    "- Note that above sampled queries are only small sample of queries and thus not all possible use of tables are represented, and only some columns in the table are used.\n",
    "- Do not use any adjective to describe the table. For example, the importance of the table, its comprehensiveness or if it is crucial, or who may be using it. For example, you can say that a table contains certain types of data, but you cannot say that the table contains a 'wealth' of data, or that it is 'comprehensive'.\n",
    "- Do not mention about the sampled query. Only talk objectively about the type of data the table contains and its possible utilities.\n",
    "- Please also include some potential usecases of the table, e.g. what kind of questions can be answered by the table, what kind of anlaysis can be done by the table, etc.\n",
    "- Please provide the output in Korean.\n",
    "</instruction>\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "<table schema>\n",
    "{table_schema}\n",
    "</table schema>\n",
    "\n",
    "<sample queries>\n",
    "{sample_queries}\n",
    "</sample queries>\n",
    "\"\"\"\n",
    "\n",
    "model_kwargs =  { \n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"system\": SYS_PROMPT\n",
    "}\n",
    "\n",
    "chat_model = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    region_name='us-west-2',\n",
    "    model_kwargs=model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb10ee72-7793-4985-a4ee-aeda73e1d714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_table_queries(queries, table_name):  # 테이블이 어떤 쿼리에 사용되었는지 검색하여 추출하는 함수입니다.\n",
    "    table_name_lower = table_name.lower()\n",
    "    matched_queries = []\n",
    "\n",
    "    for line in queries:\n",
    "        try:\n",
    "            query_data = json.loads(line)\n",
    "            if table_name_lower in query_data['query'].lower():\n",
    "                matched_queries.append(query_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid JSON line: {line}\")\n",
    "    \n",
    "    return matched_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583e3f3-f34a-4854-a580-27644c92f25e",
   "metadata": {},
   "source": [
    "#### 주어진 정보를 바탕으로 `Customer`라는 테이블에 대한 요약 문서를 추출해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3719069d-dc8c-4de1-b289-746c83fb619c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 테이블은 고객 정보와 고객을 지원하는 직원 정보를 포함하고 있습니다. 고객 ID, 이름, 회사명, 주소, 도시, 주, 국가, 우편번호, 전화번호, 팩스번호, 이메일 주소 등의 고객 세부 정보가 포함되어 있습니다. 또한 고객을 지원하는 직원의 ID도 외래키로 연결되어 있습니다.\n",
      "\n",
      "이 테이블을 활용하여 다음과 같은 분석이 가능합니다:\n",
      "\n",
      "1. 국가별 고객 분포 분석 및 타겟 마케팅 전략 수립\n",
      "2. 우수 고객 파악 및 맞춤형 프로모션/혜택 제공\n",
      "3. 고객 구매 패턴 분석을 통한 마케팅 전략 수립\n",
      "4. 지역별 고객 분포 파악 및 신규 지역 진출 전략 수립\n",
      "5. 고객 세그멘테이션 및 타겟 마케팅 전략 수립\n",
      "6. 고객 관계 관리(CRM) 및 고객 유지 전략 수립\n",
      "7. 고객 데이터 기반 비즈니스 의사결정 지원\n",
      "\n",
      "요약하면, 이 테이블은 고객 데이터를 포괄적으로 저장하고 있어 마케팅, 판매, 고객 관리 등 다양한 비즈니스 분야에서 활용될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "table_name = 'Customer'\n",
    "\n",
    "matched_queries = search_table_queries(queries, table_name)\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "table_summary = chain.invoke({\"table_schema\": schema[0]['Customer'], \"sample_queries\": matched_queries})\n",
    "print(table_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f811120-5c0d-4478-81f1-f66469dbb093",
   "metadata": {},
   "source": [
    "#### 아래는 이 작업을 Schema Description 내 모든 테이블을 대상으로 수행하는 코드입니다 (약 2-3분 소요됩니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72ab1fd-3a57-4aca-9070-e7f0530e5608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_FILE_PATH1 = \"./chinook_detailed_schema_temp.json\"\n",
    "\n",
    "with open(OUTPUT_FILE_PATH1, 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write('[\\n')\n",
    "\n",
    "def summarize_table(table_name, table_data, queries, chain):\n",
    "    table_summary = chain.invoke({\"table_schema\": table_data, \"sample_queries\": queries})\n",
    "    table_data['table_summary'] = table_summary \n",
    "    summary_output = {table_name: table_data}\n",
    "    return summary_output\n",
    "    \n",
    "for table_info in schema:\n",
    "    for table_name, table_data in table_info.items():\n",
    "        globals()[table_name] = table_data\n",
    "        matched_queries = search_table_queries(queries, table_name)\n",
    "        prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "        chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "        table_summary = summarize_table(table_name, table_data, matched_queries, chain)\n",
    "        \n",
    "        with open(OUTPUT_FILE_PATH1, 'a', encoding='utf-8') as output_file:\n",
    "            output_file.write(json.dumps(table_summary, ensure_ascii=False, indent=4) + ',\\n')\n",
    "\n",
    "with open(OUTPUT_FILE_PATH1, 'rb+') as output_file:\n",
    "    output_file.seek(-2, os.SEEK_END) \n",
    "    output_file.truncate() \n",
    "    output_file.write(b'\\n]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556af33c-7a19-4df4-b3fa-d7fa38836eb7",
   "metadata": {},
   "source": [
    "이제 `text-to-sql-bedrock/lab1_text2sql_schema_preparation/chinook_detailed_schema_temp.json` 파일을 열어보면, table_summary가 스키마 문서에 추가되어 있습니다.\n",
    "\n",
    "위와 같이, 1) 테이블에 어떤 컬럼들이 있는지, 2) 어떤 용도로 활용되는지에 대한 자세한 정보를 LLM에 전달하는 것은 올바른 테이블 선택에 도움이 됩니다.\n",
    "\n",
    "하지만, 테이블 요약이 너무 길어졌을 때 모든 테이블의 요약 정보를 LLM에 전달할 수 없으므로, 테이블 요약 정보 역시 벡터 유사도 검색으로 탐색하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56a62d-12da-4548-ac46-49c322dbbd99",
   "metadata": {},
   "source": [
    "## Step 3: 테이블 요약 문서를 벡터 임베딩으로 변환하여 OpenSearch에 저장\n",
    "\n",
    "이 Step은 `1.sample_queries.ipynb`에서 수행한 샘플 쿼리 저장과정과 유사하게 진행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95fbb15a-f521-482e-b5df-6a8cd8d4ed4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index does not exist, Create one.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "INDEX_NAME = \"schema_descriptions\"\n",
    "\n",
    "def load_opensearch_config():\n",
    "    with open(\"./libs/opensearch.yml\", 'r', encoding='utf-8') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def init_opensearch(config):\n",
    "    mapping = {\"settings\": config['settings'], \"mappings\": config['mappings-detailed-schema']}\n",
    "    endpoint = opensearch_domain_endpoint\n",
    "    http_auth = (opensearch_user_id, opensearch_user_password)\n",
    "\n",
    "    os_client = OpenSearch(\n",
    "            hosts=[{'host': endpoint.replace(\"https://\", \"\"),'port': 443}],\n",
    "            http_auth=http_auth, \n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            timeout=300,\n",
    "            connection_class=RequestsHttpConnection\n",
    "    )\n",
    "\n",
    "    create_os_index(os_client, mapping)\n",
    "    return os_client\n",
    "\n",
    "def create_os_index(os_client, mapping):\n",
    "    exists = os_client.indices.exists(INDEX_NAME)\n",
    "\n",
    "    if exists:\n",
    "        os_client.indices.delete(index=INDEX_NAME)\n",
    "        print(\"Existing index has been deleted. Create new one.\")\n",
    "    else:\n",
    "        print(\"Index does not exist, Create one.\")\n",
    "\n",
    "    os_client.indices.create(INDEX_NAME, body=mapping)\n",
    "\n",
    "config = load_opensearch_config()\n",
    "os_client = init_opensearch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "827bcc97-974a-4fa2-b643-ca6f7519e968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "emb_model = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", region_name='us-west-2', model_kwargs={\"dimensions\":1024}) \n",
    "OUTPUT_FILE_PATH2 = \"./chinook_detailed_schema.json\"\n",
    "\n",
    "def embedding_summary(emb_model):\n",
    "    with open(OUTPUT_FILE_PATH1, 'r', encoding='utf-8') as input_file:\n",
    "        data_list = json.load(input_file)\n",
    "\n",
    "    for data in data_list:\n",
    "        table_name = list(data.keys())[0]\n",
    "        table_summary = data[table_name][\"table_summary\"]\n",
    "        data[table_name][\"table_summary_v\"] = emb_model.embed_query(table_summary)\n",
    "    \n",
    "    with open(OUTPUT_FILE_PATH2, 'w', encoding='utf-8') as output_file:\n",
    "        json.dump(data_list, output_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "embedding_summary(emb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30edc234-6e09-48df-9a21-491683c00666",
   "metadata": {},
   "source": [
    "#### 이제 `text-to-sql-bedrock/lab1_text2sql_schema_preparation/chinook_detailed_schema_temp.json` 파일을 열어보면, \n",
    "#### table_summary 및 이에 대한 임베딩이 스키마 문서에 추가되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021ea3a0-7f48-441c-9d73-faa6f3fd472b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk-inserted all items successfully.\n"
     ]
    }
   ],
   "source": [
    "def load_detailed_schema_descriptions(os_client):\n",
    "\n",
    "    with open(OUTPUT_FILE_PATH2, 'r') as file:\n",
    "        schema_data = json.load(file)\n",
    "\n",
    "    bulk_data = []\n",
    "    for table in schema_data:\n",
    "        for table_name, table_info in table.items():\n",
    "            table_doc = {\n",
    "                \"table_name\": table_name,\n",
    "                \"table_desc\": table_info[\"table_desc\"],\n",
    "                \"columns\": [{\"col_name\": col[\"col\"], \"col_desc\": col[\"col_desc\"]} for col in table_info[\"cols\"]],\n",
    "                \"table_summary\": table_info[\"table_summary\"],\n",
    "                \"table_summary_v\": table_info[\"table_summary_v\"]\n",
    "            }\n",
    "            bulk_data.append({\"index\": {\"_index\": INDEX_NAME, \"_id\": table_name}})\n",
    "            bulk_data.append(table_doc)\n",
    "    \n",
    "    bulk_data_str = '\\n'.join(json.dumps(item) for item in bulk_data) + '\\n'\n",
    "\n",
    "    response = os_client.bulk(body=bulk_data_str)\n",
    "    if response[\"errors\"]:\n",
    "        print(\"There were errors during bulk indexing:\")\n",
    "        for item in response[\"items\"]:\n",
    "            if 'index' in item and item['index']['status'] >= 400:\n",
    "                print(f\"Error: {item['index']['error']['reason']}\")\n",
    "    else:\n",
    "        print(\"Bulk-inserted all items successfully.\")\n",
    "\n",
    "load_detailed_schema_descriptions(os_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bae4d-72fb-4086-a708-1195335c8fd2",
   "metadata": {},
   "source": [
    "#### 이제 OpenSearch에 스키마 정보의 저장을 완료했습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
