import json
import os
from typing import Dict, List, Any, Union
from dataclasses import dataclass
from collections import defaultdict
from decimal import Decimal
import boto3
from datetime import datetime

class DecimalEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, Decimal):
            return float(obj)
        return super(DecimalEncoder, self).default(obj)

def convert_decimal(obj):
    """DynamoDB Decimal íƒ€ì…ì„ floatë¡œ ë³€í™˜"""
    if isinstance(obj, Decimal):
        return float(obj)
    elif isinstance(obj, dict):
        return {k: convert_decimal(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_decimal(v) for v in obj]
    return obj


@dataclass
class ReviewSummary:
    total_files: int
    total_primary_files: int
    total_reference_files: int
    total_issues: int
    severity_counts: Dict[str, int]
    category_counts: Dict[str, int]
    critical_issues: List[Dict[str, Any]]
    major_issues: List[Dict[str, Any]]
    suggestions_by_file: Dict[str, List[Dict[str, Any]]]
    reference_context: Dict[str, List[str]]
    # ë³€ê²½ì‚¬í•­ ìš”ì•½
    functional_changes: List[str]
    architectural_changes: List[str]
    technical_improvements: List[str]
    # ì´ì „ ë¦¬ë·°ì™€ì˜ ë¹„êµ
    previous_reviews_count: int = 0
    resolved_issues_count: int = 0
    new_issues_count: int = 0
    persistent_issues_count: int = 0
    # ëª¨ë“  ì´ìŠˆ ëª©ë¡ ì¶”ê°€
    all_issues: List[Dict[str, Any]] = None  # ê¸°ë³¸ê°’ì€ None
    
    def __post_init__(self):
        if self.all_issues is None:
            self.all_issues = []

class ResultAggregator:
    def __init__(self, event_data: Dict[str, Any]):
        self.ssm = boto3.client('ssm')
        self.event_data = event_data
        self.dynamodb = boto3.resource('dynamodb')
        self.results_table = self.dynamodb.Table('PRReviewerResults')
        self.reports_table = self.dynamodb.Table('PRReviewerReports')
        
        # ì‹¤í–‰ ID ë¨¼ì € ì¶”ì¶œ
        try:
            self.execution_id = self._extract_execution_id()
            print(f"Extracted execution_id: {self.execution_id}")
        except Exception as e:
            print(f"Error extracting execution ID: {e}")
            self.execution_id = f"error-{int(datetime.now().timestamp())}"
    
        # ê·¸ ë‹¤ìŒ ì²­í¬ ê²°ê³¼ ë¡œë“œ
        self.chunk_results = self._load_chunk_results_from_dynamodb()
        
        # ë‚˜ë¨¸ì§€ ì´ˆê¸°í™”
        self.pr_details = self._extract_pr_details()
        self.secrets = boto3.client('secretsmanager')
        self.config = self._load_config()
        self.previous_reviews = []
        
        # PR ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ì´ì „ ë¦¬ë·° ë¡œë“œ
        if self.pr_details and 'repository' in self.pr_details and 'pr_id' in self.pr_details:
            self.previous_reviews = self._get_previous_reviews(
                self.pr_details['repository'], 
                self.pr_details['pr_id']
            )


    def _load_chunk_results_from_dynamodb(self) -> List[Dict[str, Any]]:
        """DynamoDBì—ì„œ ì²­í¬ ê²°ê³¼ ë¡œë“œ"""
        results = []
        try:
            # ì‹¤í–‰ IDê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if not hasattr(self, 'execution_id') or not self.execution_id:
                print("Execution ID not set, cannot load chunk results")
                return []

            # í˜„ì¬ ì‹¤í–‰ì— ëŒ€í•œ ëª¨ë“  ì²­í¬ ê²°ê³¼ ì¡°íšŒ
            response = self.results_table.query(
                KeyConditionExpression=boto3.dynamodb.conditions.Key('execution_id').eq(self.execution_id)
            )

            if 'Items' in response:
                for item in response['Items']:
                    if 'results' in item:  # ê²°ê³¼ê°€ ìˆëŠ” í•­ëª©ë§Œ ì²˜ë¦¬
                        results.extend(item['results'])

            print(f"Loaded {len(results)} chunk results from DynamoDB")
            return results
        except Exception as e:
            print(f"Error loading chunk results from DynamoDB: {e}")
            return []

    def _extract_execution_id(self) -> str:
        """ì´ë²¤íŠ¸ì—ì„œ ì‹¤í–‰ ID ì¶”ì¶œ"""
        try:
            # Step Functions ë§µ ìƒíƒœì—ì„œ ì˜¤ëŠ” ê²°ê³¼ ëª©ë¡ì—ì„œ ì‹¤í–‰ ID ì¶”ì¶œ
            if isinstance(self.event_data, dict):
                classified_results = self.event_data.get('classifiedResults', {})
                succeeded_results = classified_results.get('succeeded', [])
                retry_results = self.event_data.get('retryResults', [])

                all_results = succeeded_results + retry_results

                if all_results:
                    for result in all_results:
                        if isinstance(result, dict) and result.get('body'):
                            body = json.loads(result['body']) if isinstance(result['body'], str) else result['body']
                            if execution_id := body.get('execution_id'):
                                return execution_id

                # ì‹¤í–‰ IDë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì„ì‹œ ID ìƒì„±
                temp_id = f"unknown-{int(datetime.now().timestamp())}"
                print(f"Could not find execution_id in event data, using generated ID: {temp_id}")
                return temp_id

            else:
                temp_id = f"unknown-format-{int(datetime.now().timestamp())}"
                print(f"Event data is not a dictionary, using generated ID: {temp_id}")
                return temp_id

        except Exception as e:
            temp_id = f"error-{int(datetime.now().timestamp())}"
            print(f"Error extracting execution ID: {e}, using generated ID: {temp_id}")
            return temp_id

    def _load_config(self) -> Dict[str, Any]:
        """Parameter Storeì—ì„œ ì„¤ì • ë¡œë“œ"""
        config = {}
        try:
            # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
            response = self.ssm.get_parameters_by_path(
                Path='/pr-reviewer/config/',
                Recursive=True,
                WithDecryption=True
            )
            
            for param in response['Parameters']:
                # íŒŒë¼ë¯¸í„° ì´ë¦„ì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                name = param['Name'].split('/')[-1]
                config[name] = param['Value']
                   
        except Exception as e:
            print(f"Error loading config: {e}")
            raise

        return config

    def _extract_pr_details(self) -> Dict[str, Any]:
        """PR ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            # DynamoDBì—ì„œ í•˜ë‚˜ì˜ í•­ëª©ë§Œ ê°€ì ¸ì™€ PR ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            response = self.results_table.query(
                KeyConditionExpression=boto3.dynamodb.conditions.Key('execution_id').eq(self.execution_id),
                Limit=1
            )

            if response.get('Items'):
                pr_details = convert_decimal(response['Items'][0].get('pr_details', {}))
                print(f"Extracted PR details: {json.dumps(pr_details, cls=DecimalEncoder)}")
                return pr_details

            # DynamoDBì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì…ë ¥ ì´ë²¤íŠ¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
            if isinstance(self.event_data, dict):
                pr_details = {}
                if 'body' in self.event_data and 'pr_details' in self.event_data['body']:
                    pr_details = self.event_data['body']['pr_details']

                if pr_details:
                    print(f"Extracted PR details from event data: {json.dumps(pr_details, cls=DecimalEncoder)}")
                    return pr_details

            print("Failed to extract PR details from DynamoDB or event data")
            return {}

        except Exception as e:
            print(f"Error extracting PR details: {e}")
            return {}

    def _extract_chunk_results(self) -> List[Dict[str, Any]]:
        """ì²­í¬ ê²°ê³¼ ì¶”ì¶œ"""
        results = []
        try:
            if isinstance(self.event_data, list):
                # ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼
                for chunk in self.event_data:
                    if isinstance(chunk, dict) and chunk.get('body'):
                        body = json.loads(chunk['body'])
                        if chunk_results := body.get('results'):
                            results.extend(chunk_results)
            elif isinstance(self.event_data, dict):
                # ë‹¨ì¼ ì²˜ë¦¬ ê²°ê³¼
                if self.event_data.get('body'):
                    body = json.loads(self.event_data['body'])
                    if chunk_results := body.get('results'):
                        results.extend(chunk_results)
        except Exception as e:
            print(f"Error extracting chunk results: {e}")

        return results

    def _normalize_line_number(self, line_number: Union[str, int]) -> str:
        """ë¼ì¸ ë²ˆí˜¸ ì •ê·œí™”"""
        if isinstance(line_number, str) and line_number.lower() == 'all':
            return 'Throughout file'
        try:
            return str(int(line_number))
        except (ValueError, TypeError):
            return 'N/A'


    def _prepare_summary_prompt(self, changes: Dict[str, List[str]]) -> str:
        """Key Changes Summary ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„"""
        prompt = """ë‹¤ìŒ ë³€ê²½ì‚¬í•­ë“¤ì„ ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ 5ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
        ì›ë³¸ ë³€ê²½ì‚¬í•­:

        ğŸ”„ Functional Changes:
        """
        for change in changes.get('functional_changes', []):
            prompt += f"- {change}\n"

        prompt += "\nğŸ— Architectural Changes:\n"
        for change in changes.get('architectural_changes', []):
            prompt += f"- {change}\n"

        prompt += "\nğŸ”§ Technical Improvements:\n"
        for change in changes.get('technical_improvements', []):
            prompt += f"- {change}\n"

        prompt += """
        ìœ„ ë³€ê²½ì‚¬í•­ë“¤ì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

            {
                "summary": {
                    "functional_changes": "ê¸°ëŠ¥ì  ë³€ê²½ì‚¬í•­ ìš”ì•½",
                    "architectural_changes": "ì•„í‚¤í…ì²˜ ë³€ê²½ì‚¬í•­ ìš”ì•½",
                    "technical_improvements": "ê¸°ìˆ ì  ê°œì„ ì‚¬í•­ ìš”ì•½"
                }
            }

            ê° ìš”ì•½ì€ í•œê¸€ë¡œ ì‘ì„±í•˜ê³ , ì „ë¬¸ ìš©ì–´ë‚˜ ê³ ìœ ëª…ì‚¬ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì£¼ì„¸ìš”."""
        print(prompt)
        return prompt

    def _summarize_changes_with_bedrock(self, changes: Dict[str, List[str]]) -> Dict[str, str]:
        """Bedrockì„ ì‚¬ìš©í•˜ì—¬ ë³€ê²½ì‚¬í•­ ìš”ì•½"""
        try:
            bedrock = boto3.client('bedrock-runtime')
            prompt = self._prepare_summary_prompt(changes)

            body = json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 1000,
                "temperature": 0.7,
                "top_p": 0.9,
                "system": "5ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤.",
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            })

            response = bedrock.invoke_model(
                modelId=self.config['model'],
                contentType='application/json',
                accept='application/json',
                body=body.encode()
            )

            response_body = json.loads(response['body'].read())
            summary = json.loads(response_body['content'][0]['text'])
            return summary.get('summary', {})

        except Exception as e:
            print(f"Error summarizing with Bedrock: {e}")
            return {
                'functional_changes': '',
                'architectural_changes': '',
                'technical_improvements': ''
            }

    def analyze_results(self) -> ReviewSummary:
        """ë¦¬ë·° ê²°ê³¼ ë¶„ì„"""
        severity_counts = defaultdict(int)
        category_counts = defaultdict(int)
        critical_issues = []
        major_issues = []
        suggestions_by_file = defaultdict(list)
        reference_context = defaultdict(list)
        total_issues = 0

        # primary/reference íŒŒì¼ êµ¬ë¶„
        primary_files = []
        reference_files = []
        all_issues = []

        for result in self.chunk_results:
            file_path = result['file_path']

            if result.get('is_primary', True):
                primary_files.append(file_path)
                severity_counts[result['severity']] += 1

                # ì°¸ì¡° íŒŒì¼ ì •ë³´ ì €ì¥
                if referenced_by := result.get('referenced_by'):
                    reference_context[file_path].extend(referenced_by)

                for suggestion in result.get('suggestions', []):
                    total_issues += 1
                    category = suggestion.get('category', 'other')
                    severity = suggestion.get('severity', 'NORMAL')

                    category_counts[category] += 1

                    # ë¼ì¸ ë²ˆí˜¸ ì •ê·œí™”
                    suggestion['line_number'] = self._normalize_line_number(
                        suggestion.get('line_number')
                    )

                    issue_details = {
                        'file': file_path,
                        'description': suggestion.get('description'),
                        'line_number': suggestion['line_number'],
                        'suggestion': suggestion.get('suggestion'),
                        'severity': severity,
                        'category': category
                    }

                    all_issues.append(issue_details)  # ì´ìŠˆë¥¼ all_issues ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

                    if severity == 'CRITICAL':
                        critical_issues.append(issue_details)
                    elif severity == 'MAJOR':
                        major_issues.append(issue_details)

                    suggestions_by_file[file_path].append(suggestion)
            else:
                reference_files.append(file_path)

        # ë³€ê²½ì‚¬í•­ ìš”ì•½ ìˆ˜ì§‘
        functional_changes = set()
        architectural_changes = set()
        technical_improvements = set()

        for result in self.chunk_results:
            if summary := result.get('summary', {}):
                functional_changes.update(summary.get('functional_changes', []))
                architectural_changes.update(summary.get('architectural_changes', []))
                technical_improvements.update(summary.get('technical_improvements', []))

        # ì´ì „ ë¦¬ë·°ì™€ ë¹„êµ
        comparison_result = self._compare_with_previous_reviews(all_issues)

        return ReviewSummary(
            total_files=len(primary_files) + len(reference_files),
            total_primary_files=len(primary_files),
            total_reference_files=len(reference_files),
            total_issues=total_issues,
            severity_counts=dict(severity_counts),
            category_counts=dict(category_counts),
            critical_issues=critical_issues,
            major_issues=major_issues,
            suggestions_by_file=dict(suggestions_by_file),
            reference_context=dict(reference_context),
            functional_changes=sorted(list(functional_changes)),
            architectural_changes=sorted(list(architectural_changes)),
            technical_improvements=sorted(list(technical_improvements)),
            previous_reviews_count=comparison_result['previous_reviews_count'],
            resolved_issues_count=len(comparison_result['resolved_issues']),
            new_issues_count=len(comparison_result['new_issues']),
            persistent_issues_count=len(comparison_result['persistent_issues']),
            all_issues=all_issues  # all_issues í•„ë“œì— ì €ì¥
        )

    def generate_markdown_report(self, summary: ReviewSummary) -> str:
        pr_title = self.pr_details.get('title', 'Unknown PR')
        pr_author = self.pr_details.get('author', 'Unknown Author')
    
        report = [
            f"# ğŸ§¾ Code Review Report: {pr_title}",
            f"\nGenerated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
    
            "\n## Overview",
            f"- Pull Request by: {pr_author}",
            f"- Primary Files Reviewed: {summary.total_primary_files}",
            f"- Reference Files: {summary.total_reference_files}",
            f"- Total Issues Found: {summary.total_issues}",
        ]
        
        # ì´ì „ ë¦¬ë·°ê°€ ìˆëŠ” ê²½ìš° ë¹„êµ ì •ë³´ ì¶”ê°€
        if summary.previous_reviews_count > 0:
            report.extend([
                f"- Previous Reviews: {summary.previous_reviews_count}",
                f"- Resolved Issues: {summary.resolved_issues_count}",
                f"- New Issues: {summary.new_issues_count}",
                f"- Persistent Issues: {summary.persistent_issues_count}"
            ])
    
        if summary.functional_changes or summary.architectural_changes or summary.technical_improvements:
            # ëª¨ë“  ë³€ê²½ì‚¬í•­ í†µí•©
            all_changes = {
                'functional_changes': summary.functional_changes,
                'architectural_changes': summary.architectural_changes,
                'technical_improvements': summary.technical_improvements
            }
        
            # Bedrockì„ ì‚¬ìš©í•˜ì—¬ ìš”ì•½
            summarized_changes = self._summarize_changes_with_bedrock(all_changes)
    
            report.extend([
                "\n## Key Changes Summary",
                "\n### ğŸ”„ Functional Changes",
                summarized_changes.get('functional_changes', ''),
                "\n### ğŸ— Architectural Changes",
                summarized_changes.get('architectural_changes', ''),
                "\n### ğŸ”§ Technical Improvements",
                summarized_changes.get('technical_improvements', '')
            ])
        
        # ì´ì „ ë¦¬ë·° ëŒ€ë¹„ ë³€ê²½ ì‚¬í•­ (ìˆëŠ” ê²½ìš°)
        if summary.previous_reviews_count > 0:
            report.append("\n## Review History Analysis")
            
            # í•´ê²°ëœ ì´ìŠˆ
            if summary.resolved_issues_count > 0:
                report.append("\n### âœ… Resolved Issues")
                comparison_result = self._compare_with_previous_reviews([])
                
                for issue in comparison_result['resolved_issues']:
                    report.extend([
                        f"\n- **{issue['file']}** (Line {issue['line_number']})",
                        f"  - {issue['description']}"
                    ])
                
                if len(comparison_result['resolved_issues']) < summary.resolved_issues_count:
                    report.append(f"\n... and {summary.resolved_issues_count - len(comparison_result['resolved_issues'])} more resolved issues.")
            
            # ì§€ì†ì ì¸ ì´ìŠˆ
            if summary.persistent_issues_count > 0:
                report.append("\n### âš ï¸ Persistent Issues")
                comparison_result = self._compare_with_previous_reviews([])
                
                for issue in comparison_result['persistent_issues']:
                    report.extend([
                        f"\n- **{issue['file']}** (Line {issue['line_number']})",
                        f"  - {issue['description']}"
                    ])
                
                if len(comparison_result['persistent_issues']) < summary.persistent_issues_count:
                    report.append(f"\n... and {summary.persistent_issues_count - len(comparison_result['persistent_issues'])} more persistent issues.")
    
        report.extend([
            "\n## Severity Summary",
            "| Severity | Count |",
            "|----------|-------|"
        ])
    
        # ì‹¬ê°ë„ ìš”ì•½ í…Œì´ë¸”
        for severity, count in sorted(summary.severity_counts.items()):
            report.append(f"| {severity} | {count} |")
    
        # ì¹´í…Œê³ ë¦¬ ìš”ì•½ í…Œì´ë¸”    
        report.extend([
            "\n## Category Summary",
            "| Category | Count |",
            "|----------|-------|"
        ])
    
        for category, count in sorted(summary.category_counts.items()):
            report.append(f"| {category.title()} | {count} |")
    
        # ì¤‘ìš” ì´ìŠˆ ì„¹ì…˜
        if summary.critical_issues:
            report.append("\n## Critical Issues")
            for issue in summary.critical_issues:
                report.extend([
                    f"\n### {issue['file']} (Line {issue['line_number']})",
                    f"**Issue:** {issue['description']}",
                    f"**Suggestion:** {issue['suggestion']}"
                ])
        
        if summary.major_issues:
            report.append("\n## Major Issues")
            for issue in summary.major_issues:
                report.extend([
                    f"\n### {issue['file']} (Line {issue['line_number']})",
                    f"**Issue:** {issue['description']}",
                    f"**Suggestion:** {issue['suggestion']}"
                ])
    
        # íŒŒì¼ë³„ ìƒì„¸ ë¦¬ë·°
        report.append("\n## Detailed Review by File")
        
        # ëª¨ë“  ì´ìŠˆë¥¼ í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ í†µí•©
        report.extend([
            "\n| File | Line | Category | Severity | Description | Suggestion |",
            "|------|------|-----------|-----------|--------------|-------------|"
        ])
    
        # ëª¨ë“  íŒŒì¼ì˜ ì œì•ˆì‚¬í•­ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
        all_suggestions = []
        for file_path, suggestions in summary.suggestions_by_file.items():
            for suggestion in suggestions:
                all_suggestions.append((file_path, suggestion))
    
        # íŒŒì¼ëª…ê³¼ ë¼ì¸ ë²ˆí˜¸ë¡œ ì •ë ¬
        sorted_suggestions = sorted(
            all_suggestions,
            key=lambda x: (
                x[0],  # íŒŒì¼ëª…ìœ¼ë¡œ ë¨¼ì € ì •ë ¬
                # 'Throughout file'ë¥¼ ë§ˆì§€ë§‰ìœ¼ë¡œ
                x[1]['line_number'] == 'Throughout file',
                # ìˆ«ìëŠ” ìˆ«ììˆœìœ¼ë¡œ
                int(x[1]['line_number']) if x[1]['line_number'].isdigit() else float('inf'),
                # ë‚˜ë¨¸ì§€ëŠ” ë¬¸ìì—´ ìˆœìœ¼ë¡œ
                x[1]['line_number']
            )
        )
    
        # í…Œì´ë¸” ìƒì„±
        for file_path, suggestion in sorted_suggestions:
            # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì—ì„œ íŒŒì´í”„(|) ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
            description = suggestion.get('description', 'N/A').replace('|', '\\|')
            suggestion_text = suggestion.get('suggestion', 'N/A').replace('|', '\\|')
    
            report.append(
                f"| {file_path} | {suggestion['line_number']} | "
                f"{suggestion.get('category', 'Other').title()} | "
                f"{suggestion.get('severity', 'NORMAL')} | "
                f"{description} | "
                f"{suggestion_text} |"
            )
    
        # íŒŒì¼ ì˜ì¡´ì„± ì •ë³´ë¥¼ ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬
        report.append("\n### File Dependencies")
        for file_path, ref_files in sorted(summary.reference_context.items()):
            if ref_files:  # ì°¸ì¡° íŒŒì¼ì´ ìˆëŠ” ê²½ìš°ë§Œ í‘œì‹œ
                report.extend([
                    f"\n#### {file_path}",
                    "Related Files:"
                ])
                dedup_ref_files = list(set(ref_files))
                for ref_file in sorted(dedup_ref_files):
                    report.append(f"- {ref_file}")
    
        # ì¶”ê°€ ì •ë³´ ë° ë©”íƒ€ë°ì´í„°
        report.extend([
            "\n## Additional Information",
            "- Review Date: " + datetime.now().strftime('%Y-%m-%d'),
            "- Base Branch: " + self.pr_details.get('base_branch', 'Unknown'),
            "- Head Branch: " + self.pr_details.get('head_branch', 'Unknown'),
            f"- Repository: {self.pr_details.get('repository', 'Unknown')}",
            f"- PR Number: {self.pr_details.get('pr_id', 'Unknown')}"
        ])
    
        # ë¦¬í¬íŠ¸ í•˜ë‹¨ì— ìë™ ìƒì„± í‘œì‹œ
        report.extend([
            "\n---",
            "ğŸ¤– _This report was automatically generated by PR Review Bot & Amazon Bedrock_ ğŸ§¾"
        ])
    
        return '\n'.join(report)

    def prepare_pr_comment(self, summary: ReviewSummary) -> str:
        """PR ì½”ë©˜íŠ¸ìš© ìš”ì•½ ìƒì„±"""
        comment = [
            "# Code Review Summary",
            f"\nReviewed {summary.total_primary_files} primary files "
            f"(with {summary.total_reference_files} reference files) "
            f"and found {summary.total_issues} issues.",
            
            "\n## Severity Breakdown",
            "| Severity | Count |",
            "|----------|-------|",
        ]
        
        for severity, count in summary.severity_counts.items():
            comment.append(f"| {severity} | {count} |")
        
        if summary.critical_issues:
            comment.append("\n### Critical Issues Found")
            for issue in summary.critical_issues:
                comment.extend([
                    f"\n- **{issue['file']}** (Line {issue['line_number']})",
                    f"  - {issue['description']}",
                    f"  - Suggestion: {issue['suggestion']}"
                ])
        
        if summary.major_issues:
            comment.append("\n### Major Issues Found")
            for issue in summary.major_issues[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                comment.extend([
                    f"\n- **{issue['file']}** (Line {issue['line_number']})",
                    f"  - {issue['description']}"
                ])
            
            if len(summary.major_issues) > 5:
                comment.append(f"\n... and {len(summary.major_issues) - 5} more major issues.")
        
        # ì´ì „ ë¦¬ë·° ë¹„êµ ì •ë³´ ì¶”ê°€
        if summary.previous_reviews_count > 0:
            comment.extend([
                "\n## Review History",
                f"- Previous Reviews: {summary.previous_reviews_count}",
                f"- Resolved Issues: {summary.resolved_issues_count}",
                f"- New Issues: {summary.new_issues_count}",
                f"- Persistent Issues: {summary.persistent_issues_count}"
            ])
        
        
        return '\n'.join(comment)

    def prepare_slack_message(self, summary: ReviewSummary) -> Dict[str, Any]:
        """Slack ë©”ì‹œì§€ ì¤€ë¹„"""
        pr_title = self.pr_details.get('title', 'Unknown PR')
        pr_author = self.pr_details.get('author', 'Unknown Author')
        pr_url = self.pr_details.get('pr_url', '#')

        # PR ì œëª©ì´ ê¸¸ ê²½ìš° ì¶•ì•½
        MAX_TITLE_LENGTH = 100
        shortened_title = (pr_title[:MAX_TITLE_LENGTH] + '...') if len(pr_title) > MAX_TITLE_LENGTH else pr_title
        
        severity_emoji = {
            'CRITICAL': 'ğŸš¨',
            'MAJOR': 'âš ï¸',
            'MINOR': 'ğŸ“',
            'NORMAL': 'âœ…'
        }
        
        # ì „ì²´ ì‹¬ê°ë„ ê²°ì •
        overall_severity = 'NORMAL'
        if summary.critical_issues:
            overall_severity = 'CRITICAL'
        elif summary.major_issues:
            overall_severity = 'MAJOR'
        elif summary.severity_counts.get('MINOR', 0) > 0:
            overall_severity = 'MINOR'
        
        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": f"{severity_emoji[overall_severity]} Review: {shortened_title}"
                }
            },
            {
                "type": "section",
                "fields": [
                    {
                        "type": "mrkdwn",
                        "text": f"*Author:*\n{pr_author}"
                    },
                    {
                        "type": "mrkdwn",
                        "text": f"*Files:*\n{summary.total_primary_files} primary + {summary.total_reference_files} reference"
                    }
                ]
            }
        ]
        
        # ì‹¬ê°ë„ ìš”ì•½
        severity_text = []
        for severity, count in summary.severity_counts.items():
            if count > 0:
                severity_text.append(f"{severity_emoji[severity]} {severity}: {count}")
        
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "\n".join(severity_text)
            }
        })
        
        # ì¤‘ìš” ì´ìŠˆ í•˜ì´ë¼ì´íŠ¸
        if summary.critical_issues or summary.major_issues:
            highlight_text = ["*Critical/Major Issues:*"]
            
            for issue in (summary.critical_issues + summary.major_issues)[:3]:
                highlight_text.append(
                    f"â€¢ {issue['file']} (Line {issue['line_number']}): {issue['description'][:100]}..."
                )
            
            if len(summary.critical_issues + summary.major_issues) > 3:
                remaining = len(summary.critical_issues + summary.major_issues) - 3
                highlight_text.append(f"_...and {remaining} more critical/major issues_")
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "\n".join(highlight_text)
                }
            })
        
        # íŒŒì¼ í†µê³„ ì„¹ì…˜
        if summary.reference_context:
            file_stats = ["*File Dependencies:*"]
            for primary_file, ref_files in list(summary.reference_context.items())[:3]:
                file_stats.append(f"â€¢ `{primary_file}` - {len(ref_files)} related files")
            
            if len(summary.reference_context) > 3:
                remaining = len(summary.reference_context) - 3
                file_stats.append(f"_...and {remaining} more files with dependencies_")
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "\n".join(file_stats)
                }
            })
        
        # PR ë§í¬ ë²„íŠ¼
        if pr_url and pr_url != '#':
            blocks.append({
                "type": "actions",
                "elements": [
                    {
                        "type": "button",
                        "text": {
                            "type": "plain_text",
                            "text": "Review PR ğŸ‘€"
                        },
                        "url": pr_url,
                        "style": "primary"
                    }
                ]
            })
        
                # ì´ì „ ë¦¬ë·°ì™€ ë¹„êµ ì •ë³´ ì¶”ê°€
        if summary.previous_reviews_count > 0:
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*Review History:*\nâœ… Resolved: {summary.resolved_issues_count} | ğŸ†• New: {summary.new_issues_count} | âš ï¸ Persistent: {summary.persistent_issues_count}"
                }
            })
        
        
        return {
            "blocks": blocks,
            "text": f"Code Review completed for PR: {shortened_title} - Found {summary.total_issues} issues in {summary.total_primary_files} primary files"  # í´ë°± í…ìŠ¤íŠ¸
        }

    def _get_previous_reviews(self, repository: str, pr_id: str) -> List[Dict[str, Any]]:
        """ë™ì¼í•œ PRì— ëŒ€í•œ ì´ì „ ë¦¬ë·° ê²°ê³¼ ì¡°íšŒ"""
        try:
            response = self.results_table.query(
                IndexName='repository-pr-index',
                KeyConditionExpression=boto3.dynamodb.conditions.Key('repository').eq(repository) &
                                      boto3.dynamodb.conditions.Key('pr_id').eq(pr_id),
                ScanIndexForward=False  # ìµœì‹  í•­ëª©ë¶€í„° ì¡°íšŒ
            )

            # í˜„ì¬ ì‹¤í–‰ IDê°€ ì•„ë‹Œ ì´ì „ ì‹¤í–‰ì˜ ê²°ê³¼ë§Œ í•„í„°ë§
            previous_reviews = []
            execution_ids = set()

            for item in response.get('Items', []):
                exec_id = item.get('execution_id')
                if exec_id != self.execution_id and exec_id not in execution_ids:
                    execution_ids.add(exec_id)
                    previous_reviews.append(item)

                    # ìµœê·¼ 5ê°œ ì‹¤í–‰ë§Œ ê°€ì ¸ì˜´
                    if len(previous_reviews) >= 5:
                        break

            print(f"Found {len(previous_reviews)} previous reviews for PR {repository}/{pr_id}")
            return previous_reviews

        except Exception as e:
            print(f"Error retrieving previous reviews: {e}")
            return []


    def _compare_with_previous_reviews(self, current_issues: List[Dict[str, Any]]) -> Dict[str, Any]:
        """í˜„ì¬ ì´ìŠˆì™€ ì´ì „ ë¦¬ë·°ì˜ ì´ìŠˆë¥¼ ë¹„êµ"""
        if not self.previous_reviews:
            return {
                'previous_reviews_count': 0,
                'resolved_issues': [],
                'new_issues': current_issues,
                'persistent_issues': []
            }

        # ê°€ì¥ ìµœê·¼ ë¦¬ë·°ì˜ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        latest_review = self.previous_reviews[0]
        previous_results = []

        # ì´ì „ ë¦¬ë·°ì—ì„œ ëª¨ë“  ì´ìŠˆ ìˆ˜ì§‘
        for item in self.results_table.query(
            KeyConditionExpression=boto3.dynamodb.conditions.Key('execution_id').eq(latest_review.get('execution_id'))
        ).get('Items', []):
            if 'results' in item:
                for result in item['results']:
                    for suggestion in result.get('suggestions', []):
                        previous_results.append({
                            'file': result['file_path'],
                            'line_number': suggestion.get('line_number', 'N/A'),
                            'description': suggestion.get('description', ''),
                            'severity': suggestion.get('severity', 'NORMAL')
                        })

        # í˜„ì¬ ì´ìŠˆì™€ ì´ì „ ì´ìŠˆ ë¹„êµ
        current_issue_keys = {
            f"{issue['file']}:{issue['line_number']}:{issue['description'][:50]}"
            for issue in current_issues
        }

        previous_issue_keys = {
            f"{issue['file']}:{issue['line_number']}:{issue['description'][:50]}"
            for issue in previous_results
        }

        # í•´ê²°ëœ ì´ìŠˆ, ìƒˆë¡œìš´ ì´ìŠˆ, ì§€ì†ì ì¸ ì´ìŠˆ ì‹ë³„
        resolved_keys = previous_issue_keys - current_issue_keys
        new_keys = current_issue_keys - previous_issue_keys
        persistent_keys = current_issue_keys & previous_issue_keys

        # ì›ë³¸ ì´ìŠˆ ê°ì²´ ì°¾ê¸°
        resolved_issues = [
            issue for issue in previous_results
            if f"{issue['file']}:{issue['line_number']}:{issue['description'][:50]}" in resolved_keys
        ]

        new_issues = [
            issue for issue in current_issues
            if f"{issue['file']}:{issue['line_number']}:{issue['description'][:50]}" in new_keys
        ]

        persistent_issues = [
            issue for issue in current_issues
            if f"{issue['file']}:{issue['line_number']}:{issue['description'][:50]}" in persistent_keys
        ]

        return {
            'previous_reviews_count': len(self.previous_reviews),
            'resolved_issues': resolved_issues[:10],  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
            'new_issues': new_issues[:10],  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
            'persistent_issues': persistent_issues[:10]  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
        }

    def store_report_in_dynamodb(self, markdown_report: str) -> bool:
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œë¥¼ ë³„ë„ì˜ DynamoDB í…Œì´ë¸”ì— ì €ì¥"""
        try:
            if not self.pr_details or 'repository' not in self.pr_details or 'pr_id' not in self.pr_details:
                print("PR details missing, cannot store report")
                return False

            # ë¦¬í¬ì§€í† ë¦¬ ë° PR ID ì •ë³´ ì¶”ì¶œ
            repository = self.pr_details.get('repository')
            pr_id = self.pr_details.get('pr_id')

            timestamp = datetime.now().isoformat()

            # ë³´ê³ ì„œ í…Œì´ë¸”ì— ì €ì¥
            self.reports_table.put_item(
                Item={
                    'repository': repository,
                    'pr_id': pr_id,
                    'execution_id': self.execution_id,
                    'timestamp': timestamp,
                    'report': markdown_report,
                    'title': self.pr_details.get('title', 'Unknown PR'),
                    'author': self.pr_details.get('author', 'Unknown Author'),
                    'base_branch': self.pr_details.get('base_branch', ''),
                    'head_branch': self.pr_details.get('head_branch', ''),
                    'pr_url': self.pr_details.get('pr_url', '')
                }
            )

            print(f"Successfully stored report for PR {repository}/{pr_id}")
            return True

        except Exception as e:
            print(f"Error storing report in DynamoDB: {e}")
            return False

def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """Lambda í•¸ë“¤ëŸ¬"""
    try:
        # ì‹¤í–‰ ID ì„¤ì •: ì´ì „ì˜ ì²­í¬ ë©”íƒ€ë°ì´í„°ì˜ execution_idë¥¼ ì‚¬ìš©
        # ê²°ê³¼ ì§‘ê³„ê¸° ì´ˆê¸°í™” - eventë¥¼ ì§ì ‘ ì „ë‹¬
        aggregator = ResultAggregator(event)
        print(f"Initialized ResultAggregator with execution_id: {getattr(aggregator, 'execution_id', 'NOT_SET')}")
        
        summary = aggregator.analyze_results()
        
        # DynamoDBì—ì„œ ë¡œë“œí•œ ë°ì´í„°ë¡œ ë³´ê³ ì„œ ìƒì„±
        markdown_report = aggregator.generate_markdown_report(summary)
        pr_comment = aggregator.prepare_pr_comment(summary)
        slack_message = aggregator.prepare_slack_message(summary)
        
        execution_id = getattr(aggregator, 'execution_id', f"fallback-{int(datetime.now().timestamp())}")

        report_stored = aggregator.store_report_in_dynamodb(markdown_report)
        print(f"Report stored in reports table: {report_stored}")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'summary': {
                    'total_files': summary.total_files,
                    'total_primary_files': summary.total_primary_files,
                    'total_reference_files': summary.total_reference_files,
                    'total_issues': summary.total_issues,
                    'severity_counts': summary.severity_counts,
                    'category_counts': summary.category_counts,
                    'previous_reviews_count': summary.previous_reviews_count,
                    'resolved_issues_count': summary.resolved_issues_count,
                    'new_issues_count': summary.new_issues_count,
                    'persistent_issues_count': summary.persistent_issues_count
                },
                'markdown_report': markdown_report,
                'pr_comment': pr_comment,
                'slack_message': slack_message,
                'pr_details': aggregator.pr_details,
                'reference_context': summary.reference_context,
                'execution_id': execution_id  # ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¨ ì‹¤í–‰ ID ì‚¬ìš©
            }, ensure_ascii=False)
        }
        
    except Exception as e:
        print(f"Error aggregating results: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e)
            })
        }