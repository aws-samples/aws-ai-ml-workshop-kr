import streamlit as st  # ëª¨ë“  streamlit ëª…ë ¹ì€ "st" aliasë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
import bedrock as glib  # ë¡œì»¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìŠ¤í¬ë¦½íŠ¸ì— ëŒ€í•œ ì°¸ì¡°
from langchain.callbacks import StreamlitCallbackHandler

st.set_page_config(layout="wide")
st.title("AWS Q&A Bot with Advanced RAG!")  # page ì œëª©

st.markdown('''- This chatbot is implemented using Amazon Bedrock Claude v2.1.''')
st.markdown('''- Integrated advanced RAG technology: **Hybrid Search, ReRanker, and Parent Document** techniques.''')
st.markdown('''- The original data is stored in Amazon OpenSearch, and the embedding model utilizes Amazon Titan.''')
st.markdown('''
            - You can find the source code in 
            [this Github](https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot/04_web_ui)
            ''')
# Store the initial value of widgets in session state
if "showing_option" not in st.session_state:
    st.session_state.showing_option = "Separately"
    # st.session_state.disabled = False
    # st.session_state.horizontal = False

with st.sidebar: # Sidebar ëª¨ë¸ ì˜µì…˜
    # st.title("Set showing method ğŸ‘‡")
    with st.container(height=170):
        st.radio(
            "Set showing method ğŸ‘‡",
            ["Separately", "All at once"],
            captions = ["blah blah", "blah blah blah"],
            key="showing_option",
            # label_visibility=st.session_state.visibility,
            # disabled=st.session_state.disabled,
            # horizontal=st.session_state.horizontal,
        )

    st.title("Set parameter for your Bot ğŸ‘‡")
    parent = st.toggle("Parent_docs", disabled=st.session_state.showing_option=="All at once")
    reranker = st.toggle("Reranker", disabled=st.session_state.showing_option=="All at once")
    # hyde = st.toggle("HyDE")
    # custom_model = st.toggle("Custom Model")
    # alpha = st.slider('Alpha value of Hybrid Search: lexical(0.0) / semantic(1.0)', 0.0, 1.0, 0.5)

### 1) 'Separately' ì˜µì…˜ ì„ íƒí•œ ê²½ìš° ###
if st.session_state.showing_option == "Separately":
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "assistant", "content": "How can I help you?"}
        ]
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # ìœ ì €ê°€ ì“´ chatì„ queryë¼ëŠ” ë³€ìˆ˜ì— ë‹´ìŒ
    query = st.chat_input("Search documentation")
    if query:
        # Sessionì— ë©”ì„¸ì§€ ì €ì¥
        st.session_state.messages.append({"role": "user", "content": query})
        
        # UIì— ì¶œë ¥
        st.chat_message("user").write(query)
        
        # Streamlit callback handlerë¡œ bedrock streaming ë°›ì•„ì˜¤ëŠ” ì»¨í…Œì´ë„ˆ ì„¤ì •
        st_cb = StreamlitCallbackHandler(
            st.chat_message("assistant"), 
            collapse_completed_thoughts=True
            )
        # bedrock.pyì˜ invoke í•¨ìˆ˜ ì‚¬ìš©
        response = glib.invoke(
            query=query, 
            streaming_callback=st_cb, 
            parent=parent, 
            reranker=reranker
            )
        # response ë¡œ ë©”ì„¸ì§€, ë§í¬, ë ˆí¼ëŸ°ìŠ¤(source_documents) ë°›ì•„ì˜¤ê²Œ ì„¤ì •ëœ ê²ƒì„ ë³€ìˆ˜ë¡œ ì €ì¥
        answer = response[0]
        contexts1 = response[1] # semantic
        contexts2 = response[2] # lexical
        contexts3 = response[3] # reranker
        contexts4 = response[4] # similar_docs

        # UI ì¶œë ¥
        st.chat_message("assistant").write(answer)
        
        with st.chat_message("assistant"): 
            with st.expander("ì •í™•ë„ ë³„ ë‹µë³€ ë³´ê¸° (semantic) â¬‡ï¸"):
                tab_titles = []
                tab_contents = {}
                for i, context in enumerate(contexts1):
                    title = str(context[0])
                    tab_titles.append(title)
                    tab_contents[title] = context[1][0]
                tabs = st.tabs(tab_titles)
                for i, tab in enumerate(tabs):
                    with tab:
                        st.header(tab_titles[i])
                        st.write(tab_contents[tab_titles[i]])

        with st.chat_message("assistant"): 
            with st.expander("ì •í™•ë„ ë³„ ë‹µë³€ ë³´ê¸° (lexical) â¬‡ï¸"):
                tab_titles = []
                tab_contents = {}
                for i, context in enumerate(contexts2):
                    title = str(context[0])
                    tab_titles.append(title)
                    tab_contents[title] = context[1][0]
                tabs = st.tabs(tab_titles)
                for i, tab in enumerate(tabs):
                    with tab:
                        st.header(tab_titles[i])
                        st.write(tab_contents[tab_titles[i]])

        with st.chat_message("assistant"): 
            with st.expander("ì •í™•ë„ ë³„ ë‹µë³€ ë³´ê¸° (reranker) â¬‡ï¸"):
                tab_titles = []
                tab_contents = {}
                for i, context in enumerate(contexts3):
                    title = str(context[0])
                    tab_titles.append(title)
                    tab_contents[title] = context[1][0]
                tabs = st.tabs(tab_titles)
                for i, tab in enumerate(tabs):
                    with tab:
                        st.header(tab_titles[i])
                        st.write(tab_contents[tab_titles[i]])

        # Session ë©”ì„¸ì§€ ì €ì¥
        st.session_state.messages.append({"role": "assistant", "content": answer})
        st.session_state.messages.append({"role": "assistant", "content": contexts1})
        
        # Thinkingì„ completeë¡œ ìˆ˜ë™ìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤Œ
        st_cb._complete_current_thought()

### 2) 'All at once' ì˜µì…˜ ì„ íƒí•œ ê²½ìš° ###
else:
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "assistant", "content": "How can I help you?"}
        ]
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # ìœ ì €ê°€ ì“´ chatì„ queryë¼ëŠ” ë³€ìˆ˜ì— ë‹´ìŒ
    query = st.chat_input("Search documentation")
    if query:
        # Sessionì— ë©”ì„¸ì§€ ì €ì¥
        st.session_state.messages.append({"role": "user", "content": query})
        
        # UIì— ì¶œë ¥
        st.chat_message("user").write(query)

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown('''#### parent=:red[False], reranker=:red[False]''')
        with col2:
            st.markdown('''#### parent=:green[True], reranker=:red[False]''')
        with col3:
            st.markdown('''#### parent=:red[False], reranker=:green[True]''')
        with col4:
            st.markdown('''#### parent=:green[True], reranker=:green[True]''')
        
        with col1:
            # Streamlit callback handlerë¡œ bedrock streaming ë°›ì•„ì˜¤ëŠ” ì»¨í…Œì´ë„ˆ ì„¤ì •
            st_cb = StreamlitCallbackHandler(
                st.chat_message("assistant"), 
                collapse_completed_thoughts=True
                )
            answer = glib.invoke(
                query=query, 
                streaming_callback=st_cb, 
                parent=False, 
                reranker=False
                )[0]
            # st.subheader("parent=False, reranker=False â¬‡ï¸")
            st.write(answer)
            st_cb._complete_current_thought() # Thinkingì„ completeë¡œ ìˆ˜ë™ìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤Œ
        with col2:
            # Streamlit callback handlerë¡œ bedrock streaming ë°›ì•„ì˜¤ëŠ” ì»¨í…Œì´ë„ˆ ì„¤ì •
            st_cb = StreamlitCallbackHandler(
                st.chat_message("assistant"), 
                collapse_completed_thoughts=True
                )
            answer = glib.invoke(
                query=query, 
                streaming_callback=st_cb, 
                parent=True, 
                reranker=False
                )[0]
            # st.subheader("parent=True, reranker=False â¬‡ï¸")
            st.write(answer)
            st_cb._complete_current_thought() # Thinkingì„ completeë¡œ ìˆ˜ë™ìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤Œ
        with col3:
            # Streamlit callback handlerë¡œ bedrock streaming ë°›ì•„ì˜¤ëŠ” ì»¨í…Œì´ë„ˆ ì„¤ì •
            st_cb = StreamlitCallbackHandler(
                st.chat_message("assistant"), 
                collapse_completed_thoughts=True
                )
            answer = glib.invoke(
                query=query, 
                streaming_callback=st_cb, 
                parent=False, 
                reranker=True
                )[0]
            # st.subheader("parent=False, reranker=True â¬‡ï¸")
            st.write(answer)
            st_cb._complete_current_thought() # Thinkingì„ completeë¡œ ìˆ˜ë™ìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤Œ
        with col4:
            # Streamlit callback handlerë¡œ bedrock streaming ë°›ì•„ì˜¤ëŠ” ì»¨í…Œì´ë„ˆ ì„¤ì •
            st_cb = StreamlitCallbackHandler(
                st.chat_message("assistant"), 
                collapse_completed_thoughts=True
            )
            answer = glib.invoke(
                query=query, 
                streaming_callback=st_cb, 
                parent=True, 
                reranker=True
                )[0]
            # st.subheader("parent=True, reranker=True â¬‡ï¸")
            st.write(answer)
            st_cb._complete_current_thought() # Thinkingì„ completeë¡œ ìˆ˜ë™ìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤Œ

        # Session ë©”ì„¸ì§€ ì €ì¥
        st.session_state.messages.append({"role": "assistant", "content": answer})
        # st.session_state.messages.append({"role": "assistant", "content": contexts})
        
        # UI ì¶œë ¥
        # st.chat_message("assistant").write(answer)
        # st.chat_message("assistant").write(contexts)
        # st.chat_message("assistant").write(ref)