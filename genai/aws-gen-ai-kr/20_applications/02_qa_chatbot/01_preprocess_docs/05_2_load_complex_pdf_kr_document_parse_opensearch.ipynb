{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02129bd0-af47-4fd6-91af-81613fc40511",
   "metadata": {},
   "source": [
    "# Preprocessing for complex PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334e485-ef50-4ba1-b86e-b6a80c2ee676",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefce95b-b2aa-4524-92bc-28b12699ec84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b9aa2-a15a-46f5-925d-0f89afb2a611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def add_python_path(module_path):\n",
    "    if os.path.abspath(module_path) not in sys.path:\n",
    "        sys.path.append(os.path.abspath(module_path))\n",
    "        print(f\"python path: {os.path.abspath(module_path)} is added\")\n",
    "    else:\n",
    "        print(f\"python path: {os.path.abspath(module_path)} already exists\")\n",
    "    print(\"sys.path: \", sys.path)\n",
    "\n",
    "module_path = \"../../..\"\n",
    "add_python_path(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508a21d-0d22-4adc-b928-e6c0bccaa9a6",
   "metadata": {},
   "source": [
    "## 1. Create Bedrock client\n",
    "Amazon Bedrock을 API로 활용하기 위한 Client를 설정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8e4df-ef07-4cb0-b76b-cc327073425c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f222a-2cdc-490e-b1e4-43429414dcd9",
   "metadata": {},
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10630ae-e48d-4ae3-ae4d-187d5bd232f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ecb09e-2662-4cee-8c4b-c4ac9228fe3d",
   "metadata": {},
   "source": [
    "## 2. Titan Embedding v2 및 LLM 인 Claude-v3-sonnet 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f351fdc-ed28-4b00-9150-e755e51932f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM 로딩 (Claude-v3-sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf2bc3-a873-4bd6-838b-6ce4cb9fe879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585f9ee-4de7-4a16-b219-f3bde8d84b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_text = ChatBedrock(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-Sonnet\"),\n",
    "    client=boto3_bedrock,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 2048,\n",
    "        \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "        # \"temperature\": 0,\n",
    "        # \"top_k\": 350,\n",
    "        # \"top_p\": 0.999\n",
    "    }\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba6e5b8-f40f-4bc8-a823-53a280ecea66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedding 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad9168-72e3-4906-8abe-f5a23638cfde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069404eb-4daf-4ff9-aadd-0ef694df22d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_emb = BedrockEmbeddings(\n",
    "    client=boto3_bedrock,\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Titan-Text-Embeddings-V2\")\n",
    ")\n",
    "dimension = 1024 #1536\n",
    "print(\"Bedrock Embeddings Model Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de224b4a-05ae-4f40-82a4-1109b33ff452",
   "metadata": {},
   "source": [
    "## 3. 데이터 준비 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c35df1-4183-4285-bfa7-17bff9fe9169",
   "metadata": {},
   "source": [
    "### Extract Text, Table and Image from documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96566e8f-d364-4954-904a-8a6e6b9b6898",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Upstage Document Parse\n",
    "- ### Prerequisites\n",
    "    - #### 해당 에셋은 complex document parsing을 위해 [Upstage Document Parse](https://aws.amazon.com/marketplace/pp/prodview-lv5bnpdco7xoq?sr=0-4&ref_=beagle&applicationId=AWSMPContessa)을 이용합니다. \n",
    "    - Upstage Document Parse는 AWS Marketplace에 등록되어 있으며, Amazon SageMaker Endpoint 생성을 통해 사용하실 수 있습니다.\n",
    "        - Endpoint 생성 방식은 **[\"05_1_create_endpoint_upstage_document_parse.ipynb\"](./05_1_create_endpoint_upstage_document_parse.ipynb)** 참고하시기 바랍니다.\n",
    "- ### **[API Description](https://developers.upstage.ai/docs/apis/document-parse)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd7d69-23ea-4300-9eea-aa62e2eafd36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from glob import glob\n",
    "from requests_toolbelt import MultipartEncoder\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "from utils.common_utils import to_pickle, load_pickle\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc5212-bd50-40f5-bdd9-7c273084c2e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "**엔드포인트 이름을 입력합니다.**\n",
    "- Endpoint 생성 방식은 **[\"05_1_create_endpoint_upstage_document_parse.ipynb\"](./05_1_create_endpoint_upstage_document_parse.ipynb)** 참고하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deebadd-be84-453d-8053-28ae61c5f4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_document_parser = \"Upstage-Document-Parse-2024-10-17-21-53-42-914\"#\"<your endpont>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5963db-35f0-458e-b905-c6a3b0a17bf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "**추출할 문서의 위치를 입력합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a906645-1b52-45c1-98ea-32b4a415d7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"./data/complex_pdf/school_edu_guide.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b2992-37a5-40a5-a6c7-b80acfc05d05",
   "metadata": {
    "tags": []
   },
   "source": [
    "**추출된 이미지가 저장될 위치를 입력합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17f8f1-3d94-442d-8cc2-80a1e055c253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = \"./fig\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4faaeaf-7e50-4d39-8edd-8943d069ec79",
   "metadata": {},
   "source": [
    "**문서 파싱을 시작합니다 (약 1분 소요)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3916546-2d7e-4456-8c86-9ddc141f9017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isdir(image_path): shutil.rmtree(image_path)\n",
    "os.mkdir(image_path)\n",
    "\n",
    "runtime_sm_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "# Prepare multipart form data\n",
    "encoder = MultipartEncoder(\n",
    "    fields={\n",
    "        'document': (os.path.basename(file_path), open(file_path, 'rb'), 'application/pdf'),\n",
    "        'model': 'document-parse',\n",
    "        'ocr': 'auto',\n",
    "        'coordinates': 'true',\n",
    "        'output_formats': '[\"markdown\"]', #'[\"text\", \"html\", \"markdown\"]',\n",
    "        'base64_encoding': '[\"table\", \"figure\"]'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Get the raw bytes of the multipart form data\n",
    "body = encoder.to_string()\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_document_parser,\n",
    "    ContentType=encoder.content_type,  # This will be 'multipart/form-data; boundary=...'\n",
    "    Body=body\n",
    ")\n",
    "\n",
    "result = response[\"Body\"].read()\n",
    "parse_output = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f3085-237c-48e4-8977-964306d57dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_pickle(parse_output, \"parse_output.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6caf406-e9d6-41cf-aed5-f032c1e8ab5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parse_output = load_pickle(\"parse_output.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856d792-adf0-48b5-9c74-37cd72a5de94",
   "metadata": {
    "tags": []
   },
   "source": [
    "**문서 파싱 후처리를 합니다.**\n",
    "- docs: 문서는 페이지별 정리\n",
    "- texts: markdown 형식의 전체 texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2a90b-75ce-40b9-8d6e-7627a97f5808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocessing(**kwargs):\n",
    "    \n",
    "    category = kwargs[\"category\"]\n",
    "    markdown = kwargs[\"markdown\"]\n",
    "    base64_encoding = kwargs[\"base64_encoding\"]\n",
    "    coordinates = kwargs[\"coordinates\"]\n",
    "    page = kwargs[\"page\"]\n",
    "    docs = kwargs[\"docs\"]\n",
    "    \n",
    "    if page in docs: \n",
    "        docs[page].append({\"category\": category, \"markdown\": markdown, \"base64_encoding\": base64_encoding, \"coordinates\": coordinates})\n",
    "    else:\n",
    "        docs[page] = [{\"category\": category, \"markdown\": markdown, \"base64_encoding\": base64_encoding, \"coordinates\": coordinates}]\n",
    "        \n",
    "    return docs\n",
    "\n",
    "def extract_image_table(**kwargs):\n",
    "    \n",
    "    image_path = kwargs[\"image_path\"]\n",
    "    file_path = kwargs[\"file_path\"]\n",
    "    \n",
    "    image_tmp_path = os.path.join(image_path, \"tmp\")\n",
    "    if os.path.isdir(image_tmp_path): shutil.rmtree(image_tmp_path)\n",
    "    os.mkdir(image_tmp_path)\n",
    "\n",
    "    # from pdf to image\n",
    "    pages = convert_from_path(file_path)\n",
    "    for i, page in enumerate(pages):\n",
    "        print (f'pdf page {i}, size: {page.size}')    \n",
    "        page.save(f'{image_tmp_path}/{str(i+1)}.jpg', \"JPEG\")\n",
    "        \n",
    "    return image_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad23f4-1c9a-4e4f-b48e-42e26895a996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = {}\n",
    "texts = [\n",
    "    Document(\n",
    "        page_content=parse_output[\"content\"][\"markdown\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "## extract_image_table\n",
    "image_tmp_path = extract_image_table(\n",
    "    image_path=image_path,\n",
    "    file_path=file_path\n",
    ")\n",
    "\n",
    "for idx, value in enumerate(parse_output[\"elements\"]):\n",
    "      \n",
    "    category = value[\"category\"]\n",
    "    markdown = value[\"content\"][\"markdown\"]\n",
    "    page = value[\"page\"]\n",
    "    \n",
    "    if category in [\"figure\", \"table\"]:\n",
    "        \n",
    "        base64_encoding = value[\"base64_encoding\"]    \n",
    "        coordinates = value[\"coordinates\"]    \n",
    "        img = Image.open(BytesIO(base64.b64decode(base64_encoding)))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        img = cv2.imread(f'{image_tmp_path}/{page}.jpg')\n",
    "        h, w, c = img.shape\n",
    "        \n",
    "        #crob using cv2: img[y: y + h, x: x + w]\n",
    "        crop_img = img[math.ceil(coordinates[0][\"y\"]*h):math.ceil(coordinates[3][\"y\"]*h), \\\n",
    "                       math.ceil(coordinates[0][\"x\"]*w):math.ceil(coordinates[1][\"x\"]*w)]\n",
    "                \n",
    "        crob_image_path = f'{image_path}/element-{idx}.jpg'\n",
    "        cv2.imwrite(crob_image_path, crop_img)\n",
    "\n",
    "        print (f'page_number: {page}')\n",
    "        print (\"==\")\n",
    "\n",
    "        h_crop, w_crop, _ = crop_img.shape\n",
    "        image_token = w_crop*h_crop/750\n",
    "        print (f'image: {crob_image_path}, shape: {img.shape}, image_token_for_claude3: {image_token}' )\n",
    "        \n",
    "    else:\n",
    "        base64_encoding= \"\"\n",
    "        coordinates=\"\"\n",
    "\n",
    "    docs = postprocessing(\n",
    "        docs=docs,\n",
    "        page=page,\n",
    "        category=category,\n",
    "        markdown=markdown,\n",
    "        base64_encoding=base64_encoding,\n",
    "        coordinates=coordinates\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb16fd2a-1983-462d-94d8-4c62e81ef28c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summarization of table and image\n",
    "- **Image 및 Table 내용을 text 기반으로 요약합니다.**\n",
    "- **Image 및 Table이 포함된 페이지의 내용을 추가 정보로 사용하여 문맥을 고려한 요약을 합니다.**\n",
    "- **이 과정은 image 및 table 정보를 embedding 기반 모델로 검색 가능하게 합니다.**\n",
    "- BedrockChat with claude3: https://medium.com/@dminhk/building-with-anthropics-claude-3-on-amazon-bedrock-and-langchain-%EF%B8%8F-2b842f9c0ca8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca57b50-b89e-4146-912c-a4fcc75168ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a0e49-749d-41ad-8dc6-164cf1196cdf",
   "metadata": {},
   "source": [
    "**요약 대상과 그에 대한 컨텍스트 정보를 구분합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3ee3b-ef36-4467-b66b-aa398da84fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_for_summary = []\n",
    "for page, elements in docs.items():\n",
    "    \n",
    "    elements = [element for element in elements if element[\"category\"] != \"footer\"]\n",
    "    print (f'page: {page}, # elements: {len(elements)}')\n",
    "    \n",
    "    for idx, element in enumerate(elements):\n",
    "        \n",
    "        category, markdown = element[\"category\"], element[\"markdown\"]\n",
    "        print (f'element idx: {idx}, category: {element[\"category\"]}')\n",
    "        \n",
    "        elements_copy = copy.deepcopy(elements)\n",
    "        if category in (\"figure\", \"table\"):  \n",
    "            \n",
    "            summary_target = elements_copy.pop(idx)\n",
    "            contexts_markdown = '\\n'.join([context[\"markdown\"] for context in elements_copy])\n",
    "            docs_for_summary.append(\n",
    "                {\n",
    "                    \"target_category\": summary_target[\"category\"],\n",
    "                    \"target_base64\": summary_target[\"base64_encoding\"],\n",
    "                    \"target_markdown\": summary_target[\"markdown\"],\n",
    "                    \"contexts_markdown\": contexts_markdown\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53543a-fd08-4dfb-bf09-4b5f36fb9e09",
   "metadata": {},
   "source": [
    "**정보를 요약합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd00eac-01b9-4677-936d-fee8c3721371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import botocore\n",
    "from utils.common_utils import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f766cff-12e0-4d9a-aea1-4678ef94228d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant tasked with describing table and image.\"\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "\n",
    "human_prompt = [\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": \"data:image/png;base64,\" + \"{image_base64}\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": '''\n",
    "                 <contexts>\n",
    "                 {contexts}\n",
    "                 </contexts>\n",
    "                 \n",
    "                 주어진 이미지 또는 테이블을 자세히 분석하고 주어진 contexts를 참고하여 다음 정보를 추출해주세요:\n",
    "                 \n",
    "                 1. <title> 태그 안의 제목을 정확히 제시해주세요.\n",
    "                 2. <summary> 태그 안의 내용을 요약해주세요.\n",
    "                 3. <entities> 태그 안의 모든 항목을 나열하고, 각 항목에 대한 간단한 설명을 제공해주세요.\n",
    "                 4. <hypothetical_questions> 태그 안의 질문들을 모두 나열해주세요.\n",
    "                모든 정보는 원본 내용을 정확히 반영하되, 필요한 경우 약간의 추가 설명을 덧붙여 이해를 돕도록 해주세요.\n",
    "        '''\n",
    "    },\n",
    "]\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbc99a-bcb3-4c6b-83fa-232a1ce2b3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_template,\n",
    "        human_message_template\n",
    "    ]\n",
    ")\n",
    "\n",
    "summarize_chain = prompt | llm_text | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f1844-a222-4807-8143-72cd72bb949e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry(total_try_cnt=5, sleep_in_sec=10, retryable_exceptions=(botocore.exceptions.EventStreamError))\n",
    "def summary_img(summarize_chain, image_base64, contexts):\n",
    "\n",
    "    img = Image.open(BytesIO(base64.b64decode(image_base64)))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    stream = summarize_chain.stream(\n",
    "        {\n",
    "            \"image_base64\": image_base64,\n",
    "            \"contexts\": contexts\n",
    "        }\n",
    "    )\n",
    "    response = \"\"\n",
    "    for chunk in stream: response += chunk\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be579c75-38f9-4c1b-a44a-7ca930f4a4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summaries = []\n",
    "for idx, doc in enumerate(docs_for_summary):\n",
    "    summary = summary_img(summarize_chain, doc[\"target_base64\"], doc[\"contexts_markdown\"])\n",
    "    summaries.append(summary)\n",
    "    print (\"\\n==\")\n",
    "    print (idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4109e-3510-4924-9398-c8f1b4ba9148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "if verbose:\n",
    "    for doc, summary in zip(docs_for_summary, summaries):\n",
    "\n",
    "        print (\"============================\")\n",
    "        img = Image.open(BytesIO(base64.b64decode(doc[\"target_base64\"])))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        print (f'Summary: {summary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18256cfd-9cf8-4e92-a2ae-c9b921db773c",
   "metadata": {},
   "source": [
    "`요약`된 내용을 Document의 `page_content`로, `OCR`결과는 metadata의 `origin_image`로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4e057-b74a-4cf2-bcbd-ad0cc4d70638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_preprocessed = []\n",
    "\n",
    "for doc, summary in zip(docs_for_summary, summaries):\n",
    "    \n",
    "    metadata = {}\n",
    "    metadata[\"markdown\"] = doc[\"target_markdown\"]\n",
    "    metadata[\"category\"] = \"Image\"\n",
    "    metadata[\"image_base64\"] = doc[\"target_base64\"]\n",
    "    \n",
    "    doc = Document(\n",
    "        page_content=summary,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    images_preprocessed.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a499e71-7d77-4a16-b0bb-67d9fdb3e50b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_preprocessed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6c937-5a11-4907-b5bb-bee6ad0486a7",
   "metadata": {},
   "source": [
    "### For tables (summary for markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea346286-df49-4ca8-ac75-c00497f17239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = [doc for doc in docs_for_summary if doc[\"target_category\"] == \"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cd053-ef1e-41f7-ac42-868b4d28cd8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_prompt = [\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": '''\n",
    "                 Here is the table: <table>{table}</table>\n",
    "                 Given table, give a concise summary.\n",
    "                 Don't insert any XML tag such as <table> and </table> when answering.\n",
    "                 Write in Korean.\n",
    "        '''\n",
    "    },\n",
    "]\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc06b5-2c72-4b21-bf1b-b467ee2816b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_template,\n",
    "        human_message_template\n",
    "    ]\n",
    ")\n",
    "\n",
    "#summarize_chain = prompt | llm_text | StrOutputParser()\n",
    "summarize_chain = {\"table\": lambda x:x} | prompt | llm_text | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32a3e7-3c5b-485a-8a35-87b148b8b5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_info = [t[\"target_markdown\"] for t in tables]\n",
    "table_summaries = summarize_chain.batch(table_info, config={\"max_concurrency\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c99f22-ed67-4367-8496-5cc180f945ac",
   "metadata": {},
   "source": [
    "`요약`된 내용을 Document의 `page_content`로, `parsed table`은 metadata의 `origin_table`로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0772898-1eb4-48a3-be22-d77571b23ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables_preprocessed = []\n",
    "\n",
    "for doc, summary in zip(tables, table_summaries):\n",
    "    \n",
    "    metadata = {}\n",
    "    metadata[\"origin_table\"] = doc[\"target_markdown\"]\n",
    "    metadata[\"text_as_html\"] = doc[\"target_markdown\"]\n",
    "    metadata[\"category\"] = \"Table\"\n",
    "    metadata[\"image_base64\"] = doc[\"target_base64\"]\n",
    "    \n",
    "    doc = Document(\n",
    "        page_content=summary,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    tables_preprocessed.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb6b75-5303-4b7b-891e-eba2331c90e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5aaa7-fa08-4599-bb80-7b927e5f32dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "index = 0\n",
    "if verbose:\n",
    "    for table, summary in zip(tables, table_summaries):\n",
    "\n",
    "        #if table_as_image:\n",
    "        #page_contents, table_as_html, img_base64 = table\n",
    "        category, img_base64, table_as_html, page_contents = table[\"target_category\"], table[\"target_base64\"], table[\"target_markdown\"], table[\"target_markdown\"]\n",
    "        #else: page_contents, table_as_html = table\n",
    "\n",
    "        print (\"============================\")\n",
    "        print (index)\n",
    "        print (f'table: {page_contents}')\n",
    "        print (\"----------------------------\")\n",
    "        print (f'summary: {summary}')\n",
    "        print (\"----------------------------\")\n",
    "\n",
    "        print (\"----------------------------\")\n",
    "        if img_base64 is not None:\n",
    "            print (\"image\")\n",
    "            img = Image.open(BytesIO(base64.b64decode(img_base64)))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fbd15-2a30-4096-8916-d03d15ca4fb6",
   "metadata": {},
   "source": [
    "## 4. Index 생성\n",
    "Document로 부터 추출한 text, table, 그리고 image 정보를 Amazon OpenSearch에 저장합니다. (인덱싱)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d684e-0963-4f85-a725-42842eb9d46e",
   "metadata": {},
   "source": [
    "### Index 이름 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079275c-6262-44bb-8bc6-0efffff1620b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6173a-8a43-49a8-945d-dbc6014a485b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region=boto3.Session().region_name\n",
    "pm = parameter_store(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657be39-a01d-4fe8-a6d8-d4bc3334ea6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = \"complex-doc-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c8b5d-92a7-4400-a579-699e482cb68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pm.put_params(\n",
    "    key=\"opensearch_index_name\",\n",
    "    value=f'{index_name}',\n",
    "    overwrite=True,\n",
    "    enc=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32323202-e3a9-45ed-820c-a7d1087ff2e3",
   "metadata": {},
   "source": [
    "### Index 스키마 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45ec52-8aff-4513-bc17-2f613b38910c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_body = {\n",
    "    'settings': {\n",
    "        'analysis': {\n",
    "            'analyzer': {\n",
    "                'my_analyzer': {\n",
    "                         'char_filter':['html_strip'],\n",
    "                    'tokenizer': 'nori',\n",
    "                    'filter': [\n",
    "                        #'nori_number',\n",
    "                        #'lowercase',\n",
    "                        #'trim',\n",
    "                        'my_nori_part_of_speech'\n",
    "                    ],\n",
    "                    'type': 'custom'\n",
    "                }\n",
    "            },\n",
    "            'tokenizer': {\n",
    "                'nori': {\n",
    "                    'decompound_mode': 'mixed',\n",
    "                    'discard_punctuation': 'true',\n",
    "                    'type': 'nori_tokenizer'\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"my_nori_part_of_speech\": {\n",
    "                    \"type\": \"nori_part_of_speech\",\n",
    "                    \"stoptags\": [\n",
    "                        \"J\", \"XSV\", \"E\", \"IC\",\"MAJ\",\"NNB\",\n",
    "                        \"SP\", \"SSC\", \"SSO\",\n",
    "                        \"SC\",\"SE\",\"XSN\",\"XSV\",\n",
    "                        \"UNA\",\"NA\",\"VCP\",\"VSV\",\n",
    "                        \"VX\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'index': {\n",
    "            'knn': True,\n",
    "            'knn.space_type': 'cosinesimil'  # Example space type\n",
    "        }\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'metadata': {\n",
    "                'properties': {\n",
    "                    'source': {'type': 'keyword'},\n",
    "                    'page_number': {'type':'long'},\n",
    "                    'category': {'type':'text'},\n",
    "                    'file_directory': {'type':'text'},\n",
    "                    'last_modified': {'type': 'text'},\n",
    "                    'type': {'type': 'keyword'},\n",
    "                    'image_base64': {'type':'text'},\n",
    "                    'origin_image': {'type':'text'},\n",
    "                    'origin_table': {'type':'text'},\n",
    "                }\n",
    "            },\n",
    "            'text': {\n",
    "                'analyzer': 'my_analyzer',\n",
    "                'search_analyzer': 'my_analyzer',\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'vector_field': {\n",
    "                'type': 'knn_vector',\n",
    "                'dimension': f\"{dimension}\" # Replace with your vector dimension\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679edbbd-44ca-4264-a4db-0ec489c58264",
   "metadata": {},
   "source": [
    "## 5. LangChain OpenSearch VectorStore 생성 \n",
    "### 선수 조건"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae8dd80-daf4-4e81-810b-b9e2f6611605",
   "metadata": {},
   "source": [
    "#### [중요] 아래에 aws parameter store 에 아래 인증정보가 먼저 입력되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47bf94-4bf9-4152-85f0-4babcb03edbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = pm.get_params(\n",
    "    key=\"opensearch_domain_endpoint\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_id = pm.get_params(\n",
    "    key=\"opensearch_user_id\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_password = pm.get_params(\n",
    "    key=\"opensearch_user_password\",\n",
    "    enc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319184c-4531-42c9-b400-77f53de071da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = opensearch_domain_endpoint\n",
    "rag_user_name = opensearch_user_id\n",
    "rag_user_password = opensearch_user_password\n",
    "\n",
    "http_auth = (rag_user_name, rag_user_password) # Master username, Master password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42526e7-d010-4e06-b158-3c86f9ea45e9",
   "metadata": {},
   "source": [
    "### OpenSearch Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3846a-ae55-45bd-98ac-f9280dda4409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.opensearch import opensearch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0fd7c-5fe2-42c6-bf58-f41930c37c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "\n",
    "os_client = opensearch_utils.create_aws_opensearch_client(\n",
    "    aws_region,\n",
    "    opensearch_domain_endpoint,\n",
    "    http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824d282-507e-44c9-bb02-a8978ae2d110",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 오픈 서치 인덱스 생성 \n",
    "- 오픈 서치에 해당 인덱스가 존재하면, 삭제 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9429551-11f9-41e8-8c28-8e743bc308dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_exists = opensearch_utils.check_if_index_exists(\n",
    "    os_client,\n",
    "    index_name\n",
    ")\n",
    "\n",
    "if index_exists:\n",
    "    opensearch_utils.delete_index(\n",
    "        os_client,\n",
    "        index_name\n",
    "    )\n",
    "\n",
    "opensearch_utils.create_index(os_client, index_name, index_body)\n",
    "index_info = os_client.indices.get(index=index_name)\n",
    "print(\"Index is created\")\n",
    "pprint(index_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233327e3-6c4b-43cb-a5dc-65caca085355",
   "metadata": {},
   "source": [
    "### 랭체인 인덱스 연결 오브젝트 생성\n",
    "\n",
    "- [langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a80eb-eb52-458b-b37d-39214937c188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ee773-6952-4d9d-baef-bb11491df90f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    "    is_aoss=False,\n",
    "    engine=\"faiss\",\n",
    "    space_type=\"l2\",\n",
    "    bulk_size=100000,\n",
    "    timeout=60\n",
    ")\n",
    "vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10817e5-7c5b-4109-ab59-0712b777c7b2",
   "metadata": {},
   "source": [
    "### Chunking Strategy: Parent documents\n",
    "* Chunk Size and Chunk Overlap Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1886286-3b05-4c38-b02b-d0581980ab4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.chunk import parant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3320e-b8f2-4987-999e-bce0aa8fec67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_chunk_size = 4096\n",
    "parent_chunk_overlap = 0\n",
    "\n",
    "child_chunk_size = 1024\n",
    "child_chunk_overlap = 256\n",
    "\n",
    "opensearch_parent_key_name = \"parent_id\"\n",
    "opensearch_family_tree_key_name = \"family_tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6c7d1-7da7-4a63-8be6-ff05e12f8a9a",
   "metadata": {},
   "source": [
    "* Parent Chunking\n",
    "    - create_parent_chunk() 아래와 같은 작업을 합니다.\n",
    "    - all_docs 에 있는 문서를 parent_chunk_size 만큼으로 청킹 합니다.\n",
    "    - Parent Chunk 에 두개의 메타 데이타를 생성 합니다.\n",
    "        - family_tree: parent\n",
    "        - parent_id : None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d871e-7872-4c7d-be6a-a5d1e1283a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_chunk_docs = parant_documents.create_parent_chunk(\n",
    "    docs=texts,\n",
    "    parent_id_key=opensearch_parent_key_name,\n",
    "    family_tree_id_key=opensearch_family_tree_key_name,\n",
    "    parent_chunk_size=parent_chunk_size,\n",
    "    parent_chunk_overlap=parent_chunk_overlap\n",
    ")\n",
    "print(f'Number of parent_chunk_docs= {len(parent_chunk_docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4019e2-6e15-4c91-bc05-028e0844a69e",
   "metadata": {},
   "source": [
    "* Insert doc into OpenSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82fd669-3b39-4752-a1ac-3860c339072d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parent_ids = vector_db.add_documents(\n",
    "    documents = parent_chunk_docs, \n",
    "    vector_field = \"vector_field\",\n",
    "    bulk_size = 1000000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6787ed2-5827-48f9-9a3d-8e393286b041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_count_docs = opensearch_utils.get_count(os_client, index_name)\n",
    "print(\"total count docs: \", total_count_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d143588-8c55-4ab5-8f2d-ee8fff66b98e",
   "metadata": {},
   "source": [
    "* 삽입된 Parent Chunk 의 첫번째를 확인 합니다. family_tree, parent_id 의 값을 확인 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7fd75-486c-467a-9f25-53115b9b4b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_opensearch_doc_info(response):\n",
    "    print(\"opensearch document id:\" , response[\"_id\"])\n",
    "    print(\"family_tree:\" , response[\"_source\"][\"metadata\"][\"family_tree\"])\n",
    "    print(\"parent document id:\" , response[\"_source\"][\"metadata\"][\"parent_id\"])\n",
    "    print(\"parent document text: \\n\" , response[\"_source\"][\"text\"])\n",
    "\n",
    "response = opensearch_utils.get_document(os_client, doc_id = parent_ids[0], index_name = index_name)\n",
    "show_opensearch_doc_info(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74fb6a-634b-473c-be68-529d1f2f0b1e",
   "metadata": {},
   "source": [
    "* Child Chunking\n",
    "    - 아래의 create_child_chunk() 는 다음과 같은 작업을 합니다.\n",
    "    - parent_chunk_docs 각각에 대해서 Child Chunk 를 생성 합니다. \n",
    "    - Child Chunk 에 두개의 메타 데이타를 생성 합니다.\n",
    "        - family_tree: child\n",
    "        - parent_id : parent 에 대한 OpenSearch document id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be16dd-5afa-4934-9825-bf14abb5e153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# child_chunk_docs = create_child_chunk(parent_chunk_docs[0:1], parent_ids)\n",
    "child_chunk_docs = parant_documents.create_child_chunk(\n",
    "    child_chunk_size=child_chunk_size,\n",
    "    child_chunk_overlap=child_chunk_overlap,\n",
    "    docs=parent_chunk_docs,\n",
    "    parent_ids_value=parent_ids,\n",
    "    parent_id_key=opensearch_parent_key_name,\n",
    "    family_tree_id_key=opensearch_family_tree_key_name\n",
    ")\n",
    "\n",
    "print(f\"Number of child_chunk_docs= {len(child_chunk_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983a34b-14f1-4974-ae1e-03ba737505be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_id = child_chunk_docs[0].metadata[\"parent_id\"]\n",
    "print(\"child's parent_id: \", parent_id)\n",
    "print(\"\\n###### Search parent in OpenSearch\")\n",
    "response = opensearch_utils.get_document(os_client, doc_id = parent_id, index_name = index_name)\n",
    "show_opensearch_doc_info(response)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6c9a5-730c-4862-9b33-ea0b31d230d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "child_chunk_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06bc16-aa1f-461b-981a-10b04f731acc",
   "metadata": {},
   "source": [
    "### Manipulate table and image for parent documents\n",
    "- set family_tree of table and image documents as \"parent_table\" and these kinds of types are included in searcable list (child, parent_table and parent_image) in parant document strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8773b0-390f-40bd-835b-8b987c67fa0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for table in tables_preprocessed:\n",
    "    table.metadata[\"family_tree\"], table.metadata[\"parent_id\"] = \"parent_table\", \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68476c8b-ca29-4efe-bf7f-138d0a55edf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image in images_preprocessed:\n",
    "    image.metadata[\"family_tree\"], image.metadata[\"parent_id\"] = \"parent_image\", \"NA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bb779-1148-441f-adc0-0fc860ae36b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merge text, table and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e7d39-5aca-429f-998d-70aabad37df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f1822-eadf-4488-92a9-01725df1f2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_preprocessed = list(chain(child_chunk_docs, tables_preprocessed, images_preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70feee-0e0b-4e74-b65e-099ac0b1dbdd",
   "metadata": {},
   "source": [
    "* Insert doc into OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07b977-ce5d-41e4-bfbf-54113fdecb17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "child_ids = vector_db.add_documents(\n",
    "    documents=docs_preprocessed, \n",
    "    vector_field = \"vector_field\",\n",
    "    bulk_size=1000000\n",
    ")\n",
    "\n",
    "print(\"length of child_ids: \", len(child_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4223fa-ca44-4197-a1cd-2a76151df2be",
   "metadata": {},
   "source": [
    "## 6. 검색 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb6e42-506d-4152-949e-cb9e8abf9b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import qa_chain\n",
    "from utils.rag import prompt_repo, show_context_used\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "from utils.rag import retriever_utils, OpenSearchHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421e6fd-6070-4009-8138-59e8331d9946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_hybrid_retriever = OpenSearchHybridSearchRetriever(\n",
    "    os_client=os_client,\n",
    "    index_name=index_name,\n",
    "    llm_text=llm_text, # llm for query augmentation in both rag_fusion and HyDE\n",
    "    llm_emb=llm_emb, # Used in semantic search based on opensearch \n",
    "\n",
    "    # hybird-search debugger\n",
    "    #hybrid_search_debugger = \"semantic\", #[semantic, lexical, None]\n",
    "    \n",
    "    # option for lexical\n",
    "    minimum_should_match=0,\n",
    "    filter=[],\n",
    "\n",
    "    # option for search\n",
    "    fusion_algorithm=\"RRF\", # [\"RRF\", \"simple_weighted\"], rank fusion 방식 정의\n",
    "    ensemble_weights=[.51, .49], # [for semantic, for lexical], Semantic, Lexical search 결과에 대한 최종 반영 비율 정의\n",
    "    reranker=False, # enable reranker with reranker model\n",
    "    #reranker_endpoint_name=endpoint_name, # endpoint name for reranking model\n",
    "    parent_document=True, # enable parent document\n",
    "    \n",
    "    # option for complex pdf consisting of text, table and image\n",
    "    complex_doc=True,\n",
    "    \n",
    "    # option for async search\n",
    "    async_mode=True,\n",
    "\n",
    "    # option for output\n",
    "    k=7, # 최종 Document 수 정의\n",
    "    verbose=False,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9f5ca-08a2-4656-ba5b-0ead7565182d",
   "metadata": {},
   "source": [
    "### 하이브리드 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68740c-2dc3-404c-a2e5-08f2e65481cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#query = \"자동조기 상환\"\n",
    "query = \"디지털 성범죄\"\n",
    "search_hybrid_result, tables, images = opensearch_hybrid_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1553b-2f68-4cc8-940e-75f33fed0b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_context_used(search_hybrid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d949596-9271-4cf4-9488-d2c6fa30c577",
   "metadata": {},
   "source": [
    "# SageMaker Processing Job 이용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b042d5-ef95-45e9-8ca2-d7c521db56c8",
   "metadata": {},
   "source": [
    "## 1. scripy 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b6a72-de65-4599-a42f-d5c67cd95453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./src/preprocessing.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import boto3\n",
    "import shutil\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "from utils import bedrock\n",
    "from itertools import chain\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.schema import Document\n",
    "from pdf2image import convert_from_path\n",
    "from requests_toolbelt import MultipartEncoder\n",
    "\n",
    "import botocore\n",
    "from utils.common_utils import retry\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "from utils.chunk import parant_documents\n",
    "from utils.opensearch import opensearch_utils\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "class preprocess():\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        \n",
    "        self.args = args\n",
    "        self.proc_prefix = self.args.proc_prefix #'/opt/ml/processing'\n",
    "        \n",
    "        self.input_dir = os.path.join(self.proc_prefix, \"input\")\n",
    "        self.output_dir = os.path.join(self.proc_prefix, \"output\")\n",
    "        os.makedirs(self.input_dir, exist_ok=True)\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        print (os.listdir(self.input_dir))\n",
    "        \n",
    "        ############# 수정\n",
    "        #self.file_path = os.path.join(self.input_dir, \"sample-2.pdf\")\n",
    "        self.file_path = os.path.join(self.input_dir, self.args.file_name)\n",
    "        #\"./data/complex_pdf/sample-2.pdf\"\n",
    "        ###############\n",
    "        \n",
    "    def _initialization(self, ):\n",
    "        \n",
    "        self.boto3_bedrock = bedrock.get_bedrock_client(\n",
    "            assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "            endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "            region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "        )\n",
    "        \n",
    "        self.llm_text = ChatBedrock(\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-Sonnet\"),\n",
    "            client=self.boto3_bedrock,\n",
    "            streaming=True,\n",
    "            callbacks=[StreamingStdOutCallbackHandler()],\n",
    "            model_kwargs={\n",
    "                \"max_tokens\": 2048,\n",
    "                \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.llm_emb = BedrockEmbeddings(\n",
    "            client=self.boto3_bedrock,\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Titan-Text-Embeddings-V2\")\n",
    "        )\n",
    "        self.dimension = 1024\n",
    "        \n",
    "    def _document_parsing(self, ):\n",
    "        \n",
    "        runtime_sm_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "        # Prepare multipart form data\n",
    "        encoder = MultipartEncoder(\n",
    "            fields={\n",
    "                'document': (os.path.basename(self.file_path), open(self.file_path, 'rb'), 'application/pdf'),\n",
    "                'model': 'document-parse',\n",
    "                'ocr': 'auto',\n",
    "                'coordinates': 'true',\n",
    "                'output_formats': '[\"markdown\"]', #'[\"text\", \"html\", \"markdown\"]',\n",
    "                'base64_encoding': '[\"table\", \"figure\"]'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Get the raw bytes of the multipart form data\n",
    "        body = encoder.to_string()\n",
    "\n",
    "        response = runtime_sm_client.invoke_endpoint(\n",
    "            EndpointName=self.args.endpoint_document_parser,\n",
    "            ContentType=encoder.content_type,  # This will be 'multipart/form-data; boundary=...'\n",
    "            Body=body\n",
    "        )\n",
    "\n",
    "        result = response[\"Body\"].read()\n",
    "        parse_output = json.loads(result)\n",
    "        \n",
    "        return parse_output\n",
    "    \n",
    "    def _extract_image_table(self, parse_output):\n",
    "        \n",
    "        def processing(**kwargs):\n",
    "    \n",
    "            category = kwargs[\"category\"]\n",
    "            markdown = kwargs[\"markdown\"]\n",
    "            base64_encoding = kwargs[\"base64_encoding\"]\n",
    "            coordinates = kwargs[\"coordinates\"]\n",
    "            page = kwargs[\"page\"]\n",
    "            docs = kwargs[\"docs\"]\n",
    "\n",
    "            if page in docs: \n",
    "                docs[page].append(\n",
    "                    {\n",
    "                        \"category\": category,\n",
    "                         \"markdown\": markdown,\n",
    "                         \"base64_encoding\": base64_encoding,\n",
    "                         \"coordinates\": coordinates\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                docs[page] = [\n",
    "                    {\n",
    "                        \"category\": category,\n",
    "                        \"markdown\": markdown,\n",
    "                        \"base64_encoding\": base64_encoding,\n",
    "                        \"coordinates\": coordinates\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "            return docs\n",
    "\n",
    "        def image_conversion(**kwargs):\n",
    "\n",
    "            image_path = kwargs[\"image_path\"]\n",
    "            file_path = kwargs[\"file_path\"]\n",
    "\n",
    "            image_tmp_path = os.path.join(image_path, \"tmp\")\n",
    "            if os.path.isdir(image_tmp_path): shutil.rmtree(image_tmp_path)\n",
    "            os.mkdir(image_tmp_path)\n",
    "\n",
    "            # from pdf to image\n",
    "            pages = convert_from_path(file_path)\n",
    "            for i, page in enumerate(pages):\n",
    "                print (f'pdf page {i}, size: {page.size}')    \n",
    "                page.save(f'{image_tmp_path}/{str(i+1)}.jpg', \"JPEG\")\n",
    "\n",
    "            return image_tmp_path\n",
    "        \n",
    "        image_path = os.path.join(self.input_dir, \"fig\")\n",
    "        if os.path.isdir(image_path): shutil.rmtree(image_path)\n",
    "        os.mkdir(image_path)\n",
    "        \n",
    "        docs = {}\n",
    "        texts = [\n",
    "            Document(\n",
    "                page_content=parse_output[\"content\"][\"markdown\"]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        ## extract_image_table\n",
    "        image_tmp_path = image_conversion(\n",
    "            image_path=image_path,\n",
    "            file_path=self.file_path\n",
    "        )\n",
    "\n",
    "        for idx, value in enumerate(parse_output[\"elements\"]):\n",
    "\n",
    "            category = value[\"category\"]\n",
    "            markdown = value[\"content\"][\"markdown\"]\n",
    "            page = value[\"page\"]\n",
    "\n",
    "            if category in [\"figure\", \"table\"]:\n",
    "\n",
    "                base64_encoding = value[\"base64_encoding\"]    \n",
    "                coordinates = value[\"coordinates\"]    \n",
    "                img = Image.open(BytesIO(base64.b64decode(base64_encoding)))\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "\n",
    "                img = cv2.imread(f'{image_tmp_path}/{page}.jpg')\n",
    "                h, w, c = img.shape\n",
    "\n",
    "                #crob using cv2: img[y: y + h, x: x + w]\n",
    "                crop_img = img[math.ceil(coordinates[0][\"y\"]*h):math.ceil(coordinates[3][\"y\"]*h), \\\n",
    "                               math.ceil(coordinates[0][\"x\"]*w):math.ceil(coordinates[1][\"x\"]*w)]\n",
    "\n",
    "                crob_image_path = f'{image_path}/element-{idx}.jpg'\n",
    "                cv2.imwrite(crob_image_path, crop_img)\n",
    "\n",
    "                print (f'page_number: {page}')\n",
    "                print (\"==\")\n",
    "\n",
    "                h_crop, w_crop, _ = crop_img.shape\n",
    "                image_token = w_crop*h_crop/750\n",
    "                print (f'image: {crob_image_path}, shape: {img.shape}, image_token_for_claude3: {image_token}' )\n",
    "\n",
    "            else:\n",
    "                base64_encoding= \"\"\n",
    "                coordinates=\"\"\n",
    "\n",
    "            docs = processing(\n",
    "                docs=docs,\n",
    "                page=page,\n",
    "                category=category,\n",
    "                markdown=markdown,\n",
    "                base64_encoding=base64_encoding,\n",
    "                coordinates=coordinates\n",
    "            )\n",
    "            \n",
    "        return docs, texts\n",
    "    \n",
    "    def _context_generation_for_image(self, docs):\n",
    "        \n",
    "        def manipulate_docs_for_summary(docs):\n",
    "            \n",
    "            docs_for_summary = []\n",
    "            for page, elements in docs.items():\n",
    "\n",
    "                elements = [element for element in elements if element[\"category\"] != \"footer\"]\n",
    "                print (f'page: {page}, # elements: {len(elements)}')\n",
    "\n",
    "                for idx, element in enumerate(elements):\n",
    "\n",
    "                    category, markdown = element[\"category\"], element[\"markdown\"]\n",
    "                    print (f'element idx: {idx}, category: {element[\"category\"]}')\n",
    "\n",
    "                    elements_copy = copy.deepcopy(elements)\n",
    "                    if category in (\"figure\", \"table\"):  \n",
    "                        \n",
    "                        summary_target = elements_copy.pop(idx)\n",
    "                        contexts_markdown = '\\n'.join([context[\"markdown\"] for context in elements_copy])\n",
    "                        docs_for_summary.append(\n",
    "                            {\n",
    "                                \"target_category\": summary_target[\"category\"],\n",
    "                                \"target_base64\": summary_target[\"base64_encoding\"],\n",
    "                                \"target_markdown\": summary_target[\"markdown\"],\n",
    "                                \"contexts_markdown\": contexts_markdown\n",
    "                            }\n",
    "                        )\n",
    "                \n",
    "            return docs_for_summary\n",
    "        \n",
    "        def get_summary_chain():\n",
    "            \n",
    "            system_prompt = \"You are an assistant tasked with describing table and image.\"\n",
    "            system_message_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "\n",
    "            human_prompt = [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"data:image/png;base64,\" + \"{image_base64}\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": '''\n",
    "                             <contexts>\n",
    "                             {contexts}\n",
    "                             </contexts>\n",
    "\n",
    "                             주어진 이미지 또는 테이블을 자세히 분석하고 주어진 contexts를 참고하여 다음 정보를 추출해주세요:\n",
    "\n",
    "                             1. <title> 태그 안의 제목을 정확히 제시해주세요.\n",
    "                             2. <summary> 태그 안의 내용을 요약해주세요.\n",
    "                             3. <entities> 태그 안의 모든 항목을 나열하고, 각 항목에 대한 간단한 설명을 제공해주세요.\n",
    "                             4. <hypothetical_questions> 태그 안의 질문들을 모두 나열해주세요.\n",
    "                            모든 정보는 원본 내용을 정확히 반영하되, 필요한 경우 약간의 추가 설명을 덧붙여 이해를 돕도록 해주세요.\n",
    "                    '''\n",
    "                },\n",
    "            ]\n",
    "            human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "            \n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    system_message_template,\n",
    "                    human_message_template\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            summarize_chain = prompt | self.llm_text | StrOutputParser()\n",
    "            \n",
    "            return summarize_chain\n",
    "        \n",
    "        @retry(total_try_cnt=5, sleep_in_sec=10, retryable_exceptions=(botocore.exceptions.EventStreamError))\n",
    "        def summary_img(summarize_chain, image_base64, contexts):\n",
    "\n",
    "            img = Image.open(BytesIO(base64.b64decode(image_base64)))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "            stream = summarize_chain.stream(\n",
    "                {\n",
    "                    \"image_base64\": image_base64,\n",
    "                    \"contexts\": contexts\n",
    "                }\n",
    "            )\n",
    "            response = \"\"\n",
    "            for chunk in stream: response += chunk\n",
    "\n",
    "            return response\n",
    "            \n",
    "        docs_for_summary = manipulate_docs_for_summary(docs)\n",
    "        \n",
    "        print (\"docs_for_summary\", len(docs_for_summary))\n",
    "        \n",
    "        \n",
    "        summarize_chain = get_summary_chain()\n",
    "        \n",
    "        summaries = []\n",
    "        for idx, doc in enumerate(docs_for_summary):\n",
    "            summary = summary_img(summarize_chain, doc[\"target_base64\"], doc[\"contexts_markdown\"])\n",
    "            summaries.append(summary)\n",
    "            print (\"\\n==\")\n",
    "            print (idx)\n",
    "            \n",
    "        images_preprocessed = []\n",
    "        for doc, summary in zip(docs_for_summary, summaries):\n",
    "\n",
    "            metadata = {}\n",
    "            metadata[\"markdown\"] = doc[\"target_markdown\"]\n",
    "            metadata[\"category\"] = \"Image\"\n",
    "            metadata[\"image_base64\"] = doc[\"target_base64\"]\n",
    "\n",
    "            doc = Document(\n",
    "                page_content=summary,\n",
    "                metadata=metadata\n",
    "            )\n",
    "            images_preprocessed.append(doc)\n",
    "            \n",
    "        for image in images_preprocessed:\n",
    "            image.metadata[\"family_tree\"], image.metadata[\"parent_id\"] = \"parent_image\", \"NA\"\n",
    "        \n",
    "        return images_preprocessed, docs_for_summary\n",
    "\n",
    "    def _context_generation_for_table(self, docs_for_summary):\n",
    "        \n",
    "        def get_summary_chain():\n",
    "            \n",
    "            system_prompt = \"You are an assistant tasked with describing table and image.\"\n",
    "            system_message_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "            \n",
    "            human_prompt = [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": '''\n",
    "                             Here is the table: <table>{table}</table>\n",
    "                             Given table, give a concise summary.\n",
    "                             Don't insert any XML tag such as <table> and </table> when answering.\n",
    "                             Write in Korean.\n",
    "                    '''\n",
    "                },\n",
    "            ]\n",
    "            human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "            prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    system_message_template,\n",
    "                    human_message_template\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            summarize_chain = {\"table\": lambda x:x} | prompt | self.llm_text | StrOutputParser()\n",
    "            \n",
    "            return summarize_chain\n",
    "        \n",
    "        tables = [doc for doc in docs_for_summary if doc[\"target_category\"] == \"table\"]\n",
    "        summarize_chain = get_summary_chain()\n",
    "        table_info = [t[\"target_markdown\"] for t in tables]\n",
    "        table_summaries = summarize_chain.batch(table_info, config={\"max_concurrency\": 1})\n",
    "        \n",
    "        tables_preprocessed = []\n",
    "        for doc, summary in zip(tables, table_summaries):\n",
    "\n",
    "            metadata = {}\n",
    "            metadata[\"origin_table\"] = doc[\"target_markdown\"]\n",
    "            metadata[\"text_as_html\"] = doc[\"target_markdown\"]\n",
    "            metadata[\"category\"] = \"Table\"\n",
    "            metadata[\"image_base64\"] = doc[\"target_base64\"]\n",
    "\n",
    "            doc = Document(\n",
    "                page_content=summary,\n",
    "                metadata=metadata\n",
    "            )\n",
    "            tables_preprocessed.append(doc)\n",
    "        \n",
    "        for table in tables_preprocessed:\n",
    "            table.metadata[\"family_tree\"], table.metadata[\"parent_id\"] = \"parent_table\", \"NA\"\n",
    "            \n",
    "        return tables_preprocessed\n",
    "    \n",
    "    def _opensearch(self, ):\n",
    "        \n",
    "        index_body = {\n",
    "            'settings': {\n",
    "                'analysis': {\n",
    "                    'analyzer': {\n",
    "                        'my_analyzer': {\n",
    "                                 'char_filter':['html_strip'],\n",
    "                            'tokenizer': 'nori',\n",
    "                            'filter': [\n",
    "                                #'nori_number',\n",
    "                                #'lowercase',\n",
    "                                #'trim',\n",
    "                                'my_nori_part_of_speech'\n",
    "                            ],\n",
    "                            'type': 'custom'\n",
    "                        }\n",
    "                    },\n",
    "                    'tokenizer': {\n",
    "                        'nori': {\n",
    "                            'decompound_mode': 'mixed',\n",
    "                            'discard_punctuation': 'true',\n",
    "                            'type': 'nori_tokenizer'\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"my_nori_part_of_speech\": {\n",
    "                            \"type\": \"nori_part_of_speech\",\n",
    "                            \"stoptags\": [\n",
    "                                \"J\", \"XSV\", \"E\", \"IC\",\"MAJ\",\"NNB\",\n",
    "                                \"SP\", \"SSC\", \"SSO\",\n",
    "                                \"SC\",\"SE\",\"XSN\",\"XSV\",\n",
    "                                \"UNA\",\"NA\",\"VCP\",\"VSV\",\n",
    "                                \"VX\"\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                'index': {\n",
    "                    'knn': True,\n",
    "                    'knn.space_type': 'cosinesimil'  # Example space type\n",
    "                }\n",
    "            },\n",
    "            'mappings': {\n",
    "                'properties': {\n",
    "                    'metadata': {\n",
    "                        'properties': {\n",
    "                            'source': {'type': 'keyword'},\n",
    "                            'page_number': {'type':'long'},\n",
    "                            'category': {'type':'text'},\n",
    "                            'file_directory': {'type':'text'},\n",
    "                            'last_modified': {'type': 'text'},\n",
    "                            'type': {'type': 'keyword'},\n",
    "                            'image_base64': {'type':'text'},\n",
    "                            'origin_image': {'type':'text'},\n",
    "                            'origin_table': {'type':'text'},\n",
    "                        }\n",
    "                    },\n",
    "                    'text': {\n",
    "                        'analyzer': 'my_analyzer',\n",
    "                        'search_analyzer': 'my_analyzer',\n",
    "                        'type': 'text'\n",
    "                    },\n",
    "                    'vector_field': {\n",
    "                        'type': 'knn_vector',\n",
    "                        'dimension': f\"{self.dimension}\" # Replace with your vector dimension\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        opensearch_domain_endpoint = self.args.opensearch_domain_endpoint\n",
    "        opensearch_user_id = self.args.opensearch_user_id\n",
    "        opensearch_user_password = self.args.opensearch_user_password\n",
    "        index_name = self.args.index_name\n",
    "        \n",
    "        http_auth = (opensearch_user_id, opensearch_user_password) # Master username, Master password\n",
    "        \n",
    "        ## opensearch clinet 생성\n",
    "        aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "        os_client = opensearch_utils.create_aws_opensearch_client(\n",
    "            aws_region,\n",
    "            opensearch_domain_endpoint,\n",
    "            http_auth\n",
    "        )\n",
    "        \n",
    "        ## opensearch index 생성\n",
    "        index_exists = opensearch_utils.check_if_index_exists(\n",
    "            os_client,\n",
    "            index_name\n",
    "        )\n",
    "\n",
    "        if index_exists:\n",
    "            opensearch_utils.delete_index(\n",
    "                os_client,\n",
    "                index_name\n",
    "            )\n",
    "\n",
    "        opensearch_utils.create_index(os_client, index_name, index_body)\n",
    "        index_info = os_client.indices.get(index=index_name)\n",
    "        print(\"Index is created\")\n",
    "        pprint(index_info)\n",
    "        \n",
    "        vector_db = OpenSearchVectorSearch(\n",
    "            index_name=index_name,\n",
    "            opensearch_url=opensearch_domain_endpoint,\n",
    "            embedding_function=self.llm_emb,\n",
    "            http_auth=http_auth, # http_auth\n",
    "            is_aoss=False,\n",
    "            engine=\"faiss\",\n",
    "            space_type=\"l2\",\n",
    "            bulk_size=100000,\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        return os_client, vector_db, index_name\n",
    "        \n",
    "    def _chunking_and_indexing(self, os_client, vector_db, index_name, texts, images_preprocessed, tables_preprocessed):\n",
    "        \n",
    "        parent_chunk_size = 4096\n",
    "        parent_chunk_overlap = 0\n",
    "\n",
    "        child_chunk_size = 1024\n",
    "        child_chunk_overlap = 256\n",
    "\n",
    "        opensearch_parent_key_name = \"parent_id\"\n",
    "        opensearch_family_tree_key_name = \"family_tree\"\n",
    "        \n",
    "        parent_chunk_docs = parant_documents.create_parent_chunk(\n",
    "            docs=texts,\n",
    "            parent_id_key=opensearch_parent_key_name,\n",
    "            family_tree_id_key=opensearch_family_tree_key_name,\n",
    "            parent_chunk_size=parent_chunk_size,\n",
    "            parent_chunk_overlap=parent_chunk_overlap\n",
    "        )\n",
    "        print(f'Number of parent_chunk_docs= {len(parent_chunk_docs)}')\n",
    "        parent_ids = vector_db.add_documents(\n",
    "            documents = parent_chunk_docs, \n",
    "            vector_field = \"vector_field\",\n",
    "            bulk_size = 1000000\n",
    "        )\n",
    "        \n",
    "        total_count_docs = opensearch_utils.get_count(os_client, index_name)\n",
    "        print(\"total count docs: \", total_count_docs)\n",
    "                \n",
    "        # child_chunk_docs = create_child_chunk(parent_chunk_docs[0:1], parent_ids)\n",
    "        child_chunk_docs = parant_documents.create_child_chunk(\n",
    "            child_chunk_size=child_chunk_size,\n",
    "            child_chunk_overlap=child_chunk_overlap,\n",
    "            docs=parent_chunk_docs,\n",
    "            parent_ids_value=parent_ids,\n",
    "            parent_id_key=opensearch_parent_key_name,\n",
    "            family_tree_id_key=opensearch_family_tree_key_name\n",
    "        )\n",
    "\n",
    "        print(f\"Number of child_chunk_docs= {len(child_chunk_docs)}\")\n",
    "        parent_id = child_chunk_docs[0].metadata[\"parent_id\"]\n",
    "        print(\"child's parent_id: \", parent_id)\n",
    "        print(\"\\n###### Search parent in OpenSearch\")\n",
    "        \n",
    "        \n",
    "        ## Merge\n",
    "        docs_preprocessed = list(chain(child_chunk_docs, tables_preprocessed, images_preprocessed))\n",
    "        \n",
    "        child_ids = vector_db.add_documents(\n",
    "            documents=docs_preprocessed, \n",
    "            vector_field = \"vector_field\",\n",
    "            bulk_size=1000000\n",
    "        )\n",
    "        print(\"length of child_ids: \", len(child_ids))\n",
    "        \n",
    "        return child_chunk_docs\n",
    "        \n",
    "    def execution(self, ):\n",
    "        \n",
    "        ## Initialization for Bedrock\n",
    "        self._initialization()\n",
    "        \n",
    "        ## Document parsing\n",
    "        parse_output = self._document_parsing()\n",
    "        \n",
    "        ## Context generation for images and tables\n",
    "        docs, texts = self._extract_image_table(parse_output)\n",
    "        images_preprocessed, docs_for_summary = self._context_generation_for_image(docs)\n",
    "        tables_preprocessed = self._context_generation_for_table(docs_for_summary)\n",
    "        \n",
    "        ## Opensearch setting\n",
    "        os_client, vector_db, index_name = self._opensearch()\n",
    "        \n",
    "        ## Chunking(Parent document) and indexing\n",
    "        child_chunk_docs = self._chunking_and_indexing(os_client, vector_db, index_name, texts, images_preprocessed, tables_preprocessed)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--region\", type=str, default=\"us-west-2\")\n",
    "    parser.add_argument(\"--proc_prefix\", type=str, default=\"./src\")\n",
    "    parser.add_argument(\"--endpoint_document_parser\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--opensearch_domain_endpoint\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--opensearch_user_id\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--opensearch_user_password\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--index_name\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--file_name\", type=str, default=\"\")\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"Received arguments {}\".format(args))\n",
    "    \n",
    "    os.environ['AWS_DEFAULT_REGION'] = args.region\n",
    "        \n",
    "    prep = preprocess(args)\n",
    "    prep.execution()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f530ab-bac6-45ee-a245-bd3616cffa23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python ./src/preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a73c15-93a2-4f52-897b-5a7a2c8f5fbb",
   "metadata": {},
   "source": [
    "## 2. parser용 이미지 생성하기\n",
    " **[중요] ECR 사용을 위해 \"AmazonEC2ContainerRegistryFullAccess\" policy를 role에 추가해야 합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1254eb-cb55-4871-bba2-cdb41349c6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from utils.ecr import ecr_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118d918-bdab-4f73-957b-6ebe40ce1578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecr = ecr_handler()\n",
    "region=boto3.Session().region_name\n",
    "strAccountID = boto3.client(\"sts\").get_caller_identity().get(\"Account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66e0ef-a8db-4d66-af00-0029d2f8b64f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\", version=\"1.2-1\", region=region\n",
    ")\n",
    "container_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f78274-1737-4cf4-85e0-b4fcf12fa037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./custom-docker/Dockerfile-docparse\n",
    "\n",
    "FROM 246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
    "\n",
    "RUN wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --dearmor - | tee /usr/share/keyrings/kitware-archive-keyring.gpg >/dev/null\n",
    "RUN apt-get update\n",
    "RUN apt-get install -y libgl1-mesa-glx\n",
    "RUN apt-get install -y libglib2.0-0\n",
    "RUN apt-get install -y poppler-utils\n",
    "\n",
    "RUN pip install -U pip\n",
    "RUN pip install botocore==1.35.40\n",
    "RUN pip install boto3==1.35.40\n",
    "RUN pip install sagemaker==2.232.2\n",
    "RUN pip install langchain==0.3.3\n",
    "RUN pip install langchain_aws==0.2.2\n",
    "RUN pip install langchain_community==0.3.2\n",
    "RUN pip install requests_toolbelt==1.0.0\n",
    "RUN pip install pdf2image==1.17.0\n",
    "RUN pip install numpy==1.26.4\n",
    "RUN pip install opencv-python==4.10.0.84\n",
    "RUN pip install ipython==8.18.1\n",
    "RUN pip install opensearch-py==2.7.1\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de1813-7859-48c9-a170-f0777264561d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strRepositoryName=\"docparse-image\"  ## <-- 원하는 docker repostory 이름을 추가\n",
    "strRepositoryName = strRepositoryName.lower()\n",
    "strDockerFile = \"Dockerfile-docparse\"\n",
    "strDockerDir = \"./custom-docker/\"\n",
    "strTag = \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8df246-7556-459c-93cd-07b677ae3814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Build\n",
    "#ecr.build_docker(strDockerDir, strDockerFile, strRepositoryName, strRegionName=\"ap-northeast-2\", strAccountId=\"246618743249\")\n",
    "ecr.build_docker(strDockerDir, strDockerFile, strRepositoryName, strRegionName=\"us-west-2\", strAccountId=\"246618743249\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8368e501-adf2-4fb5-bd70-ee4b0fa5d4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Upload to ECR\n",
    "strEcrRepositoryUri = ecr.register_image_to_ecr(region, strAccountID, strRepositoryName, strTag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1da989-0062-4f0f-a4bb-d5afabd265f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. 파일 업로드 to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48b831-cece-4ddd-af02-3be35f01486f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from utils.s3 import s3_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa35ca-b42a-475f-959e-f9b1973b5760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "strBucketName = sagemaker_session.default_bucket() # 기본 버킷 이름 가져오기\n",
    "strLocalDataPath = \"./data/complex_pdf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a75f1-d0d3-4df4-9dd5-1ceb866fedab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = s3_handler()\n",
    "source_dir, target_bucket, target_dir = strLocalDataPath, strBucketName, \"doc_parse_data\"\n",
    "s3.upload_dir(source_dir, target_bucket, target_dir)\n",
    "\n",
    "strS3DataPath = f's3://{strBucketName}/doc_parse_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f6574-c1f9-4ea7-a5ca-b569fd791b7c",
   "metadata": {},
   "source": [
    "## 3. Processing Job 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf59c1c-9190-4ec1-8828-80d456052b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.ssm import parameter_store\n",
    "from sagemaker import get_execution_role\n",
    "#from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, FrameworkProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8748c-8864-4bf2-8066-514e2cbff3ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strRegionName = boto3.Session().region_name\n",
    "strAccountId = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "strPrefix = \"doc-parse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85196b-d289-40e2-99c0-3ba0e830d2aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_mode = False\n",
    "\n",
    "strExecutionRole = get_execution_role()\n",
    "\n",
    "if local_mode: \n",
    "    strInstanceType = 'local'\n",
    "    \n",
    "    import os\n",
    "    from sagemaker.local import LocalSession\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    strDataPath = str(os.path.join(\"file://\", os.getcwd(), \"data\", \"complex_pdf\"))\n",
    "    \n",
    "else:\n",
    "    strInstanceType = \"ml.m5.xlarge\"\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    strDataPath = strS3DataPath\n",
    "        \n",
    "print (f\"instance-type: {strInstanceType}\")\n",
    "print (f'role: {strExecutionRole}')\n",
    "print (f\"bucket: {strBucketName}\")\n",
    "print (f\"dataset-path: {strDataPath}\")\n",
    "print (f\"sagemaker_session: {sagemaker_session}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a89093-b1e2-42dd-af75-41fc8f728d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processor = FrameworkProcessor(\n",
    "    estimator_cls=SKLearn,\n",
    "    framework_version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    image_uri=\"615299776985.dkr.ecr.us-west-2.amazonaws.com/docparse-image\",#\"<your image uri>\"\n",
    "    instance_type=strInstanceType,\n",
    "    instance_count=1,\n",
    "    role=strExecutionRole,\n",
    "    base_job_name=\"preprocessing\", # bucket에 보이는 이름 (pipeline으로 묶으면 pipeline에서 정의한 이름으로 bucket에 보임)\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "strProcPrefix = \"/opt/ml/processing\"\n",
    "strOutputPath = os.path.join(\n",
    "    \"s3://{}\".format(strBucketName),\n",
    "    strPrefix,\n",
    "    \"preprocessing\",\n",
    "    \"output\"\n",
    ")\n",
    "\n",
    "pm = parameter_store(strRegionName)\n",
    "endpoint_document_parser = \"Upstage-Document-Parse-2024-10-17-21-53-42-914\"\n",
    "opensearch_domain_endpoint = pm.get_params(\n",
    "    key=\"opensearch_domain_endpoint\",\n",
    "    enc=False\n",
    ")\n",
    "opensearch_user_id = pm.get_params(\n",
    "    key=\"opensearch_user_id\",\n",
    "    enc=False\n",
    ")\n",
    "opensearch_user_password = pm.get_params(\n",
    "    key=\"opensearch_user_password\",\n",
    "    enc=True\n",
    ")\n",
    "index_name = \"sm_prep_job\"\n",
    "file_name = \"sample-2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa082f3a-8e59-4dfb-8288-be20d3defa35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_processor.run(\n",
    "    #job_name=\"preprocessing\", ## 이걸 넣어야 캐시가 작동함, 안그러면 프로세서의 base_job_name 이름뒤에 날짜 시간이 붙어서 캐시 동작 안함\n",
    "    #git_config=git_config,\n",
    "    code='preprocessing.py', #소스 디렉토리 안에서 파일 path\n",
    "    source_dir= \"./src\", #현재 파일에서 소스 디렉토리 상대경로 # add processing.py and requirements.txt here\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name=\"input-data\",\n",
    "            source=strDataPath,\n",
    "            destination=os.path.join(strProcPrefix, \"input\")\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[       \n",
    "        ProcessingOutput(\n",
    "            output_name=\"output-data\",\n",
    "            source=os.path.join(strProcPrefix, \"output\"),\n",
    "            destination=strOutputPath\n",
    "        ),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--proc_prefix\", strProcPrefix, \\\n",
    "        \"--region\", region, \\\n",
    "        \"--endpoint_document_parser\", endpoint_document_parser, \\\n",
    "        \"--opensearch_domain_endpoint\", opensearch_domain_endpoint, \\\n",
    "        \"--opensearch_user_id\", opensearch_user_id, \\\n",
    "        \"--opensearch_user_password\", opensearch_user_password, \\\n",
    "        \"--index_name\", index_name, \\\n",
    "        \"--file_name\", file_name\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700808db-32d5-4759-bc49-ce23a9bc758f",
   "metadata": {},
   "source": [
    "## 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3750f-990a-49cc-942a-e18d59f4c521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_hybrid_retriever = OpenSearchHybridSearchRetriever(\n",
    "    os_client=os_client,\n",
    "    index_name=\"sm_prep_job\",\n",
    "    llm_text=llm_text, # llm for query augmentation in both rag_fusion and HyDE\n",
    "    llm_emb=llm_emb, # Used in semantic search based on opensearch \n",
    "\n",
    "    # hybird-search debugger\n",
    "    #hybrid_search_debugger = \"semantic\", #[semantic, lexical, None]\n",
    "    \n",
    "    # option for lexical\n",
    "    minimum_should_match=0,\n",
    "    filter=[],\n",
    "\n",
    "    # option for search\n",
    "    fusion_algorithm=\"RRF\", # [\"RRF\", \"simple_weighted\"], rank fusion 방식 정의\n",
    "    ensemble_weights=[.51, .49], # [for semantic, for lexical], Semantic, Lexical search 결과에 대한 최종 반영 비율 정의\n",
    "    reranker=False, # enable reranker with reranker model\n",
    "    #reranker_endpoint_name=endpoint_name, # endpoint name for reranking model\n",
    "    parent_document=True, # enable parent document\n",
    "    \n",
    "    # option for complex pdf consisting of text, table and image\n",
    "    complex_doc=True,\n",
    "    \n",
    "    # option for async search\n",
    "    async_mode=True,\n",
    "\n",
    "    # option for output\n",
    "    k=7, # 최종 Document 수 정의\n",
    "    verbose=False,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c032fc7-42ae-4df6-aff3-9fe11de7702c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query = \"자동조기 상환\"\n",
    "search_hybrid_result, tables, images = opensearch_hybrid_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ae0cf-0eab-4611-a2bd-bcbebeb6c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_context_used(search_hybrid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54979b12-655a-44e7-960a-9fc65779ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
