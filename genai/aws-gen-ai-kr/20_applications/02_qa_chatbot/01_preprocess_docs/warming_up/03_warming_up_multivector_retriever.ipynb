{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e3a59b-97a1-47a6-a162-0d22e9b01535",
   "metadata": {},
   "source": [
    "# Parent Document Retriever 를 OpenSearch 로 구현\n",
    "\n",
    "### Ref:  MultiVector Retriever\n",
    "- https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1623dfd-2f16-46d6-b8f5-ad759c738028",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e1a302-1da2-471a-b5e4-30a23b84ca4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot/01_preprocess_docs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "# module_path = \"../../../utils\"\n",
    "# sys.path.append(os.path.abspath(module_path))\n",
    "# print(os.path.abspath(module_path))\n",
    "\n",
    "module_path = \"../\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "print(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b89dd4-2659-4c77-aeb8-b78709bf4079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\n",
      "== FM lists ==\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-G1': 'TBD'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print(colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint(bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d1fae-29fb-4c26-bc5d-fa6b8e5eb23e",
   "metadata": {},
   "source": [
    "# 2. Embedding 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f6d49b-9372-4a97-95bb-c0a6243944a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Use_Titan_Embedding = True\n",
    "Use_Cohere_English_Embedding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac33c7e-acd3-4cfb-8899-1fbc36fe7194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x7f7bf7b31f90>, region_name=None, credentials_profile_name=None, model_id='amazon.titan-embed-text-v1', model_kwargs=None, endpoint_url=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "if Use_Titan_Embedding:\n",
    "    llm_emb = BedrockEmbeddings(client=boto3_bedrock, model_id = \"amazon.titan-embed-text-v1\")\n",
    "    dimension = 1536\n",
    "elif Use_Cohere_English_Embedding:\n",
    "    llm_emb = BedrockEmbeddings(client=boto3_bedrock, model_id = \"cohere.embed-english-v3\")    \n",
    "    dimension = 1024\n",
    "else:\n",
    "    lim_emb = None\n",
    "\n",
    "llm_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde05e0-d061-46c3-8071-ac9d3497d5d8",
   "metadata": {},
   "source": [
    "# 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ba8bfe-27f1-44f2-a167-5a4333544b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac754da-45d3-4995-90b8-ae01301e9456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    TextLoader(\"../backup/Parent_Document_Retriever/paul_graham_essay.txt\"),\n",
    "    # TextLoader(\"../backup/Parent_Document_Retriever/state_of_the_union.txt\"),\n",
    "]\n",
    "docs = []\n",
    "for l in loaders:\n",
    "    docs.extend(l.load())\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2842b6b3-74b6-4569-9027-ead936ae478f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3227edf-7397-4fb9-882f-92981fb08481",
   "metadata": {},
   "source": [
    "# 4. Index 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64fc434f-6142-4f46-8dca-82fbbecc8c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = \"genai-poc-knox-parent-child\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6331d3d-6c50-47c3-a52e-47243f5bd9cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. LangChain OpenSearch VectorStore 생성 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6970a3c5-48fc-4039-925a-da113bddfb5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.proc_docs import get_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413dec38-0eb5-4593-86ed-61d7bdde0927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "ssm = boto3.client('ssm', 'us-east-1')\n",
    "\n",
    "opensearch_domain_endpoint = get_parameter(\n",
    "    boto3_client = ssm,\n",
    "    parameter_name = 'knox_opensearch_domain_endpoint',\n",
    ")\n",
    "\n",
    "opensearch_user_id = get_parameter(\n",
    "    boto3_client = ssm,\n",
    "    parameter_name = 'knox_opensearch_userid',\n",
    ")\n",
    "\n",
    "opensearch_user_password = get_parameter(\n",
    "    boto3_client = ssm,\n",
    "    parameter_name = 'knox_opensearch_password',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71e6bea-44fb-4077-ab51-8c9290f8e6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = opensearch_domain_endpoint\n",
    "rag_user_name = opensearch_user_id\n",
    "rag_user_password = opensearch_user_password\n",
    "\n",
    "http_auth = (rag_user_name, rag_user_password) # Master username, Master password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b924558-f8c4-4a4f-b58c-824d99405039",
   "metadata": {},
   "source": [
    "## OpenSearch Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c399ff-624b-4de4-9c78-296680c42105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.opensearch import opensearch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd7ff33-3265-443e-9c3b-9e88e5abb05f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "\n",
    "os_client = opensearch_utils.create_aws_opensearch_client(\n",
    "    aws_region,\n",
    "    opensearch_domain_endpoint,\n",
    "    http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b55a809-3c55-470d-8ed2-931912a91726",
   "metadata": {},
   "source": [
    "## 오픈 서치 인덱스 생성 \n",
    "- 오픈 서치에 해당 인덱스가 존재하면, 삭제 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5812c6f-2454-400d-bcf0-f3740e9521f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.opensearch import opensearch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138f1a3b-d3c3-4863-ba27-c170038f2549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_name=genai-poc-knox-parent-child, exists=False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index_exists = opensearch_utils.check_if_index_exists(\n",
    "    os_client,\n",
    "    index_name\n",
    ")\n",
    "\n",
    "if index_exists:\n",
    "    opensearch_utils.delete_index(\n",
    "        os_client,\n",
    "        index_name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c543eccf-ce41-4244-9392-d0414253ce7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 랭체인 인덱스 연결 오브젝트 생성\n",
    "\n",
    "- [langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bd86820-3ed4-409e-a8d5-3339e716e824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b131a1f-0c47-4ebe-982d-c53aaa3391f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch at 0x7f7bec0028f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    "    is_aoss =False,\n",
    "    engine=\"faiss\",\n",
    "    space_type=\"l2\",\n",
    "    bulk_size=100000,\n",
    "    timeout=60    \n",
    ")\n",
    "vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c9be0-89f3-47a5-af8e-802d49dd71ad",
   "metadata": {},
   "source": [
    "# 6. Parent Doc key 와 함계 MultiVectorRetriever 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b0294-deb7-4253-815c-ef5245482ab6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parent Doc 을 Doc ID 와 함계 Vector Store 에 저장\n",
    "-  We can also add the original chunks to the vectorstore you should use this instead of the docstore \n",
    "    - https://stackoverflow.com/questions/77325854/is-there-a-way-to-set-the-vectorstore-as-the-docstore-when-setting-up-a-langchai\n",
    "```\n",
    "for i, doc in enumerate(docs):\n",
    "    doc.metadata[id_key] = doc_ids[i]\n",
    "retriever.vectorstore.add_documents(docs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d10343db-f625-4196-9c7e-f6ad916a4acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_ids = vector_db.add_documents(\n",
    "                        documents = docs, \n",
    "                        vector_field = \"vector_field\",\n",
    "                        bulk_size = 1000000\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d405c70-d1da-4241-aac4-b571344da8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2dc76df5-454a-4027-b0d0-5b104029c000',\n",
       " '0d47066b-f5da-4a57-847d-471482493dd9',\n",
       " '04b51e61-b183-471a-8bb0-c00e1d371bf0',\n",
       " '81708bd9-2034-484d-92ad-4b703ca2af7a',\n",
       " '0eaa92b4-0af7-4865-8ba0-dd0fd95e05eb',\n",
       " 'c5398811-1c86-43d9-bc99-5a11ca642289',\n",
       " 'c67d319f-5666-4c1c-bc84-d060c6ddabf4',\n",
       " 'd735d96a-80d9-4eb2-8f21-fe9a586a6379']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e11e5d2-62e6-4879-9853-a2866d7db5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count docs:  {'count': 8, '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "total_count_docs = os_client.count(index = index_name)\n",
    "print(\"total count docs: \", total_count_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d60f93-b65c-419c-b4ff-6f6a42b593ae",
   "metadata": {},
   "source": [
    "# 7. Child Chunk 생성 및 OpenSearch 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d84d5-6a55-4357-b235-d1d887e5c310",
   "metadata": {},
   "source": [
    "## Parent 당 Child Chunk 생성 \n",
    "- Child Chunk 는 Parent Doc ID 를 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5066afe2-cffe-4bd6-8780-9143eb3835aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The splitter to use to create smaller chunks\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ba14bee-c8a3-4e91-bb0c-31d47b175476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_key = \"doc_id\"\n",
    "\n",
    "sub_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "#     _id = doc_ids[i]\n",
    "    _id = parent_ids[i]    \n",
    "    _sub_docs = child_text_splitter.split_documents([doc])\n",
    "    for _doc in _sub_docs:\n",
    "        _doc.metadata[id_key] = _id\n",
    "    sub_docs.extend(_sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd6c4c1-ed65-41af-82b3-b73c40e6352b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\", metadata={'source': '../backup/Parent_Document_Retriever/paul_graham_essay.txt', 'doc_id': '2dc76df5-454a-4027-b0d0-5b104029c000'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_docs[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97015775-f225-4094-b4f0-f70bc7bf781b",
   "metadata": {},
   "source": [
    "## Child Chunks 를 Vectore Store 에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8b0017b-ffd7-40c2-9ae7-72432bbedc42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 631 ms, sys: 44.7 ms, total: 675 ms\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "child_doc_ids = vector_db.add_documents(documents = sub_docs, \n",
    "                        vector_field = \"vector_field\",\n",
    "                        bulk_size = 1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f8a213-451d-47f3-ae7f-dab24dee306f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count docs:  {'count': 310, '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "total_count_docs = os_client.count(index = index_name)\n",
    "print(\"total count docs: \", total_count_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018a0a7-8c1f-4e21-b8e6-f31de84f6233",
   "metadata": {},
   "source": [
    "# 8. 벡터 스토어 검색 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57b3e0-12aa-48ac-8e6a-c27f7790fb3a",
   "metadata": {},
   "source": [
    "## MultiVectorRetriever 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61d84927-2437-421f-b91b-899974279074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore= vector_db,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f30511-05b1-420c-9005-c108dd853df8",
   "metadata": {},
   "source": [
    "## Child Chunk 에 대한 유사 검색 및 Parent Doc 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7f615b5-3492-40e0-822a-5728d45093d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='One day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Viaweb, when I was bent over double from a kidney stone, he suggested that it would be a good idea for him to take me to the hospital. That was what it took for Rtm to offer unsolicited advice. So I' metadata={'source': '../backup/Parent_Document_Retriever/paul_graham_essay.txt', 'doc_id': 'c67d319f-5666-4c1c-bc84-d060c6ddabf4'}\n",
      "\n",
      "Parent doc id:  c67d319f-5666-4c1c-bc84-d060c6ddabf4\n"
     ]
    }
   ],
   "source": [
    "# Vectorstore alone retrieves the small chunks\n",
    "# response = retriever.vectorstore.similarity_search(\"justice breyer\")[0]\n",
    "response = retriever.vectorstore.similarity_search(\"Robert Morris\")[0]\n",
    "print(response)\n",
    "parent_doc_id = response.metadata[\"doc_id\"]\n",
    "print(\"\\nParent doc id: \", parent_doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9b5a92a-7054-4ee3-835e-de3437aeacde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parent document id: c67d319f-5666-4c1c-bc84-d060c6ddabf4\n",
      "parent document text: \n",
      " One day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Viaweb, when I was bent over double from a kidney stone, he suggested that it would be a good idea for him to take me to the hospital. That was what it took for Rtm to offer unsolicited advice. So I remember his exact words very clearly. \"You know,\" he said, \"you should make sure Y Combinator isn't the last cool thing you do.\"\n",
      "\n",
      "At the time I didn't understand what he meant, but gradually it dawned on me that he was saying I should quit. This seemed strange advice, because YC was doing great. But if there was one thing rarer than Rtm offering advice, it was Rtm being wrong. So this set me thinking. It was true that on my current trajectory, YC would be the last thing I did, because it was only taking up more of my attention. It had already eaten Arc, and was in the process of eating essays too. Either YC was my life's work or I'd have to leave eventually. And it wasn't, so I would.\n",
      "\n",
      "In the summer of 2012 my mother had a stroke, and the cause turned out to be a blood clot caused by colon cancer. The stroke destroyed her balance, and she was put in a nursing home, but she really wanted to get out of it and back to her house, and my sister and I were determined to help her do it. I used to fly up to Oregon to visit her regularly, and I had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\n",
      "\n",
      "I asked Jessica if she wanted to be president, but she didn't, so we decided we'd try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn't be controlled by the founders. So if Sam said yes, we'd let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\n",
      "\n",
      "When we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he'd take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.\n",
      "\n",
      "She died on January 15, 2014. We knew this was coming, but it was still hard when it did.\n",
      "\n",
      "I kept working on YC till March, to help get that batch of startups through Demo Day, then I checked out pretty completely. (I still talk to alumni and to new startups working on things I'm interested in, but that only takes a few hours a week.)\n",
      "\n",
      "What should I do next? Rtm's advice hadn't included anything about that. I wanted to do something completely different, so I decided I'd paint. I wanted to see how good I could get if I really focused on it. So the day after I stopped working on YC, I started painting. I was rusty and it took a while to get back into shape, but it was at least completely engaging. [18]\n",
      "\n",
      "I spent most of the rest of 2014 painting. I'd never been able to work so uninterruptedly before, and I got to be better than I had been. Not good enough, but better. Then in November, right in the middle of a painting, I ran out of steam. Up till that point I'd always been curious to see how the painting I was working on would turn out, but suddenly finishing this one seemed like a chore. So I stopped working on it and cleaned my brushes and haven't painted since. So far anyway.\n",
      "\n",
      "I realize that sounds rather wimpy. But attention is a zero sum game. If you can choose what to work on, and you choose a project that's not the best one (or at least a good one) for you, then it's getting in the way of another project that is. And at 50 there was some opportunity cost to screwing around.\n",
      "\n",
      "I started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren't about startups. Then in March 2015 I started working on Lisp again.\n",
      "\n",
      "The distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn't originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]\n",
      "\n",
      "McCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.\n",
      "\n",
      "McCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach. That wouldn't have been feasible at the time. McCarthy tested his interpreter by hand-simulating the execution of programs. But it was already getting close to the limit of interpreters you could test that way — indeed, there was a bug in it that McCarthy had overlooked. To test a more complicated interpreter, you'd have had to run it, and computers then weren't powerful enough.\n",
      "\n",
      "Now they are, though. Now you could continue using McCarthy's axiomatic approach till you'd defined a complete programming language. And as long as every change you made to McCarthy's Lisp was a discoveredness-preserving transformation, you could, in principle, end up with a complete language that had this quality. Harder to do than to talk about, of course, but if it was possible in principle, why not try? So I decided to take a shot at it. It took 4 years, from March 26, 2015 to October 12, 2019. It was fortunate that I had a precisely defined goal, or it would have been hard to keep at it for so long.\n",
      "\n",
      "I wrote this new Lisp, called Bel, in itself in Arc. That may sound like a contradiction, but it's an indication of the sort of trickery I had to engage in to make this work. By means of an egregious collection of hacks I managed to make something close enough to an interpreter written in itself that could actually run. Not fast, but fast enough to test.\n",
      "\n",
      "I had to ban myself from writing essays during most of this time, or I'd never have finished. In late 2015 I spent 3 months writing essays, and when I went back to working on Bel I could barely understand the code. Not so much because it was badly written as because the problem is so convoluted. When you're working on an interpreter written in itself, it's hard to keep track of what's happening at what level, and errors can be practically encrypted by the time you get them.\n",
      "\n",
      "So I said no more essays till Bel was done. But I told few people about Bel while I was working on it. So for years it must have seemed that I was doing nothing, when in fact I was working harder than I'd ever worked on anything. Occasionally after wrestling for hours with some gruesome bug I'd check Twitter or HN and see someone asking \"Does Paul Graham still code?\"\n",
      "\n",
      "Working on Bel was hard but satisfying. I worked on it so intensively that at any given time I had a decent chunk of the code in my head and could write more there. I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\n",
      "\n",
      "In the summer of 2016 we moved to England. We wanted our kids to see what it was like living in another country, and since I was a British citizen by birth, that seemed the obvious choice. We only meant to stay for a year, but we liked it so much that we still live there. So most of Bel was written in England.\n",
      "\n",
      "In the fall of 2019, Bel was finally finished. Like McCarthy's original Lisp, it's a spec rather than an implementation, although like McCarthy's Lisp it's a spec expressed as code.\n",
      "\n",
      "Now that I could write essays again, I wrote a bunch about topics I'd had stacked up. I kept writing essays through 2020, but I also started to think about other things I could work on. How should I choose what to do? Well, how had I chosen what to work on in the past? I wrote an essay for myself to answer that question, and I was surprised how long and messy the answer turned out to be. If this surprised me, who'd lived it, then I thought perhaps it would be interesting to other people, and encouraging to those with similarly messy lives. So I wrote a more detailed version for others to read, and this is the last sentence of it.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Notes\n",
      "\n",
      "[1] My experience skipped a step in the evolution of computers: time-sharing machines with interactive OSes. I went straight from batch processing to microcomputers, which made microcomputers seem all the more exciting.\n",
      "\n",
      "[2] Italian words for abstract concepts can nearly always be predicted from their English cognates (except for occasional traps like polluzione). It's the everyday words that differ. So if you string together a lot of abstract concepts with a few simple verbs, you can make a little Italian go a long way.\n"
     ]
    }
   ],
   "source": [
    "response = opensearch_utils.get_document(os_client, doc_id = parent_doc_id, index_name = index_name)\n",
    "print(\"\\nparent document id:\" , response[\"_id\"])\n",
    "print(\"parent document text: \\n\" , response[\"_source\"][\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d146b8-d3a5-4596-9212-a2f1e769a2cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Child Chunk 의 유사 검색 결과 연결된 Parent Chunk 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4289f16-574d-4b84-a350-5a07feaf4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.docstore.mset(list(zip(parent_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b1841f6-02dc-480d-824b-598631c356f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count docs:  {'count': 310, '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "total_count_docs = os_client.count(index = index_name)\n",
    "print(\"total count docs: \", total_count_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36e5cce8-f827-45b5-b51c-507e0339cbef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Viaweb, when I was bent over double from a kidney stone, he suggested that it would be a good idea for him to take me to the hospital. That was what it took for Rtm to offer unsolicited advice. So I remember his exact words very clearly. \"You know,\" he said, \"you should make sure Y Combinator isn\\'t the last cool thing you do.\"\\n\\nAt the time I didn\\'t understand what he meant, but gradually it dawned on me that he was saying I should quit. This seemed strange advice, because YC was doing great. But if there was one thing rarer than Rtm offering advice, it was Rtm being wrong. So this set me thinking. It was true that on my current trajectory, YC would be the last thing I did, because it was only taking up more of my attention. It had already eaten Arc, and was in the process of eating essays too. Either YC was my life\\'s work or I\\'d have to leave eventually. And it wasn\\'t, so I would.\\n\\nIn the summer of 2012 my mother had a stroke, and the cause turned out to be a blood clot caused by colon cancer. The stroke destroyed her balance, and she was put in a nursing home, but she really wanted to get out of it and back to her house, and my sister and I were determined to help her do it. I used to fly up to Oregon to visit her regularly, and I had a lot of time to think on those flights. On one of them I realized I was ready to hand YC over to someone else.\\n\\nI asked Jessica if she wanted to be president, but she didn\\'t, so we decided we\\'d try to recruit Sam Altman. We talked to Robert and Trevor and we agreed to make it a complete changing of the guard. Up till that point YC had been controlled by the original LLC we four had started. But we wanted YC to last for a long time, and to do that it couldn\\'t be controlled by the founders. So if Sam said yes, we\\'d let him reorganize YC. Robert and I would retire, and Jessica and Trevor would become ordinary partners.\\n\\nWhen we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he\\'d take over starting with the winter 2014 batch. For the rest of 2013 I left running YC more and more to Sam, partly so he could learn the job, and partly because I was focused on my mother, whose cancer had returned.\\n\\nShe died on January 15, 2014. We knew this was coming, but it was still hard when it did.\\n\\nI kept working on YC till March, to help get that batch of startups through Demo Day, then I checked out pretty completely. (I still talk to alumni and to new startups working on things I\\'m interested in, but that only takes a few hours a week.)\\n\\nWhat should I do next? Rtm\\'s advice hadn\\'t included anything about that. I wanted to do something completely different, so I decided I\\'d paint. I wanted to see how good I could get if I really focused on it. So the day after I stopped working on YC, I started painting. I was rusty and it took a while to get back into shape, but it was at least completely engaging. [18]\\n\\nI spent most of the rest of 2014 painting. I\\'d never been able to work so uninterruptedly before, and I got to be better than I had been. Not good enough, but better. Then in November, right in the middle of a painting, I ran out of steam. Up till that point I\\'d always been curious to see how the painting I was working on would turn out, but suddenly finishing this one seemed like a chore. So I stopped working on it and cleaned my brushes and haven\\'t painted since. So far anyway.\\n\\nI realize that sounds rather wimpy. But attention is a zero sum game. If you can choose what to work on, and you choose a project that\\'s not the best one (or at least a good one) for you, then it\\'s getting in the way of another project that is. And at 50 there was some opportunity cost to screwing around.\\n\\nI started writing essays again, and wrote a bunch of new ones over the next few months. I even wrote a couple that weren\\'t about startups. Then in March 2015 I started working on Lisp again.\\n\\nThe distinctive thing about Lisp is that its core is a language defined by writing an interpreter in itself. It wasn\\'t originally intended as a programming language in the ordinary sense. It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what\\'s the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]\\n\\nMcCarthy didn\\'t realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy\\'s interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn\\'t match. It was this that attracted me in college, though I didn\\'t understand why at the time.\\n\\nMcCarthy\\'s 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you\\'d want in a programming language. So these had to be added, and when they were, they weren\\'t defined using McCarthy\\'s original axiomatic approach. That wouldn\\'t have been feasible at the time. McCarthy tested his interpreter by hand-simulating the execution of programs. But it was already getting close to the limit of interpreters you could test that way — indeed, there was a bug in it that McCarthy had overlooked. To test a more complicated interpreter, you\\'d have had to run it, and computers then weren\\'t powerful enough.\\n\\nNow they are, though. Now you could continue using McCarthy\\'s axiomatic approach till you\\'d defined a complete programming language. And as long as every change you made to McCarthy\\'s Lisp was a discoveredness-preserving transformation, you could, in principle, end up with a complete language that had this quality. Harder to do than to talk about, of course, but if it was possible in principle, why not try? So I decided to take a shot at it. It took 4 years, from March 26, 2015 to October 12, 2019. It was fortunate that I had a precisely defined goal, or it would have been hard to keep at it for so long.\\n\\nI wrote this new Lisp, called Bel, in itself in Arc. That may sound like a contradiction, but it\\'s an indication of the sort of trickery I had to engage in to make this work. By means of an egregious collection of hacks I managed to make something close enough to an interpreter written in itself that could actually run. Not fast, but fast enough to test.\\n\\nI had to ban myself from writing essays during most of this time, or I\\'d never have finished. In late 2015 I spent 3 months writing essays, and when I went back to working on Bel I could barely understand the code. Not so much because it was badly written as because the problem is so convoluted. When you\\'re working on an interpreter written in itself, it\\'s hard to keep track of what\\'s happening at what level, and errors can be practically encrypted by the time you get them.\\n\\nSo I said no more essays till Bel was done. But I told few people about Bel while I was working on it. So for years it must have seemed that I was doing nothing, when in fact I was working harder than I\\'d ever worked on anything. Occasionally after wrestling for hours with some gruesome bug I\\'d check Twitter or HN and see someone asking \"Does Paul Graham still code?\"\\n\\nWorking on Bel was hard but satisfying. I worked on it so intensively that at any given time I had a decent chunk of the code in my head and could write more there. I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with some problem involving continuations while I watched them play in the tide pools. It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\\n\\nIn the summer of 2016 we moved to England. We wanted our kids to see what it was like living in another country, and since I was a British citizen by birth, that seemed the obvious choice. We only meant to stay for a year, but we liked it so much that we still live there. So most of Bel was written in England.\\n\\nIn the fall of 2019, Bel was finally finished. Like McCarthy\\'s original Lisp, it\\'s a spec rather than an implementation, although like McCarthy\\'s Lisp it\\'s a spec expressed as code.\\n\\nNow that I could write essays again, I wrote a bunch about topics I\\'d had stacked up. I kept writing essays through 2020, but I also started to think about other things I could work on. How should I choose what to do? Well, how had I chosen what to work on in the past? I wrote an essay for myself to answer that question, and I was surprised how long and messy the answer turned out to be. If this surprised me, who\\'d lived it, then I thought perhaps it would be interesting to other people, and encouraging to those with similarly messy lives. So I wrote a more detailed version for others to read, and this is the last sentence of it.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotes\\n\\n[1] My experience skipped a step in the evolution of computers: time-sharing machines with interactive OSes. I went straight from batch processing to microcomputers, which made microcomputers seem all the more exciting.\\n\\n[2] Italian words for abstract concepts can nearly always be predicted from their English cognates (except for occasional traps like polluzione). It\\'s the everyday words that differ. So if you string together a lot of abstract concepts with a few simple verbs, you can make a little Italian go a long way.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retriever returns larger chunks\n",
    "retriever.get_relevant_documents(\"Robert Morris\")[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65041cc-205a-4498-9dd6-7cf5e4dd722f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
