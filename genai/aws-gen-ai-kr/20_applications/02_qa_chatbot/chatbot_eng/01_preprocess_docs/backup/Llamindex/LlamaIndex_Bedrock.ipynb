{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ccb27e-f825-45c6-bca1-7d13b76e59bf",
   "metadata": {},
   "source": [
    "# Llamaindex ì—ì„œ Bedrock API ì‚¬ìš©\n",
    "- Llamaindex ì—ì„œ Bedrock ì„ ì ‘ê·¼\n",
    "    - https://docs.llamaindex.ai/en/stable/examples/llm/bedrock.html\n",
    "    - https://docs.llamaindex.ai/en/stable/examples/llm/bedrock.html#bedrock\n",
    "    - [LlamaIndex ðŸ¦™ Q&A over your data ðŸ“‚using Amazon Bedrock and Streamlit](https://medium.com/@dminhk/llamaindex-q-a-over-your-data-using-amazon-bedrock-and-streamlit-1e52a096ec7c)\n",
    "    \n",
    "- LlamaIndex Git\n",
    "    - https://github.com/run-llama/llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90acf41d-e29b-4907-af07-2d9b219fa488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34d198-fd95-448f-929c-de05398c5463",
   "metadata": {},
   "source": [
    "# ê¸°ë³¸ ì„¸íŒ… ë° AWS CLI Profile ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0291edff-b803-421c-9d3d-e511f3869a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import Bedrock\n",
    "\n",
    "prompt = \"\\n\\nHuman: ì„¸ì´ì§€ë©”ì´ì»¤ì˜ ìž¥ì ì„ 100ë‹¨ì–´ë¡œ ì•Œë ¤ì£¼ì„¸ìš” \\n\\nAssistant:\"\n",
    "model_id = \"anthropic.claude-v2\"\n",
    "\n",
    "aws_cli_profile_name = \"gonsoomoon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eadc22fc-787d-418f-bb04-da7301ffae02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=' ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” AI ì±—ë´‡ìœ¼ë¡œ ì‚¬ìš©ìžì™€ ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. ëŒ€í™”ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ê³  íë¦„ì— ë§žì¶”ì–´ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìžì˜ ì˜ë„ë¥¼ ì •í™•ížˆ íŒŒì•…í•˜ì—¬ ì •ë³´ë¥¼ ì œê³µí•˜ê±°ë‚˜ ì¶”ì²œì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ëŒ€í™” ëŠ¥ë ¥ì´ í–¥ìƒë©ë‹ˆë‹¤. ê°œì¸í™”ëœ ì„œë¹„ìŠ¤ ì œê³µì´ ê°€ëŠ¥í•˜ê³  24ì‹œê°„ í™œìš©í•  ìˆ˜ ìžˆë‹¤ëŠ” ìž¥ì ì´ ìžˆìŠµë‹ˆë‹¤.', additional_kwargs={}, raw={'completion': ' ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” AI ì±—ë´‡ìœ¼ë¡œ ì‚¬ìš©ìžì™€ ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. ëŒ€í™”ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ê³  íë¦„ì— ë§žì¶”ì–´ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìžì˜ ì˜ë„ë¥¼ ì •í™•ížˆ íŒŒì•…í•˜ì—¬ ì •ë³´ë¥¼ ì œê³µí•˜ê±°ë‚˜ ì¶”ì²œì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ëŒ€í™” ëŠ¥ë ¥ì´ í–¥ìƒë©ë‹ˆë‹¤. ê°œì¸í™”ëœ ì„œë¹„ìŠ¤ ì œê³µì´ ê°€ëŠ¥í•˜ê³  24ì‹œê°„ í™œìš©í•  ìˆ˜ ìžˆë‹¤ëŠ” ìž¥ì ì´ ìžˆìŠµë‹ˆë‹¤.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}, delta=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resp = Bedrock(\n",
    "    model= model_id, profile_name= aws_cli_profile_name\n",
    ").complete(prompt)\n",
    "\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac744993-d8c3-4faa-962a-652ed327f7fd",
   "metadata": {},
   "source": [
    "# Stream ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "396ae51e-55e1-469c-93a7-9f226338a0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” AI ê¸°ë°˜ì˜ ëŒ€í™”í˜• ì±—ë´‡ìœ¼ë¡œ, ì‚¬ìš©ìžì™€ ìžì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜ë©°, ëŒ€í™”ì˜ ë§¥ë½ì„ ìœ ì§€í•˜ë©´ì„œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë˜í•œ ì§€ì†ì ì¸ í•™ìŠµì„ í†µí•´ ê¸°ëŠ¥ê³¼ ì§€ì‹ì´ í™•ìž¥ë˜ë¯€ë¡œ ì ì  ë” ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê°œë°œìžê°€ ìµœì†Œí•œì˜ ë…¸ë ¥ìœ¼ë¡œ ì„¸ì´ì§€ë©”ì´ì»¤ë¥¼ í†µí•´ ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ì±—ë´‡ ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³  ìš´ì˜í•  ìˆ˜ ìžˆë‹¤ëŠ” ì ë„ í° ìž¥ì ìž…ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "from llama_index.llms import Bedrock\n",
    "\n",
    "llm = Bedrock(\n",
    "    model= model_id, profile_name= aws_cli_profile_name\n",
    ")\n",
    "resp = llm.stream_complete(prompt)\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04196f3-ee9e-45c2-9ae7-797e2b107249",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8e08a0-8449-4a0a-9015-b6d1c8f6ed29",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock LLama2 Model ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "898f8f5a-ddc0-4a10-beff-2ffaf7edb84d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='ì„¸ì´ì§€ë©”ì´ì»¤ì˜ ìž¥ì ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì´ ìžˆìŠµë‹ˆë‹¤.\\n\\n1. ë†’ì€ í’ˆì§ˆ: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ í’ˆì§ˆì˜ ìž¬ë£Œë¥¼ ì‚¬ìš©í•˜ì—¬ ì œí’ˆì„ ìƒì‚°í•˜ë¯€ë¡œ, ê³ ê°ì—ê²Œ ë†’ì€ í’ˆì§ˆì˜ ì œí’ˆì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n2. ë¹ ë¥¸ ì œìž‘: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ ê°ì˜ ìš”ì²­ì— ë”°ë¼ ë¹ ë¥¸ ì‹œì¼ë‚´ì— ì œí’ˆì„ ì œìž‘í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n3. ì €ë ´í•œ ê°€ê²©: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ì§ì ‘ì ìœ¼ë¡œ ìž¬ë£Œë¥¼ êµ¬ìž…í•˜ì—¬ ì œí’ˆì„ ìƒì‚°í•˜ë¯€ë¡œ, ê³ ê°ì—ê²Œ ì €ë ´í•œ ê°€ê²©ìœ¼ë¡œ ì œí’ˆì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n4. ë””ìžì¸ ìžìœ : ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ ê°ì˜ ìš”ì²­ì— ë”°ë¼ ë””ìžì¸ì„ ìžìœ ë¡­ê²Œ ì„¤ê³„í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n5. ê³ ê° ì§€ì›: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ ê°ì—ê²Œ ë¹ ë¥¸ ê³ ê° ì§€ì›ì„ ì œê³µí•˜ì—¬, ê³ ê°ì˜ ë¬¸ì˜ë‚˜ ë¬¸ì œì— ', additional_kwargs={}, raw={'generation': 'ì„¸ì´ì§€ë©”ì´ì»¤ì˜ ìž¥ì ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì´ ìžˆìŠµë‹ˆë‹¤.\\n\\n1. ë†’ì€ í’ˆì§ˆ: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ í’ˆì§ˆì˜ ìž¬ë£Œë¥¼ ì‚¬ìš©í•˜ì—¬ ì œí’ˆì„ ìƒì‚°í•˜ë¯€ë¡œ, ê³ ê°ì—ê²Œ ë†’ì€ í’ˆì§ˆì˜ ì œí’ˆì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n2. ë¹ ë¥¸ ì œìž‘: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ ê°ì˜ ìš”ì²­ì— ë”°ë¼ ë¹ ë¥¸ ì‹œì¼ë‚´ì— ì œí’ˆì„ ì œìž‘í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n3. ì €ë ´í•œ ê°€ê²©: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ì§ì ‘ì ìœ¼ë¡œ ìž¬ë£Œë¥¼ êµ¬ìž…í•˜ì—¬ ì œí’ˆì„ ìƒì‚°í•˜ë¯€ë¡œ, ê³ ê°ì—ê²Œ ì €ë ´í•œ ê°€ê²©ìœ¼ë¡œ ì œí’ˆì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n4. ë””ìžì¸ ìžìœ : ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ ê°ì˜ ìš”ì²­ì— ë”°ë¼ ë””ìžì¸ì„ ìžìœ ë¡­ê²Œ ì„¤ê³„í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n5. ê³ ê° ì§€ì›: ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ê³ ê°ì—ê²Œ ë¹ ë¥¸ ê³ ê° ì§€ì›ì„ ì œê³µí•˜ì—¬, ê³ ê°ì˜ ë¬¸ì˜ë‚˜ ë¬¸ì œì— ', 'prompt_token_count': 48, 'generation_token_count': 512, 'stop_reason': 'length'}, delta=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms import Bedrock\n",
    "\n",
    "# model_id = \"amazon.titan-embed-text-v1\"\n",
    "# model_id = \"amazon.titan-embed-g1-text-02\"\n",
    "model_id = \"meta.llama2-13b-chat-v1\"\n",
    "\n",
    "llm = Bedrock(\n",
    "    model= model_id, profile_name= aws_cli_profile_name\n",
    ")\n",
    "\n",
    "# llm.context_size = 8192\n",
    "\n",
    "resp = llm.complete(prompt)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619d36a-3e49-497f-9e6e-3369daf1e931",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock Embedding Model ì‚¬ìš©\n",
    "- ì•„ì§ ì§€ì›ì´ ì•ˆë˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ìž„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffe63ea0-d15b-4107-8040-5e89edc6a9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`context_size` argument not provided andmodel provided refers to a non-foundation model. Please specify the context_size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model_id = \"amazon.titan-embed-text-v1\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model_id = \"amazon.titan-embed-g1-text-02\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamazon.titan-elt-medium\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mBedrock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maws_cli_profile_name\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# llm.context_size = 8192\u001b[39;00m\n\u001b[1;32m     13\u001b[0m resp \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mcomplete(prompt, )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/llama_index/llms/bedrock.py:71\u001b[0m, in \u001b[0;36mBedrock.__init__\u001b[0;34m(self, model, temperature, max_tokens, context_size, profile_name, aws_access_key_id, aws_secret_access_key, aws_session_token, timeout, max_retries, additional_kwargs, callback_manager)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     57\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     callback_manager: Optional[CallbackManager] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     69\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m BEDROCK_FOUNDATION_LLMS:\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`context_size` argument not provided and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel provided refers to a non-foundation model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please specify the context_size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         )\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: `context_size` argument not provided andmodel provided refers to a non-foundation model. Please specify the context_size"
     ]
    }
   ],
   "source": [
    "from llama_index.llms import Bedrock\n",
    "\n",
    "# model_id = \"amazon.titan-embed-text-v1\"\n",
    "# model_id = \"amazon.titan-embed-g1-text-02\"\n",
    "model_id = \"amazon.titan-elt-medium\"\n",
    "\n",
    "llm = Bedrock(\n",
    "    model= model_id, profile_name= aws_cli_profile_name\n",
    ")\n",
    "\n",
    "# llm.context_size = 8192\n",
    "\n",
    "resp = llm.complete(prompt, )\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4f9b7-905f-4f91-bf90-39032978dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
