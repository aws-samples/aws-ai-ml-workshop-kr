{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cf0287-4f34-423d-a25b-83e92acdb5d7",
   "metadata": {},
   "source": [
    "# RAG Based on ReRanker\n",
    "- Hybrid Search\n",
    "- ReRanker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f81abc-3277-4a6b-9ef1-d4f997d67fbe",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde4105-b759-4d6c-8214-8e1ab485ae48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2cdb1-d785-4317-afce-938f13141085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ade56-8dbc-4ded-b355-7e4bcc971e90",
   "metadata": {},
   "source": [
    "## 1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d877f-e877-48f6-8dd4-239de20e45cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e6490-c79a-49e4-841c-9fdb91292608",
   "metadata": {},
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9312c-5f61-4730-96c3-5eef54a5f08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a9e34-417a-422f-9f75-cb211b2e70e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Titan Embedding 및 LLM 인 Claude-v3 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf63d2-4110-407c-af06-a45d2fbed4b5",
   "metadata": {},
   "source": [
    "### LLM 로딩 (Claude-v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51443a-04f9-465c-9564-53053eb3e1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e84e0-b9e1-4b12-8e7a-68f03c5416e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_text = ChatBedrock(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-Haiku\"),\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 1024,\n",
    "        \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2e829-af8f-4e90-b994-59106cdec8d8",
   "metadata": {},
   "source": [
    "### Embedding 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b8752-d1e3-4f41-ba35-6da42c3785db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import KoSimCSERobertaContentHandler, SagemakerEndpointEmbeddingsJumpStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b03f7-3186-4969-b76a-98fe56bd5fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding_model(is_bedrock_embeddings, is_KoSimCSERobert, aws_region, endpont_name=None):\n",
    "    \n",
    "    if is_bedrock_embeddings:\n",
    "        # We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "        from langchain.embeddings import BedrockEmbeddings\n",
    "        llm_emb = BedrockEmbeddings(\n",
    "            client=boto3_bedrock,\n",
    "            model_id=bedrock_info.get_model_id(\n",
    "                model_name=\"Titan-Embeddings-G1\"\n",
    "            )\n",
    "        )\n",
    "        print(\"Bedrock Embeddings Model Loaded\")\n",
    "\n",
    "    elif is_KoSimCSERobert:\n",
    "        LLMEmbHandler = KoSimCSERobertaContentHandler()\n",
    "        endpoint_name_emb = endpont_name\n",
    "        llm_emb = SagemakerEndpointEmbeddingsJumpStart(\n",
    "            endpoint_name=endpoint_name_emb,\n",
    "            region_name=aws_region,\n",
    "            content_handler=LLMEmbHandler,\n",
    "        )        \n",
    "        print(\"KoSimCSERobert Embeddings Model Loaded\")\n",
    "    else:\n",
    "        llm_emb = None\n",
    "        print(\"No Embedding Model Selected\")\n",
    "    \n",
    "    return llm_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72a6b8-eaf0-4036-a530-3bde5ba988cd",
   "metadata": {},
   "source": [
    "#### [중요] is_KoSimCSERobert == True 일시에 endpoint_name 을 꼭 넣어 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e032b-8715-432c-ae71-12a889f8ffc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_bedrock_embeddings = True\n",
    "is_KoSimCSERobert = False\n",
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "\n",
    "##############################\n",
    "# Parameters for is_KoSimCSERobert\n",
    "##############################\n",
    "if is_KoSimCSERobert: endpont_name = \"<endpoint-name>\"\n",
    "else: endpont_name = None\n",
    "##############################\n",
    "\n",
    "llm_emb = get_embedding_model(is_bedrock_embeddings, is_KoSimCSERobert, aws_region, endpont_name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b67d5-382e-4715-a841-eb07b8655da8",
   "metadata": {},
   "source": [
    "## 3. Depoly ReRanker model (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08a296-41ef-44cb-857b-63d05a8d187c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd04a7-8200-49e7-ae69-55a82be199b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "depoly = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfd5d7-0fc0-4b00-8106-1e239e44f7c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Korean fune-tuned model\n",
    "    - hugging face: https://huggingface.co/Dongjin-kr/ko-reranker\n",
    "    - git repo: https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/30_fine_tune/reranker-kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40e3dd-a19f-4af3-831a-0cfe79e72cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if depoly:\n",
    "\n",
    "    try:\n",
    "        role = sagemaker.get_execution_role()\n",
    "    except ValueError:\n",
    "        iam = boto3.client('iam')\n",
    "        role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "    # Hub Model configuration. https://huggingface.co/models\n",
    "    hub = {\n",
    "        'HF_MODEL_ID':'Dongjin-kr/ko-reranker',\n",
    "        'HF_TASK':'text-classification'\n",
    "    }\n",
    "\n",
    "    # create Hugging Face Model Class\n",
    "    huggingface_model = HuggingFaceModel(\n",
    "        transformers_version='4.28.1',\n",
    "        pytorch_version='2.0.0',\n",
    "        py_version='py310',\n",
    "        env=hub,\n",
    "        role=role, \n",
    "    )\n",
    "\n",
    "    # deploy model to SageMaker Inference\n",
    "    predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1, # number of instances\n",
    "        instance_type='ml.g5.xlarge' # instance type\n",
    "    )\n",
    "\n",
    "    print(f'Accept: {predictor.accept}')\n",
    "    print(f'ContentType: {predictor.content_type}')\n",
    "    print(f'Endpoint: {predictor.endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a9f20-f531-49cc-8947-50a2973b49d2",
   "metadata": {},
   "source": [
    "#### Save reranker endpoint to Parameter Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070c5d9-b202-4b8c-a1ee-cb7fea9f87c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cf902-d408-48c9-883b-0c7dd9a827bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region=boto3.Session().region_name\n",
    "pm = parameter_store(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948269e-28ea-480c-a718-9cb2f53e71fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pm.put_params(\n",
    "    key=\"reranker_endpoint\",\n",
    "    value=f'{predictor.endpoint}',\n",
    "    overwrite=True,\n",
    "    enc=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e648ef-01ec-4e2f-ba88-7d2510fdb7a6",
   "metadata": {},
   "source": [
    "## 4. Invocation (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114be617-a687-4733-abb9-30394c7ef35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n",
    "print (f'runtime_client: {runtime_client}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee5c45-de87-4a2b-bc04-bbc649fcd0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = pm.get_params(\n",
    "    key=\"reranker_endpoint\",\n",
    "    enc=False\n",
    ")\n",
    "deserializer = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6288ed-b4fa-466f-9e2b-57484b827b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"text\": \"I hate you\", \"text_pair\": \"I don't like you\"},\n",
    "            {\"text\": \"He hates you\", \"text_pair\": \"He like you\"},\n",
    "            {\"text\": \"그는 너를 싫어해\", \"text_pair\": \"그는 너를 좋아해\"},\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eebe88-8b92-4e81-a103-b5a5d7a91bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=deserializer,\n",
    "    Body=payload\n",
    ")\n",
    "## deserialization\n",
    "out = json.loads(response['Body'].read().decode()) ## for json\n",
    "print (f'Response: {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e432237-b9b5-4be3-aa0c-c30eeca6f480",
   "metadata": {},
   "source": [
    "## 5. LangChainmOpenSearch VectorStore 정의\n",
    "### 선수 조건\n",
    "- 01_preprocess_docs/02_load_docs_opensearch.ipynb를 통해서 OpenSearch Index 가 생성이 되어 있어야 합니다.\n",
    "#### [중요] 아래에 aws parameter store 에 아래 인증정보가 먼저 입력되어 있어야 합니다.\n",
    "- 01_preprocess_docs/01_parameter_store_example.ipynb 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d192b6-68ce-465e-9fa7-04b5201f4453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = pm.get_params(\n",
    "    key=\"opensearch_domain_endpoint\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_id = pm.get_params(\n",
    "    key=\"opensearch_user_id\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_password = pm.get_params(\n",
    "    key=\"opensearch_user_password\",\n",
    "    enc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7866fd-fd9c-4b41-b600-a91e43edfe4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = opensearch_domain_endpoint\n",
    "rag_user_name = opensearch_user_id\n",
    "rag_user_password = opensearch_user_password\n",
    "\n",
    "http_auth = (rag_user_name, rag_user_password) # Master username, Master password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a900e-effc-4d7f-a179-b6c00eac03ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index 이름 셋팅\n",
    "- 이전 노트북 01_preprocess_docs/02_load_docs_opensearch.ipynb를 통해서 생성된 OpenSearch Index name 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9b5eb-052e-4e84-846b-c5385e853ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = opensearch_user_password = pm.get_params(\n",
    "    key=\"opensearch_index_name\",\n",
    "    enc=True\n",
    ")\n",
    "\n",
    "print (f'index_name: {index_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f5785-b88d-44fa-a603-080e4bd734a6",
   "metadata": {},
   "source": [
    "### OpenSearch Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b7502-5799-4702-bc17-959e88c330a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.opensearch import opensearch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb46a1-e425-4f7e-9319-793b55abb938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_client = opensearch_utils.create_aws_opensearch_client(\n",
    "    aws_region,\n",
    "    opensearch_domain_endpoint,\n",
    "    http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5084376-7523-4cf9-9123-adc4ae79f66d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Retriever based on Hybrid Search 정의\n",
    "- LangChain에서 제공하는 **BaseRetriever** 클래스를 상속받아 **Custom Retriever**를 정의 할 수 있습니다.\n",
    "- 본 샘플코드 에서는 **Hybrid Search based Retriever**를 **정의**합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a25df0-2a13-4d73-9edc-532caf98f804",
   "metadata": {},
   "source": [
    "OpenSearch Hybrid 는 아래와 같은 방식으로 작동합니다.\n",
    "- (1) Sematic search를 통해 각 document별 relevant score 산출\n",
    "- (2) Lexical search를 통해 각 document별 relevant score 산출\n",
    "- (3-1) Rank-fusion 방식이 \"simple weighted\" 일 경우\n",
    "    - 산출된 score에 대한 normalization 수행\n",
    "    - 전체 결과에서 가장 높은 스코어는 표준화 과정을 통하여 스코어가 1.0 이 됨.\n",
    "- (3-2) Rank-fusion 방식이 \"Reciprocal Rank Fusion (RRF)\" 일 경우\n",
    "    - Paper: https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf\n",
    "    - Desc: https://medium.com/@sowmiyajaganathan/hybrid-search-with-re-ranking-ff120c8a426d\n",
    "    - **RRF의 경우 score가 아닌 ranking 정보를 활용, 때문에 score normalization이 필요 없음**\n",
    "    - ![rrf.png](../../../10_advanced_question_answering/img/rrf.png)\n",
    "\n",
    "RRF는 langchain에서 \"Ensemble Retriever\" 이름으로 api를 제공합니다. \n",
    "- https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8e470-63a9-4c3d-94c8-1d270a6da822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import OpenSearchHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7feac2f-21a2-4756-b989-66c180bb1e79",
   "metadata": {},
   "source": [
    "- 필터 설정 예시\n",
    "- filter=[ <BR>\n",
    "    　{\"term\": {\"metadata.[**your_metadata_attribute_name**]\": \"**your first keyword**\"}}, <BR>\n",
    "    　{\"term\": {\"metadata.[**your_metadata_attribute_name**]\": \"**your second keyword**\"}},<BR>\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7e131-294f-4ff8-9331-989709c7079c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_hybrid_retriever = OpenSearchHybridSearchRetriever(\n",
    "    # necessary\n",
    "    os_client=os_client,\n",
    "    index_name=index_name,\n",
    "    llm_emb=llm_emb,\n",
    "    llm_text=llm_text,\n",
    "\n",
    "    # option for lexical\n",
    "    minimum_should_match=0,\n",
    "    filter=[],\n",
    "\n",
    "    # option for rank fusion\n",
    "    fusion_algorithm=\"RRF\", # [\"RRF\", \"simple_weighted\"], rank fusion 방식 정의\n",
    "    ensemble_weights=[.51, .49], # [for semantic, for lexical], Semantic, Lexical search 결과에 대한 최종 반영 비율 정의\n",
    "\n",
    "    reranker=True, # enable reranker with reranker model\n",
    "    reranker_endpoint_name=endpoint_name, # endpoint name for reranking model\n",
    "\n",
    "    # option for async search\n",
    "    async_mode=True,\n",
    "\n",
    "    # option for output\n",
    "    k=5, # 최종 Document 수 정의\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb26835-ad98-41c5-9e9d-2453642e3551",
   "metadata": {},
   "source": [
    "### Retrieval example\n",
    "- default search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06e89f-79de-413c-ba9c-a188ca3fe2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import show_context_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bfee3-dac1-45b9-8795-03e36c1632a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"중지된 경우 이체\"\n",
    "#query = \"vidio max size?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b13e5e-4a66-4dc8-b18c-42a6e3bd6037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "search_hybrid_result = opensearch_hybrid_retriever.get_relevant_documents(query)\n",
    "\n",
    "print(\"\\n==========  Results  ==========\\n\")\n",
    "print(f'1. question: {query}')\n",
    "print (f'2. # documents: {len(search_hybrid_result)}')\n",
    "print(\"3. Documents: \\n\")\n",
    "\n",
    "search_hybrid_result\n",
    "show_context_used(search_hybrid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981abe7-5208-48f5-a9cc-8c557e9941ca",
   "metadata": {},
   "source": [
    "## 5. RAG using RetrievalQA powered by LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf6d2b-451b-499c-aec2-bb6f5abafbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import prompt_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490df1f-8113-4dd1-a578-a3e1a6918fde",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prompting\n",
    "- [TIP] Prompt의 instruction의 경우 한글보다 영어로 했을 때 더 좋은 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3ec15-7750-40c3-bab8-341d56195057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = prompt_repo.get_system_prompt()\n",
    "pprint (system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66157a6-aec8-4555-a90f-1178e6f4f6e0",
   "metadata": {},
   "source": [
    "### Update Search Params (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df2daf-8b42-472a-885f-97320ee98132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import qa_chain\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2697230-6962-43d8-8917-ba9daa4295bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_hybrid_retriever.update_search_params(\n",
    "    k=5,\n",
    "    minimum_should_match=0,\n",
    "    #filter=[\n",
    "    #    {\"term\": {\"metadata.project\": \"KPE\"}},\n",
    "    #],\n",
    "    reranker=True,\n",
    "    reranker_endpoint_name=endpoint_name,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee26c22-b674-4f4f-a87b-29508e336fda",
   "metadata": {},
   "source": [
    "### Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa61d3-9256-432a-96a3-2c696c97ea68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa = qa_chain(\n",
    "    llm_text=llm_text,\n",
    "    retriever=opensearch_hybrid_retriever,\n",
    "    system_prompt=system_prompt,\n",
    "    return_context=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ad324-40b3-4bcb-92b9-50eb080492a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"중지된 경우 이체\"\n",
    "#query = \"vidio max size?\"\n",
    "\n",
    "response, contexts = qa.invoke(\n",
    "    query = query\n",
    ")\n",
    "\n",
    "show_context_used(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e77dad-dc19-416b-80e7-19fac3b736a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"##################################\")\n",
    "print(\"query: \", query)\n",
    "print(\"##################################\")\n",
    "\n",
    "print (colored(\"\\n\\n### Answer ###\", \"blue\"))\n",
    "print_ww(response)\n",
    "\n",
    "print (colored(\"\\n\\n### Contexts ###\", \"green\"))\n",
    "show_context_used(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d1ef1-8a66-4530-9080-94671c1402ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1a2a9-a914-4b61-8e8f-3523997f2181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6653b87-015b-4b2c-872b-26772b22c266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995dbeec-9be1-498f-8732-465abe3eb723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f437e5-7f85-469e-bf27-17fedafcf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U FlagEmbedding\n",
    "%%time\n",
    "from FlagEmbedding import FlagReranker\n",
    "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=False) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "score = reranker.compute_score(['query', 'passage'])\n",
    "print(score)\n",
    "\n",
    "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
