{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406afba6-7840-4f53-9945-ee3c2e6b143b",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Claude3 Caculator_tool\n",
    "\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html\n",
    "- https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d769b173-6319-4aad-b0bc-1665b1556eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.136)\n",
      "Requirement already satisfied: botocore in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.136)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57b6c1-733d-411b-8b67-3911ac320b32",
   "metadata": {},
   "source": [
    "## 1. Bedrock 호출 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f0cdba-f1d5-4c7a-80a0-87ede38e1293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "class StationNotFoundError(Exception):\n",
    "    \"\"\"Raised when a radio station isn't found.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate(expression):\n",
    "    import re\n",
    "    # Remove any non-digit or non-operator characters from the expression\n",
    "    expression = re.sub(r'[^0-9+\\-*/().]', '', expression)\n",
    "    \n",
    "    try:\n",
    "        # Evaluate the expression using the built-in eval() function\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except (SyntaxError, ZeroDivisionError, NameError, TypeError, OverflowError):\n",
    "        return \"Error: Invalid expression\"\n",
    "    \n",
    "\n",
    "def process_tool_call(tool_name, tool_input):\n",
    "    if tool_name == \"calculator\":\n",
    "        return calculate(tool_input[\"expression\"])\n",
    "\n",
    "\n",
    "def claude_converse(messages, model='haiku', stream=True, system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    import boto3\n",
    "    from botocore.config import Config\n",
    "    \n",
    "    config = Config(\n",
    "        read_timeout=600, ## Timeout 시간 조정\n",
    "        retries = dict(\n",
    "            max_attempts = 8 ## Retry 횟수 조정\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region_name, config=config)\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    params['messages'] = messages\n",
    "    \n",
    "    if model == 'opus':\n",
    "        params['modelId'] = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "    elif model == 'sonnet':\n",
    "        params['modelId'] = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    else:\n",
    "        params['modelId'] = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    \n",
    "    \n",
    "    # Format the request payload using the model's native structure.\n",
    "    params['inferenceConfig'] = {\n",
    "        \"maxTokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.999\n",
    "    }\n",
    "    \n",
    "    ## Additional inference parameters that the model supports\n",
    "    params['additionalModelRequestFields'] = {\"top_k\": 350}\n",
    "    \n",
    "    if system:\n",
    "        params['system'] = [{\"text\" : system}]\n",
    "    \n",
    "    # print(f\"tools : {tools}\")\n",
    "    if toolConfig:\n",
    "        params['toolConfig'] = toolConfig\n",
    "    \n",
    "    if stream:\n",
    "        response = client.converse_stream(**params)\n",
    "    else:\n",
    "        response = client.converse(**params)\n",
    "    return response\n",
    "\n",
    "    \n",
    "    \n",
    "def chat_with_claude_converse_tooluse(user_message, model='haiku', stream=True, system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    \n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}]\n",
    "    }]\n",
    "\n",
    "    response = claude_converse(messages, model, stream, system, toolConfig, region_name)\n",
    "    \n",
    "    if stream:\n",
    "        return_params = tool_use(response)\n",
    "        \n",
    "        role = return_params.get('role')\n",
    "        toolUseId = return_params.get('toolUseId')\n",
    "        tool_name = return_params.get('tool_name')\n",
    "        tool_input = return_params.get('tool_input')\n",
    "        text_input = return_params.get('text_input')\n",
    "        pre_inputTokens = return_params.get('inputTokens')\n",
    "        pre_outputTokens = return_params.get('outputTokens') \n",
    "        pre_totalTokens = return_params.get('totalTokens')\n",
    "        pre_latencyMs = return_params.get('latencyMs')\n",
    "        stop_reason = return_params.get('stop_reason')\n",
    "        \n",
    "        msg_dict = {}\n",
    "        msg_dict['toolUse'] = {}\n",
    "        \n",
    "        if text_input:\n",
    "            msg_dict['text']= text_input\n",
    "        if toolUseId:\n",
    "            msg_dict['toolUse']['toolUseId']= toolUseId\n",
    "        if tool_name:\n",
    "            msg_dict['toolUse']['name']= tool_name\n",
    "        if tool_input:\n",
    "            msg_dict['toolUse']['input']= tool_input\n",
    "        \n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": role,\n",
    "                \"content\": [msg_dict]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if stop_reason == 'tool_use':\n",
    "            if tool_name == 'calculator':\n",
    "                print(f\"Requesting tool {tool_name}. Request: {toolUseId}\")\n",
    "                tool_result = {}\n",
    "                try:\n",
    "                    result = process_tool_call(tool_name, tool_input)\n",
    "                    print(f\"result : {result}\")\n",
    "\n",
    "                    tool_result = {\n",
    "                        \"toolUseId\": toolUseId,\n",
    "                        \"content\": [{\"json\": {\"result\": result}}]\n",
    "                    }\n",
    "                except StationNotFoundError as err:\n",
    "                    tool_result = {\n",
    "                        \"toolUseId\": tool['toolUseId'],\n",
    "                        \"content\": [{\"text\":  err.args[0]}],\n",
    "                        \"status\": 'error'\n",
    "                    }\n",
    "\n",
    "                tool_result_message = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"toolResult\": tool_result\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                messages.append(tool_result_message)\n",
    "                # print(f\"messages : {messages}\")\n",
    "                # Send the tool result to the model.\n",
    "                response = claude_converse(messages, model, stream, system, toolConfig, region_name)\n",
    "                return_params = tool_use(response, pre_inputTokens, pre_outputTokens, pre_totalTokens, pre_latencyMs, last_output=True)\n",
    " \n",
    "                        \n",
    "        # print the final response from the model.\n",
    "        for content in output_message['content']:\n",
    "            if content.get(\"text\"):\n",
    "                print(f\"Text: {content['text']}\")\n",
    "            elif content.get(\"toolUse\"):\n",
    "                print(f\"toolUseId: {content['toolUse']['toolUseId']}\")\n",
    "                print(f\"name: {content['toolUse']['name']}\")\n",
    "                print(f\"input: {content['toolUse']['input']}\")\n",
    "            \n",
    "        print(f\"Input tokens:  {inputTokens}\")\n",
    "        print(f\"Output tokens:  {outputTokens}\")\n",
    "        print(f\"Total tokens:  {totalTokens}\")\n",
    "        print(f\"Stop reason: {response['stopReason']}\")\n",
    "\n",
    "\n",
    "def output_claude_converse_stream(messages, model='haiku',system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    from botocore.exceptions import ClientError\n",
    "    import json\n",
    "    msg_param = {}\n",
    "    msg_param['text_input'] = \"\"\n",
    "    msg_param['tool_input'] = \"\"\n",
    "\n",
    "    try:\n",
    "        response = claude_converse(messages, model, True, system, toolConfig, region_name)\n",
    "        msg_tooluse = \"\"\n",
    "        msg_print = False\n",
    "        stream_response = response.get('stream')\n",
    "        for event in stream_response:\n",
    "            if 'messageStart' in event:\n",
    "                msg_param['role'] = event['messageStart']['role']\n",
    "                print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "            if 'contentBlockStart' in event:\n",
    "                contentblock = event['contentBlockStart']['start']\n",
    "                if contentblock.get(\"toolUse\"):\n",
    "                    msg_param['toolUseId'] = contentblock['toolUse']['toolUseId']\n",
    "                    msg_param['tool_name'] = contentblock['toolUse']['name']\n",
    "            \n",
    "            if 'contentBlockDelta' in event:\n",
    "                delta = event['contentBlockDelta']['delta']\n",
    "                if delta.get('text'):\n",
    "                    msg_param['text_input'] += event['contentBlockDelta']['delta']['text']\n",
    "                    print(event['contentBlockDelta']['delta']['text'], end=\"\")\n",
    "                elif delta.get('toolUse'):\n",
    "                    msg_param['tool_input'] += event['contentBlockDelta']['delta']['toolUse']['input']\n",
    "                    print(event['contentBlockDelta']['delta']['toolUse']['input'], end=\"\")\n",
    "            if 'messageStop' in event:\n",
    "                msg_param['stop_reason'] = event['messageStop']['stopReason']\n",
    "                print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "\n",
    "            if 'metadata' in event:\n",
    "                metadata = event['metadata']\n",
    "                if 'usage' in metadata:\n",
    "                    print(\"\\nToken usage\")\n",
    "                    print(f\"Input tokens: {metadata['usage']['inputTokens']}\")\n",
    "                    print(\n",
    "                        f\"Output tokens: {metadata['usage']['outputTokens']}\")\n",
    "                    print(f\"Total tokens: {metadata['usage']['totalTokens']}\")\n",
    "                if 'metrics' in event['metadata']:\n",
    "                    print(\n",
    "                        f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\")\n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        print(\"A client error occurred: %s\", message)\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"\\nFinished generating text with model {model}.\")\n",
    "    return response, msg_param\n",
    "\n",
    "\n",
    "def caculator_stream_output(messages, response, msg_param):\n",
    "    import json\n",
    "\n",
    "    stream_response = response.get('stream')\n",
    "    role = msg_param['role']\n",
    "    stop_reason = msg_param['stop_reason']\n",
    "\n",
    "    msg_dict = {}\n",
    "    msg_dict['toolUse'] = {}\n",
    "    \n",
    "    toolUseId , tool_name, tool_input = \"\", \"\", \"\"\n",
    "\n",
    "    if msg_param.get('tool_input'):\n",
    "        tool_input = msg_param['tool_input']\n",
    "        tool_input = json.loads(tool_input)\n",
    "        msg_dict['toolUse']['input']= tool_input\n",
    "    if msg_param.get('text'):\n",
    "        msg_dict['text']= text_input\n",
    "    if msg_param.get('toolUseId'):\n",
    "        toolUseId = msg_param['toolUseId']\n",
    "        msg_dict['toolUse']['toolUseId']= toolUseId\n",
    "    if msg_param.get('tool_name'):\n",
    "        tool_name = msg_param['tool_name']\n",
    "        msg_dict['toolUse']['name']= tool_name\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": role,\n",
    "            \"content\": [msg_dict]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if stop_reason == 'tool_use':\n",
    "        if tool_name == 'calculator':\n",
    "            print(f\"Requesting tool {tool_name}. Request: {toolUseId}\")\n",
    "            tool_result = {}\n",
    "            try:\n",
    "                result = process_tool_call(tool_name, tool_input)\n",
    "                print(f\"result : {result}\")\n",
    "\n",
    "                tool_result = {\n",
    "                    \"toolUseId\": toolUseId,\n",
    "                    \"content\": [{\"json\": {\"result\": result}}]\n",
    "                }\n",
    "            except StationNotFoundError as err:\n",
    "                tool_result = {\n",
    "                    \"toolUseId\": tool['toolUseId'],\n",
    "                    \"content\": [{\"text\":  err.args[0]}],\n",
    "                    \"status\": 'error'\n",
    "                }\n",
    "            \n",
    "            tool_result_message = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"toolResult\": tool_result\n",
    "\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            messages.append(tool_result_message)\n",
    "\n",
    "    return messages\n",
    "\n",
    "def output_claude_converse(messages, model='haiku', system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    from botocore.exceptions import ClientError\n",
    "    try:\n",
    "        response = claude_converse(messages, model, False, system, toolConfig, region_name)\n",
    "\n",
    "        output_message = response['output']['message']\n",
    "\n",
    "        print(f\"Role: {output_message['role']}\")\n",
    "\n",
    "        for content in output_message['content']:\n",
    "            if content.get(\"text\"):\n",
    "                print(f\"Text: {content['text']}\")\n",
    "            elif content.get(\"toolUse\"):\n",
    "                print(f\"toolUseId: {content['toolUse']['toolUseId']}\")\n",
    "                print(f\"name: {content['toolUse']['name']}\")\n",
    "                print(f\"input: {content['toolUse']['input']}\")\n",
    "        token_usage = response['usage']\n",
    "        print(f\"Input tokens:  {token_usage['inputTokens']}\")\n",
    "        print(f\"Output tokens:  {token_usage['outputTokens']}\")\n",
    "        print(f\"Total tokens:  {token_usage['totalTokens']}\")\n",
    "        print(f\"Stop reason: {response['stopReason']}\")  \n",
    "    \n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        print(\"A client error occurred: %s\", message)\n",
    "    else:\n",
    "        print(\n",
    "            f\"\\nFinished generating text with model {model}.\")\n",
    "    return response\n",
    "\n",
    "\n",
    "def caculator_output(messages, response):\n",
    "    output_message = response['output']['message']\n",
    "    messages.append(output_message)\n",
    "    if response['stopReason'] == 'tool_use':\n",
    "        # Tool use requested. Call the tool and send the result to the model.\n",
    "        tool_requests = response['output']['message']['content']\n",
    "        for tool_request in tool_requests:\n",
    "            if 'toolUse' in tool_request:\n",
    "                tool = tool_request['toolUse']\n",
    "                print(f\"Requesting tool {tool['name']}. Request: {tool['toolUseId']}\")\n",
    "\n",
    "                if tool['name'] == 'calculator':\n",
    "                    tool_result = {}\n",
    "                    try:\n",
    "                        result = process_tool_call(tool['name'], tool['input'])\n",
    "                        print(f\"result : {result}\")\n",
    "\n",
    "                        tool_result = {\n",
    "                            \"toolUseId\": tool['toolUseId'],\n",
    "                            \"content\": [{\"json\": {\"result\": result}}]\n",
    "                        }\n",
    "                    except StationNotFoundError as err:\n",
    "                        print(f\"err : {err}\")\n",
    "                        tool_result = {\n",
    "                            \"toolUseId\": tool['toolUseId'],\n",
    "                            \"content\": [{\"text\":  err.args[0]}],\n",
    "                            \"status\": 'error'\n",
    "                        }\n",
    "\n",
    "                    tool_result_message = {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"toolResult\": tool_result\n",
    "\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    messages.append(tool_result_message)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f920b5-ba3e-4a76-a522-a1649d41577e",
   "metadata": {},
   "source": [
    "We'll define a simple calculator tool that can perform basic arithmetic operations. The tool will take a mathematical expression as input and return the result.\n",
    "Note that we are calling eval on the outputted expression. This is bad practice and should not be used generally but we are doing it for the purpose of demonstration.\n",
    "In this example, we define a calculate function that takes a mathematical expression as input, removes any non-digit or non-operator characters using a regular expression, and then evaluates the expression using the built-in eval() function. If the evaluation is successful, the result is returned as a string. If an error occurs during evaluation, an error message is returned.\n",
    "\n",
    "We then define the calculator tool with an input schema that expects a single expression property of type string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1f9bab-706f-451c-9a94-b046a51d4b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"기본적인 산술 연산을 수행하는 간단한 계산기\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"평가할 수학 표현식입니다.(예: '2 + 3 * 4').\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "],\n",
    "    \"toolChoice\": {\n",
    "        \"tool\" : {\n",
    "            \"name\":\"calculator\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955253cc-fe39-4022-a150-847456be7973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Role: assistant\n",
      "{\"expression\": \"1984135 * 9343116\"}\n",
      "Stop reason: tool_use\n",
      "\n",
      "Token usage\n",
      "Input tokens: 485\n",
      "Output tokens: 32\n",
      "Total tokens: 517\n",
      "Latency: 1151 milliseconds\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "Requesting tool calculator. Request: tooluse_Ea4D76u4QmyfmRNxFV4KWw\n",
      "result : 18538003464660\n",
      "\n",
      "Role: assistant\n",
      "{\"expression\": \"18538003464660\"}\n",
      "Stop reason: tool_use\n",
      "\n",
      "Token usage\n",
      "Input tokens: 566\n",
      "Output tokens: 32\n",
      "Total tokens: 598\n",
      "Latency: 1367 milliseconds\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "CPU times: user 172 ms, sys: 16.3 ms, total: 188 ms\n",
      "Wall time: 2.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"1,984,135 * 9,343,116의 결과는?\"\n",
    "\n",
    "message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}]\n",
    "    \n",
    "# response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)\n",
    "# message = caculator_output(message, response)\n",
    "# response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)\n",
    "\n",
    "response, msg_param = output_claude_converse_stream(message, 'sonnet', toolConfig=toolConfig)\n",
    "message = caculator_stream_output(message, response, msg_param)\n",
    "response, msg_param = output_claude_converse_stream(message, 'sonnet', toolConfig=toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc68a91-7bec-40be-877c-fc4e28a1e867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: assistant\n",
      "toolUseId: tooluse_qLlC0QZGQY2cx6W4Fl9OSg\n",
      "name: calculator\n",
      "input: {'expression': '(12851 - 593) * 301 + 76'}\n",
      "Input tokens:  486\n",
      "Output tokens:  47\n",
      "Total tokens:  533\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "Requesting tool calculator. Request: tooluse_qLlC0QZGQY2cx6W4Fl9OSg\n",
      "result : 3689734\n",
      "Role: assistant\n",
      "toolUseId: tooluse_bRv8fy5dRmWukwRZY07b1w\n",
      "name: calculator\n",
      "input: {'expression': '(12851 - 593) * 301 + 76'}\n",
      "Input tokens:  571\n",
      "Output tokens:  47\n",
      "Total tokens:  618\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "CPU times: user 33.6 ms, sys: 365 μs, total: 33.9 ms\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"(12851 - 593) * 301 + 76 계산해줘\"\n",
    "\n",
    "message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}]\n",
    "\n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)\n",
    "message = caculator_output(message, response)\n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30885b0f-0e5d-4f9e-83e5-dc91a3272bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: assistant\n",
      "toolUseId: tooluse_cbsKkOoFShW6_803jpkkvQ\n",
      "name: calculator\n",
      "input: {'expression': '15910385 / 193053'}\n",
      "Input tokens:  490\n",
      "Output tokens:  40\n",
      "Total tokens:  530\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "Requesting tool calculator. Request: tooluse_cbsKkOoFShW6_803jpkkvQ\n",
      "result : 82.41459599177428\n",
      "Role: assistant\n",
      "toolUseId: tooluse_GTIdjttjRmCUL6bQklM1tw\n",
      "name: calculator\n",
      "input: {'expression': 'round(15910385 / 193053, 2)'}\n",
      "Input tokens:  572\n",
      "Output tokens:  45\n",
      "Total tokens:  617\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "CPU times: user 32.9 ms, sys: 372 μs, total: 33.2 ms\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"15910385 을 193053으로 나눈 값은 뭐에요?\"\n",
    "\n",
    "message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}]\n",
    "\n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)\n",
    "message = caculator_output(message, response)\n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a74da-fd75-4fe4-81a7-4c5312aad706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
