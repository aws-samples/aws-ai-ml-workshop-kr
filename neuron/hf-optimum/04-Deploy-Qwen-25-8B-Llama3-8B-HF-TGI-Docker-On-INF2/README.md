#  Amazon SageMaker ë¥¼ ì´ìš©í•˜ì—¬ Amazon Inferentia2 ê¸°ë°˜ ìœ„ì— Llama3-í•œêµ­ì–´ íŒŒì¸ íŠœë‹ ëª¨ë¸, Qwen-2.5-8B ì„ ì„œë¹™í•˜ê¸°
Last Update: May 26, 2025 <br>
Contributor: ë¬¸ê³¤ìˆ˜ (Gonsoo Moon)

---

AWS Neuron ê¸°ë°˜ Optimum-neuron 0.0.28ì„ ì‚¬ìš©í•˜ì—¬ Llama3 í•œêµ­ì–´ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ Inferentia2ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì„œë¹™í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

1. ê°„í¸í•œ ê°œë°œ í™˜ê²½ì¸ SageMaker Notebook Instanceì˜ inf2.xlargeë¥¼ í™œìš©í•˜ì—¬ EC2ë¥¼ ì§ì ‘ ì„¤ì •í•  í•„ìš” ì—†ì´ Neuron SDKê°€ í¬í•¨ëœ Docker ì´ë¯¸ì§€ë¡œ ì‰½ê²Œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. íš¨ìœ¨ì ì¸ ë°°í¬ ì›Œí¬í”Œë¡œìš°: Notebook Instanceì—ì„œ ë¡œì»¬ ë„ì»¤ ì¼„í…Œì´ë„ˆ í…ŒìŠ¤íŠ¸ë¥¼ ì™„ë£Œí•œ í›„, ê²€ì¦ëœ ì„¤ì •ìœ¼ë¡œ SageMaker Inference Endpointë¥¼ ì‹ ì†í•˜ê²Œ ë°°í¬í•  ìˆ˜ ìˆì–´ ê°œë°œê³¼ ìš´ì˜ í™˜ê²½ì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

### Quick Start
ì´ë¯¸ Neuron ìœ¼ë¡œ ì»´íŒŒì¼ëœ ëª¨ë¸ì„ ë°”ë¡œ ì•„ë˜ ë…¸íŠ¸ë¶ì„ í†µí•´ì„œ ë°”ë¡œ ì‹¤í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
ì•„ë˜, "1. ê¸°ë³¸ ì‚¬ì „ ë‹¨ê³„: Quota ì¤€ë¹„ " ì—ì„œ Inference Endpoint Usage ì—ì„œ Quota í™•ë³´ í›„ì— í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

- [01-deploy-llama-3-neuron-moel-inferentia2](notebook/01-deploy-llama-3-neuron-moel-inferentia2.ipynb)
- [02-deploy-llama-3-neuron-moel-inferentia2-from-S3](notebook/02-deploy-llama-3-neuron-moel-inferentia2-from-S3.ipynb)
- [03-deploy-qwen-2-5-instruct-neuron-moel-inferentia2](notebook/03-deploy-qwen-2-5-instruct-neuron-moel-inferentia2.ipynb)

---

### ğŸ¯ ëª©ì 
í•œêµ­ì–´ë¡œ íŒŒì¸íŠœë‹ëœ Llama-3 8B ëª¨ë¸ì„ AWS Inferentia2 ì¹©ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…

### ğŸ“‹ ì£¼ìš” ë‹¨ê³„

**1. í™˜ê²½ ì¤€ë¹„**
- AWS í• ë‹¹ëŸ‰ í™•ë³´ (SageMaker Notebook Instance, Inference Endpoint)
- SageMaker Notebook Instance ìƒì„± (ml.inf2.xlarge, 128GB ìŠ¤í† ë¦¬ì§€)
- Docker ë°ì´í„° ì €ì¥ ìœ„ì¹˜ë¥¼ SageMaker ë””ë ‰í† ë¦¬ë¡œ ë³€ê²½

**2. Docker ì´ë¯¸ì§€ ì¤€ë¹„**
- AWSì—ì„œ ì œê³µí•˜ëŠ” ìµœì‹  TGI Neuron Docker ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
- optimum-neuron 0.0.28 ë²„ì „ ì‚¬ìš©
- ECR ë¡œê·¸ì¸ í›„ ì´ë¯¸ì§€ Pull

**3. ëª¨ë¸ ì»´íŒŒì¼**
- í•œêµ­ì–´ Llama-3 8B ëª¨ë¸ì„ Neuron ì¹©ìš©ìœ¼ë¡œ ì»´íŒŒì¼
- ë°°ì¹˜ í¬ê¸° 4, ì‹œí€€ìŠ¤ ê¸¸ì´ 4096, fp16 ì •ë°€ë„ ì‚¬ìš©
- 2ê°œ Neuron ì½”ì–´ í™œìš© (ml.inf2.xlarge ì— ë§ì¶˜ ì„¤ì •)

**4. ëª¨ë¸ ì„œë¹™**
- ì»´íŒŒì¼ëœ ëª¨ë¸ì„ TGI(Text Generation Inference)ë¡œ ì„œë¹™
- í¬íŠ¸ 8080ì—ì„œ HTTP API ì œê³µ
- OpenAI í˜¸í™˜ APIì™€ ê¸°ë³¸ Completion API ëª¨ë‘ ì§€ì›

**5. ì„±ëŠ¥ ê²€ì¦**
- ì¶”ë¡  ì†ë„: í† í°ë‹¹ ì•½ 49ms
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 19.4GB
- ë‘ ê°€ì§€ API í˜•íƒœë¡œ í…ŒìŠ¤íŠ¸ (Completion, Messages)

**6. ëª¨ë¸ ë°°í¬**
- ì»´íŒŒì¼ëœ ëª¨ë¸ì„ Hugging Face Hubì— ì—…ë¡œë“œ
- ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì´ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê³µìœ 


---

# 1. ê¸°ë³¸ ì‚¬ì „ ë‹¨ê³„
## Quota ì¤€ë¹„ 
- ë¨¼ì € AWS ê³„ì •ì— ì•„ë˜ì— í•´ë‹¹ë˜ëŠ” ê¸°ë³¸ì ì¸ [Quota](https://docs.aws.amazon.com/servicequotas/latest/userguide/intro.html) ê°€ í•„ìš” í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” [SageMaker AI Notebook instance](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html) ì™€ [SageMaker AI Inference Endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html) ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ê°ê° 1ê°œ ì”©ë§Œì„ ì¤€ë¹„ í•˜ì‹œë©´ ë©ë‹ˆë‹¤. 
    - ![quota_inf2.png](img/quota_inf2.png)

# 2. í™˜ê²½ ì¤€ë¹„ í•˜ê¸°
## 2.1 SageMaker Notebook Instance ìƒì„±í•˜ê¸°
ìƒì„±ì€ ì—¬ê¸° [SageMaker AI Notebook instance](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html) ê°€ì´ë“œë¥¼ í™•ì¸ í•´ì£¼ì‹œê³ , ì•„ë˜ëŠ” ì¤‘ìš” ë‚´ìš©ë§Œ ê¸°ìˆ  í•˜ê² ìŠµë‹ˆë‹¤.
ì•„ë˜ì™€ ê°™ì´ SageMaker Notebook Instance ë¥¼ ìƒì„±ì‹œì—, instance type ì„ ml.inf2.xlarge, ìŠ¤í† ë¦¬ì§€ëŠ” 128 GB ì§€ì • í•©ë‹ˆë‹¤.
- [sm_notebook.png](img/sm_notebook.png)
roleì€ ê¸°ì¡´ ê²ƒ í˜¹ì€ ìƒˆë¡œìš´ role ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤. ê·¸ë¦¬ê³  role ì€ AmazonSageMakerFullAccess, AmazonS3FullAccess ì´ í•„ìš”í•˜ê³ , SageMakr ì˜ ì‹ ë¢° ê´€ê³„ë„ í•„ìš” í•©ë‹ˆë‹¤.
- ![sm_role](img/sm_role.png)
- ![trust_r](img/trust_r.png)


## 2.2 SageMaker Notebook Instance ì—´ê¸° ë° ê¹ƒ ë¦¬í¬ ë‹¤ìš´ë¡œë“œ
ì¥¬í”¼í„° ë…¸íŠ¸ë¶ì„ ì˜¤í”ˆí•˜ê³ , í„°ë¯¸ë„ì„ ì—´ì–´ì„œ ì•„ë˜ì™€ ê°™ì´ Git Repo ë¥¼ í´ë¡œë‹ í•´ì£¼ì„¸ìš”.

```    
pwd
cd SageMaker/
pwd
git clone https://github.com/aws-samples/aws-ai-ml-workshop-kr.git
```       
- ![git_clone_repo.png](img/git_clone_repo.png)
- 
## 2.3 ë„ì»¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜ ë³€ê²½
ìš©ëŸ‰ì˜ í° docker image ë° ëŒ€ìš©ëŸ‰ì˜ Python Package ë¥¼ ì„¤ì¹˜í•˜ë©´, ë””í´íŠ¸ì˜ File System ì˜ ì‚¬ì´ì¦ˆê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ì¶”ê°€ë¡œ ìš©ëŸ‰ì´ í° File System ìœ¼ë¡œ ê²½ë¡œë¥¼ ë³€ê²½ í•©ë‹ˆë‹¤.

```    
docker info | grep "Docker Root Dir"
sudo systemctl stop docker docker.socket
sudo mkdir -p /etc/docker 
sudo tee /etc/docker/daemon.json << EOF
{
  "data-root": "/home/ec2-user/SageMaker/docker-data"
}
EOF

sudo systemctl enable docker    # ìë™ ì‹œì‘ ì„¤ì •
sudo systemctl start docker     # ì¦‰ì‹œ ì‹œì‘

docker info | grep "Docker Root Dir"
df -h
```    
- ![change_docker_loc.png](img/change_docker_loc.png)


# 3. AWS Neuron ê¸°ë°˜ì˜ Optimum-neuron 0.0.28 ë„ì»¤ ë‹¤ìš´ë¡œë“œ ë°›ê¸°
## 3.1 ìµœì‹  ë„ì»¤ ì´ë¯¸ì§€ ì •ë³´
- 2025.5.26 ì¼ í˜„ì¬ [v1.2-hf-tgi-0.0.28-pt-2.1.2-inf-neuronx-py310](https://github.com/aws/deep-learning-containers/releases?q=tgi&expanded=true) ì´ ë²„ì „ì´ ìµœì‹  ë²„ì „ ì…ë‹ˆë‹¤.
- ì´ ë„ì»¤ ì´ë¯¸ì§€ëŠ” SageMaker Endpoint ë¥¼ ìƒì„±ì‹œì— "ì¶”ë¡  ë„ì»¤ ì´ë¯¸ì§€" ë¡œ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
  ì •í™•í•œ Docker Image ì´ë¦„ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. (us-west-2 ë¦¬ì ¼ì˜ ê²½ìš°)
  
    ```  
      763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2 
    ```    
    
## 3.2 ìµœì‹  ë„ì»¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•˜ê¸°
```  
# AWS ECR ë¡œê·¸ì¸ í•˜ê¸°
aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com 

docker pull 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2 

docker image ls
```  
- ![pull_docker_optimum.png](img/pull_docker_optimum.png)

## 3.3 ë„ì»¤ì˜ Optimum-neuron ë²„ì „ í™•ì¸í•˜ê¸°
ë‹¤ìš´ë¡œë“œ ë°›ì€ ë„ì»¤ ì´ë¯¸ì§€ì˜ Optimum-neuron ì˜ ë²„ì „ ë° Neuron-cc ì˜ ë²„ì „ ë“±ì„ í™•ì¸ í•©ë‹ˆë‹¤.

```    
# ë„ì»¤ ì•ˆìœ¼ë¡œ ë“¤ì–´ê°€ê¸°
docker run -it --entrypoint /bin/bash \
763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2
# ëª…ë ¹ì–´ ì‹¤í–‰
optimum-cli env
```    

- ![enter_in_docker.jpg](img/enter_in_docker.jpg)

# 4. ëª¨ë¸ ì»´íŒŒì¼ í•˜ê¸°
í•œêµ­ì–´ íŒŒì¸ íŠœë‹ëœ [MLP-KTLim/llama-3-Korean-Bllossom-8B](https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B) ì„ Neuron ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ì»´íŒŒì¼ í•˜ê² ìŠµë‹ˆë‹¤. 

```
cd ~/SageMaker/

time docker run --entrypoint optimum-cli \
  -v $(pwd)/data:/data \
  --privileged \
  763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2 \
  export neuron \
  --model MLP-KTLim/llama-3-Korean-Bllossom-8B \
  --batch_size 4 \
  --sequence_length 4096 \
  --auto_cast_type fp16 \
  --num_cores 2 \
  /data/llama-3-Korean-Bllossom-8B-recompiled
```

- ![compile_model.jpg](img/compile_model.jpg)
  
# 5. ëª¨ë¸ ì„œë¹™ í…ŒìŠ¤íŠ¸ 
## 5.1 ë„ì»¤ ì»¨í…Œì´ë„ˆì˜ TGI ë¡œ ëª¨ë¸ ì„œë¹™
ì•„ë˜ë¥¼ ì‹¤í–‰í•˜ë©´ ì´ë¯¸ì§€ ì²˜ëŸ¼ ë‚˜ì˜¤ë©´ ëª¨ë¸ ì„œë¹™ ì¤€ë¹„ê°€ ë¨.
```
docker run -p 8080:8080 \
  -v $(pwd)/data:/data \
  --privileged \
  -e HF_MODEL_ID=/data/llama-3-Korean-Bllossom-8B-recompiled \
  -e HF_NUM_CORES=2 \
  -e HF_BATCH_SIZE=4 \
  -e HF_SEQUENCE_LENGTH=4096 \
  -e HF_AUTO_CAST_TYPE=fp16 \
  -e MAX_BATCH_SIZE=4 \
  -e MAX_INPUT_LENGTH=2048 \
  -e MAX_TOTAL_TOKENS=4096 \
  -e MESSAGES_API_ENABLED=true \
  763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2
```
- ![serve_model.png](img/serve_model.png)


## 5.2. Completion API í˜•íƒœë¡œ curl ì‹¤í–‰
- ì•„ë˜ curl ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰ í•©ë‹ˆë‹¤.ì•„ë˜ì˜ ì¶”ë¡  ëª…ë ¹ í˜•ì‹ì€ [TGI Official Git Repo](https://github.com/huggingface/text-generation-inference) ë¥¼ ì°¸ê³  í•˜ì„¸ìš”.

```
curl 127.0.0.1:8080/generate \
-X POST \
-d '{"inputs":"ë”¥ëŸ¬ë‹ì´ ë­ì•¼?","parameters":{"max_new_tokens":512}}' \
-H 'Content-Type: application/json'
```

- ì•„ë˜ëŠ” total_time="25.099483509s" validation_time="336.958Âµs" queue_time="24.691Âµs" inference_time="25.09912212s" time_per_token="49.021722ms" ì˜ ê±¸ë¦° ì‹œê°„ì„ ë³´ì—¬ ì¤ë‹ˆë‹¤.    
    - ![inference_completion_api.png](img/inference_completion_api.png)

## 5.3. Message API í˜•íƒœë¡œ curl ì‹¤í–‰
- ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰ í•©ë‹ˆë‹¤.

```
curl localhost:8080/v1/chat/completions \
    -X POST \
    -d '{
"model": "tgi",
"messages": [
    {
    "role": "system",
    "content": "ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ì „ë¬¸ê°€ ì…ë‹ˆë‹¤."
    },
    {
    "role": "user",
    "content": "ë”¥ëŸ¬ë‹ì´ ë¬´ì—‡ì…ë‹ˆê¹Œ?"
    }
],
"stream": false,
"max_tokens": 512
}' \
    -H 'Content-Type: application/json'  
```

- ì•„ë˜ëŠ” total_time="24.338049835s" validation_time="394.38Âµs" queue_time="38.361Âµs" inference_time="24.337617254s" time_per_token="49.266431ms ì‹œê°„ì„ ë³´ì—¬ì£¼ê³ , ìœ„ì˜ ê²°ê³¼ì™€ ìœ ì‚¬ í•©ë‹ˆë‹¤.
    - ![inference_message_api.png](img/inference_message_api.png)

## 5.4. Inferentia2 ì˜ Neuron Core ì‚¬ìš©ëŸ‰ í™•ì¸
- ì•„ë˜ ë‚´ìš©ì€ ìœ„ì˜ "ì¶”ë¡  í…ŒìŠ¤íŠ¸ í•˜ê¸° (Message API)" ì‹¤í–‰ ì¤‘ì—, ìŠ¤í¬ë¦°ìƒ· í™”ë©´ ì…ë‹ˆë‹¤. ë‘ê°œì˜ ì½”ì–´ê°€ ê±°ì˜ ë‹¤ ì‚¬ìš©ë˜ê³  ìˆê³ , Memory 19.4 GB ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. 
    - ![neuron-top.png](img/neuron-top.png)         

# 6. Neuron Model ì„ Hugging Face Hub ë¡œ ì—…ë¡œë“œ
- Hugging Face Hub ì— ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ì„œëŠ” "ì“°ê¸°ìš©" HF Writable Token ì´ í•„ìš” í•©ë‹ˆë‹¤., ì´í›„ì— ì•„ë˜ì™€ ê°™ì´ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œê¸´ í•˜ì„¸ìš”.
    - í† í°ì„ í™˜ê²½ ë³€ìˆ˜ì— ì €ì¥
        ```
        export API_TOKEN=<HF Writable Token ì…ë ¥>
        ```
    - HF ì— ë¡œê·¸ì¸
        ```
        huggingface-cli login --token $API_TOKEN
        ```
- ì•„ë˜ì™€ ê°™ì´ Gonsoo/AWS-NeuronCC-2-14-llama-3-Korean-Bllossom-8B ì— ì—…ë¡œë“œ
    ```
        huggingface-cli upload  Gonsoo/AWS-HF-optimum-neuron-0-0-28-llama-3-Korean-Bllossom-8B \
        ./data/llama-3-Korean-Bllossom-8B-recompiled --exclude "checkpoint/**"
    ```
    - ìœ„ì˜ ëª…ë ¹ì–´ì˜ ì‹¤í–‰ í™”ë©´ ì…ë‹ˆë‹¤. 
    - ![upload_model_hf.png](img/upload_model_hf.jpg)
- Hugging Face Hub ì— ë“±ë¡ëœ ëª¨ë¸ í™”ë©´ ì…ë‹ˆë‹¤.<br><br>
    - ![llama3-kr-bllossom.png](img/llama3-kr-bllossom.png)

# 7. SageMaker Inference Endpoint ìƒì„±
ê³ ìƒ í•˜ì…¨ìŠµë‹ˆë‹¤. ì´ì œ ì´ë ‡ê²Œ ë¡œì»¬ì—ì„œ "í•œêµ­ì–´ íŒŒì¸ íŠœë‹ ëª¨ë¸" ì˜ ì»´íŒŒì¼ ë° ëª¨ë¸ ì„œë¹™ í…ŒìŠ¤íŠ¸ ëœ ê²ƒì„ SageMaker Endpoint ìƒì„±í•˜ì—¬ ì¶”ë¡  í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰ í•˜ì„¸ìš”.
- [01-deploy-llama-3-neuron-moel-inferentia2](notebook/01-deploy-llama-3-neuron-moel-inferentia2.ipynb)
- [02-deploy-llama-3-neuron-moel-inferentia2-from-S3](notebook/02-deploy-llama-3-neuron-moel-inferentia2-from-S3.ipynb)
- [03-deploy-qwen-2-5-instruct-neuron-moel-inferentia2](notebook/03-deploy-qwen-2-5-instruct-neuron-moel-inferentia2.ipynb)
---
Contributor: ë¬¸ê³¤ìˆ˜ (Gonsoo Moon)