# AWS Neuron 가이드

AWS Neuron (Tranium, Tranium1, Inferentia, Inferentia2 ) 에 관련 링크, 튜토리얼, 가이드를 제공 합니다.

Last updated: Feb 25, 2024

---


# 1. Quick Links
- AWS Neuron 공식 문서[AWS Neuron Documentation](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/)
- AWS Neuron 공식 Git Repo: [aws-neuron-samples](https://github.com/aws-neuron/aws-neuron-samples)
- AWS Neuron Roadmap 으로서 완료, 진행 중인 기능 및 모델 확인: [AWS Neuron Roadmap](https://github.com/orgs/aws-neuron/projects/1)
- Hugging Face 로 쉽게 AWS Neuron 활용: [Hugging Face Optimum Neuron](https://huggingface.co/docs/optimum-neuron/index)
- Hugging Face Optimum Neuron Git Repo: [Optimum-neuron git](https://github.com/huggingface/optimum-neuron.git)
        
<p>

# 2. 튜토리얼 및 코드 예시
여기는 AWS Neuron 을 사용한  튜토리얼, 코드, 지직 및 Tip 을 제공합니다.

## 2.1 AWS Neuron 
- (Feb 2024) [Run Hugging Face `meta-llama/Llama-2-13b autoregressive sampling on Inf2 & Trn1](tutorial/inference-Llama-2-13b/README.md)

## 2.2. Hugging Face Optimum Neuron
- (Feb 2024) [AWS Inferentia 기반 위에 llama-2-13B 이용하여 챗봇 데모](hf-optimum/01-Chatbot-Llama-2-13B-Inf2/README.md)
- (Feb 2024) [AWS Tranium 기반 위에 llama-2-7B 및 Dolly Dataset 으로 파인 튜닝](hf-optimum/02-Fine-tune-Llama-7B-Trn1/README.md)

## 2.3. Transformer Neuronx
- (Apr 2024) [AWS Inferentia 기반 위에 llama-2-13B 이용한 자기회귀 샘플링](transformers-neuronx/meta-llama-2-13b-sampling.ipynb)
- (Apr 2024) [AWS Inferentia 기반 위에 SOLAR-10.7B 이용한 자기회귀 샘플링](transformers-neuronx/SOLAR-10.7B-Instruct-v1.0-sampling.ipynb)



# 3. 관련 블로그
- [주요 블로그 보기](blog/Readme.md)
---

## License
This library is licensed under the Apache 2.0 License. For more details, please take a look at the LICENSE file.

---

## Contributing
Although we're extremely excited to receive contributions from the community, we're still working on the best mechanism to take in examples from external sources. Please bear with us in the short-term if pull requests take longer than expected or are closed. Please read our contributing guidelines if you'd like to open an issue or submit a pull request.

---